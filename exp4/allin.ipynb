{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:06.420933Z",
     "start_time": "2024-04-29T12:02:58.646870Z"
    }
   },
   "source": [
    "# tensorflow_text, tensorflow, matplotlib\n",
    "import numpy as np\n",
    "\n",
    "import typing\n",
    "from typing import Any, Tuple\n",
    "# Customize types\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "# import preprocess module\n",
    "import tensorflow_text as tf_text\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:06.436404Z",
     "start_time": "2024-04-29T12:03:06.423436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ShapeChecker:\n",
    "    def __init__(self):\n",
    "        # save every cache\n",
    "        self.shapes = {}\n",
    "\n",
    "    def __call__(self, tensor, names, broadcast=False):\n",
    "        if not tf.executing_eagerly():\n",
    "            return\n",
    "\n",
    "        if isinstance(names, str):\n",
    "            names = (names,)\n",
    "\n",
    "        shape = tf.shape(tensor)\n",
    "        rank = tf.rank(tensor)\n",
    "\n",
    "        if rank != len(names):\n",
    "            raise ValueError(f'Rank mismatch:\\n'\n",
    "                             f'    found {rank}: {shape.numpy()}\\n'\n",
    "                             f'    expected {len(names)}: {names}\\n')\n",
    "\n",
    "        for i, name in enumerate(names):\n",
    "            if isinstance(name, int):\n",
    "                old_dim = name\n",
    "            else:\n",
    "                old_dim = self.shapes.get(name, None)\n",
    "            new_dim = shape[i]\n",
    "\n",
    "            if broadcast and new_dim == 1:\n",
    "                continue\n",
    "\n",
    "            if old_dim is None:\n",
    "                # if the name is new, save it to the cache\n",
    "                self.shapes[name] = new_dim\n",
    "                continue\n",
    "\n",
    "            if new_dim != old_dim:\n",
    "                raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
    "                                 f\"    found: {new_dim}\\n\"\n",
    "                                 f\"    expected: {old_dim}\\n\")\n"
   ],
   "id": "42a9b1393d063af2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:06.529233Z",
     "start_time": "2024-04-29T12:03:06.439399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download the file\n",
    "import pathlib\n",
    "\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = pathlib.Path(path_to_zip).parent /'spa-eng/spa.txt'\n"
   ],
   "id": "485b5de119708900",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:06.545014Z",
     "start_time": "2024-04-29T12:03:06.532226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def load_data(path):\n",
    "    text = path.read_text(encoding='utf-8')\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    pairs = [line.split('\\t') for line in lines]\n",
    "\n",
    "    inp = [inp for targ, inp in pairs]\n",
    "    targ = [targ for targ, inp in pairs]\n",
    "\n",
    "    return targ, inp"
   ],
   "id": "5956e97d2c6a4eb8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:07.859262Z",
     "start_time": "2024-04-29T12:03:06.547214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "targ, inp = load_data(path_to_file)\n",
    "BUFFER_SIZE = len(inp)\n",
    "BATCH_SIZE = 64\n",
    "# create a tf.data.Dataset string to wash the data and batch it efficiently\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ],
   "id": "4475a6549acef647",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:07.998523Z",
     "start_time": "2024-04-29T12:03:07.861258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for example_input_batch, example_target_batch in dataset.take(1):\n",
    "    print(example_input_batch[:5])\n",
    "    print()\n",
    "    print(example_target_batch[:5])\n",
    "    break\n"
   ],
   "id": "ac17296a84086aed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'Es muy popular.' b'\\xc2\\xbfTiene un pasaje de vuelta a Jap\\xc3\\xb3n?'\n",
      " b'Por supuesto que te ayudar\\xc3\\xa9.'\n",
      " b'La dehesa est\\xc3\\xa1 llena de mala hierba.'\n",
      " b'Se meti\\xc3\\xb3 un ladr\\xc3\\xb3n a la casa mientras and\\xc3\\xa1bamos afuera.'], shape=(5,), dtype=string)\n",
      "\n",
      "tf.Tensor(\n",
      "[b\"It's very popular.\" b'Do you have a return ticket to Japan?'\n",
      " b'I will help you, of course.' b'The pasture is full of weeds.'\n",
      " b'A thief broke into the house while we were away.'], shape=(5,), dtype=string)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:08.013989Z",
     "start_time": "2024-04-29T12:03:08.000999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example_text = tf.constant('¿Todavía está en casa?')\n",
    "\n",
    "print(example_text.numpy())\n",
    "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
   ],
   "id": "68b40f0e4e351426",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xc2\\xbfTodav\\xc3\\xada est\\xc3\\xa1 en casa?'\n",
      "b'\\xc2\\xbfTodavi\\xcc\\x81a esta\\xcc\\x81 en casa?'\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:08.029620Z",
     "start_time": "2024-04-29T12:03:08.018985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tf_lower_and_split_punct(text):\n",
    "    # 对字符进行切分\n",
    "    text = tf_text.normalize_utf8(text, 'NFKD')\n",
    "    text = tf.strings.lower(text)\n",
    "    # 保持空格，从a到z，并选择标点符号。\n",
    "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
    "    # 在标点符号周围添加空格。\n",
    "    text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
    "    # 去空格。\n",
    "    text = tf.strings.strip(text)\n",
    "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
    "    return text"
   ],
   "id": "e7b1bf603f12b66",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:08.044918Z",
     "start_time": "2024-04-29T12:03:08.033440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(example_text.numpy().decode())\n",
    "# 输出解码结果(德语)\n",
    "print(tf_lower_and_split_punct(example_text).numpy().decode())\n",
    "# 对句子进行头尾标注\n",
    "# 输出结果：\n",
    "# ¿Todavía está en casa?\n",
    "# [START] ¿ todavia esta en casa ? [END]"
   ],
   "id": "56aa451228bda03b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Todavía está en casa?\n",
      "[START] ¿ todavia esta en casa ? [END]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:08.091831Z",
     "start_time": "2024-04-29T12:03:08.047413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_vocab_size = 5000\n",
    "\n",
    "input_text_processor = preprocessing.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size)"
   ],
   "id": "1e45d49e8b42afe0",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:12.144983Z",
     "start_time": "2024-04-29T12:03:08.094826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_text_processor.adapt(inp)\n",
    "# this is first 10 words in vocabulary\n",
    "print(input_text_processor.get_vocabulary()[:10])"
   ],
   "id": "ba1992dcbd1177aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', '[START]', '[END]', '.', 'que', 'de', 'el', 'a', 'no']\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:14.635694Z",
     "start_time": "2024-04-29T12:03:12.146800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_text_processor = preprocessing.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size)\n",
    "output_text_processor.adapt(targ)\n",
    "print(output_text_processor.get_vocabulary()[:10])"
   ],
   "id": "8a1b40bc6a8a00a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', '[START]', '[END]', '.', 'the', 'i', 'to', 'you', 'tom']\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:14.651363Z",
     "start_time": "2024-04-29T12:03:14.637677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example_tokens = input_text_processor(example_input_batch)\n",
    "print(example_tokens[:3, :10])"
   ],
   "id": "7ec369b4228b2eeb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[   2   15   42 1298    4    3    0    0    0    0]\n",
      " [   2   13   44   16 3406    6  557    8  250   12]\n",
      " [   2   21 1931    5   30 3489    4    3    0    0]], shape=(3, 10), dtype=int64)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:14.682113Z",
     "start_time": "2024-04-29T12:03:14.653665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_vocab = np.array(input_text_processor.get_vocabulary())\n",
    "tokens = input_vocab[example_tokens[0].numpy()]\n",
    "' '.join(tokens)"
   ],
   "id": "91ebdba501f9f30e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[START] es muy popular . [END]                '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:14.960640Z",
     "start_time": "2024-04-29T12:03:14.684588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(example_tokens)\n",
    "plt.title('Token IDs')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(example_tokens != 0)\n",
    "plt.title('Mask')"
   ],
   "id": "94279d9c634fd979",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mask')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:14.976047Z",
     "start_time": "2024-04-29T12:03:14.963086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#嵌入维度\n",
    "embedding_dim = 256\n",
    "#隐藏单元个数\n",
    "units = 1024"
   ],
   "id": "92b008892c8694cc",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:14.991518Z",
     "start_time": "2024-04-29T12:03:14.978544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "        # 嵌入层将令牌转换为向量\n",
    "        self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
    "                                                   embedding_dim)\n",
    "        # GRU RNN层依次处理这些向量。\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, tokens, state=None):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(tokens, ('batch', 's'))\n",
    "        # 嵌入层查找每个标记的嵌入情况。\n",
    "        vectors = self.embedding(tokens)\n",
    "        shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
    "        output, state = self.gru(vectors, initial_state=state)\n",
    "        shape_checker(output, ('batch', 's', 'enc_units'))\n",
    "        shape_checker(state, ('batch', 'enc_units'))\n",
    "        # 返回新的序列和它的状态。\n",
    "        return output, state\n"
   ],
   "id": "33858f34e8e65108",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:15.254529Z",
     "start_time": "2024-04-29T12:03:14.994014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 将输入的文本转换为token。\n",
    "example_tokens = input_text_processor(example_input_batch)\n",
    "# 对输入序列进行编码。\n",
    "encoder = Encoder(input_text_processor.vocabulary_size(),\n",
    "                  embedding_dim, units)\n",
    "example_enc_output, example_enc_state = encoder(example_tokens)\n",
    "print(f'Input batch, shape (batch): {example_input_batch.shape}')\n",
    "print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\n",
    "print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\n",
    "print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')"
   ],
   "id": "d1b80a889960f0bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch, shape (batch): (64,)\n",
      "Input batch tokens, shape (batch, s): (64, 22)\n",
      "Encoder output, shape (batch, s, units): (64, 22, 1024)\n",
      "Encoder state, shape (batch, units): (64, 1024)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:15.270031Z",
     "start_time": "2024-04-29T12:03:15.257026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.attention = tf.keras.layers.AdditiveAttention()\n",
    "\n",
    "    def call(self, query, value, mask):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(query, ('batch', 't', 'query_units'))\n",
    "        shape_checker(value, ('batch', 's', 'value_units'))\n",
    "        shape_checker(mask, ('batch', 's'))\n",
    "        # 构建Query矩阵\n",
    "        w1_query = self.W1(query)\n",
    "        shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
    "        # 构建Key矩阵\n",
    "        w2_key = self.W2(value)\n",
    "        shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
    "        # 构建mask矩阵\n",
    "        query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
    "        value_mask = mask\n",
    "        # 计算得到注意力图谱\n",
    "        context_vector, attention_weights = self.attention(\n",
    "            inputs=[w1_query, value, w2_key],\n",
    "            mask=[query_mask, value_mask],\n",
    "            return_attention_scores=True,\n",
    "        )\n",
    "        shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
    "        shape_checker(attention_weights, ('batch', 't', 's'))\n",
    "        return context_vector, attention_weights"
   ],
   "id": "70fd654762f0305",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:15.347358Z",
     "start_time": "2024-04-29T12:03:15.271997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test attention\n",
    "# 创建一个BahdanauAttention层\n",
    "attention_layer = BahdanauAttention(units)\n",
    "# 后续解码器将产生这个attention查询(Query矩阵)\n",
    "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n",
    "# 添加到编码tokens\n",
    "context_vector, attention_weights = attention_layer(\n",
    "    query=example_attention_query,\n",
    "    value=example_enc_output,\n",
    "    mask=(example_tokens != 0))\n",
    "\n",
    "print(f'Attention result shape: (batch_size, query_seq_length, units): {context_vector.shape}')\n",
    "\n",
    "print(f'Attention weights shape: (batch_size, query_seq_length,value_seq_length): {attention_weights.shape}')"
   ],
   "id": "376e9c3e42ba190e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch_size, query_seq_length, units): (64, 2, 1024)\n",
      "Attention weights shape: (batch_size, query_seq_length,value_seq_length): (64, 2, 22)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:15.548458Z",
     "start_time": "2024-04-29T12:03:15.348855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(attention_weights[:, 0, :])\n",
    "plt.title('Attention weights')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(example_tokens != 0)\n",
    "plt.title('Mask')\n",
    "# 输出结果：\n",
    "# Text(0.5, 1.0, 'Mask')"
   ],
   "id": "99c4dd2e35ab31b9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mask')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:15.919723Z",
     "start_time": "2024-04-29T12:03:15.550423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#取出部分attention用于展示\n",
    "attention_slice = attention_weights[0, 0].numpy()\n",
    "attention_slice = attention_slice[attention_slice != 0]\n",
    "plt.suptitle('Attention weights for one sequence')\n",
    "plt.figure(figsize=(12, 6))\n",
    "a1 = plt.subplot(1, 2, 1)\n",
    "plt.bar(range(len(attention_slice)), attention_slice)\n",
    "# 固定x轴\n",
    "plt.xlim(plt.xlim())\n",
    "plt.xlabel('Attention weights')\n",
    "a2 = plt.subplot(1, 2, 2)\n",
    "plt.bar(range(len(attention_slice)), attention_slice)\n",
    "plt.xlabel('Attention weights, zoomed')\n",
    "# 放大结果\n",
    "top = max(a1.get_ylim())\n",
    "zoom = 0.85 * top\n",
    "a2.set_ylim([0.90 * top, top])\n",
    "a1.plot(a1.get_xlim(), [zoom, zoom], color='k')\n",
    "\n",
    "\n",
    "# 输出结果：\n",
    "# [<matplotlib.lines.Line2D at 0x20c356a9670>]\n",
    "# <Figure size 432x288 with 0 Axes>"
   ],
   "id": "4099e18f7321e049",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x253c25e92e8>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:15.950665Z",
     "start_time": "2024-04-29T12:03:15.927708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.output_vocab_size = output_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # 嵌入层将令牌ID转为向量\n",
    "        self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
    "                                                   embedding_dim)\n",
    "        # RNN会记录到目前为止已经生成的内容。\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        # RNN的输出将是注意力层的查询。\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "        self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
    "                                        use_bias=False)\n",
    "        self.fc = tf.keras.layers.Dense(self.output_vocab_size)"
   ],
   "id": "b09fb5c11dbc3e3b",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:15.966261Z",
     "start_time": "2024-04-29T12:03:15.954658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DecoderInput(typing.NamedTuple):\n",
    "    new_tokens: Any\n",
    "    enc_output: Any\n",
    "    mask: Any\n",
    "\n",
    "\n",
    "class DecoderOutput(typing.NamedTuple):\n",
    "    logits: Any\n",
    "    attention_weights: Any"
   ],
   "id": "b7895dcff51bc6bd",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:15.997078Z",
     "start_time": "2024-04-29T12:03:15.969131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def call(self,\n",
    "         inputs: DecoderInput,\n",
    "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
    "    shape_checker = ShapeChecker()\n",
    "    shape_checker(inputs.new_tokens, ('batch', 't'))\n",
    "    shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n",
    "    shape_checker(inputs.mask, ('batch', 's'))\n",
    "    if state is not None:\n",
    "        shape_checker(state, ('batch', 'dec_units'))\n",
    "    #查询词嵌入\n",
    "    vectors = self.embedding(inputs.new_tokens)\n",
    "    shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n",
    "    #用RNN处理一个步骤\n",
    "    rnn_output, state = self.gru(vectors, initial_state=state)\n",
    "    shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n",
    "    shape_checker(state, ('batch', 'dec_units'))\n",
    "    #使用RNN输出作为关注的查询，超过了编码器的输出。\n",
    "\n",
    "    context_vector, attention_weights = self.attention(\n",
    "        query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
    "    shape_checker(context_vector, ('batch', 't', 'dec_units'))\n",
    "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
    "    # 加入context_vector和rnn_output\n",
    "    context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
    "    attention_vector = self.Wc(context_and_rnn_output)\n",
    "    shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n",
    "    # 生成logit预测\n",
    "    logits = self.fc(attention_vector)\n",
    "    shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n",
    "    return DecoderOutput(logits, attention_weights), state"
   ],
   "id": "2a090632c7f1f4cc",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:16.028130Z",
     "start_time": "2024-04-29T12:03:15.999575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Decoder.call = call\n",
    "decoder = Decoder(output_text_processor.vocabulary_size(),\n",
    "                  embedding_dim, units)"
   ],
   "id": "6ca491eaa79919bc",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:16.058964Z",
     "start_time": "2024-04-29T12:03:16.031016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#转换目标序列，并收集[START]标记。\n",
    "example_output_tokens = output_text_processor(example_target_batch)\n",
    "start_index = output_text_processor.get_vocabulary().index('[START]')\n",
    "first_token = tf.constant([[start_index]] * example_output_tokens.shape[0])"
   ],
   "id": "8f9d744a6f575879",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:16.275562Z",
     "start_time": "2024-04-29T12:03:16.061459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#运行decoder\n",
    "dec_result, dec_state = decoder(\n",
    "    inputs=DecoderInput(new_tokens=first_token,\n",
    "                        enc_output=example_enc_output,\n",
    "                        mask=(example_tokens != 0)),\n",
    "    state=example_enc_state\n",
    ")\n",
    "print(f'logits shape: (batch_size, t, output_vocab_size)'\n",
    "      f'{dec_result.logits.shape}')\n",
    "print(f'state shape: (batch_size, dec_units) {dec_state.shape}')"
   ],
   "id": "ac8670868f7d900e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape: (batch_size, t, output_vocab_size)(64, 1, 5000)\n",
      "state shape: (batch_size, dec_units) (64, 1024)\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:16.306581Z",
     "start_time": "2024-04-29T12:03:16.278557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
    "#将令牌解码为输出的第一个单词。\n",
    "vocab = np.array(output_text_processor.get_vocabulary())\n",
    "first_word = vocab[sampled_token.numpy()]\n",
    "print(first_word[:5])"
   ],
   "id": "20eaa1a478485039",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ticket']\n",
      " ['intended']\n",
      " ['if']\n",
      " ['avoided']\n",
      " ['jury']]\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:16.383861Z",
     "start_time": "2024-04-29T12:03:16.308003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dec_result, dec_state = decoder(\n",
    "    DecoderInput(sampled_token,\n",
    "                 example_enc_output,\n",
    "                 mask=(example_tokens != 0)),\n",
    "    state=dec_state)\n",
    "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
    "first_word = vocab[sampled_token.numpy()]\n",
    "print(first_word[:5])"
   ],
   "id": "d8cb160a6cb9cbe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['gym']\n",
      " ['escape']\n",
      " ['bite']\n",
      " ['referring']\n",
      " ['currently']]\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:16.399332Z",
     "start_time": "2024-04-29T12:03:16.386357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MaskedLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        self.name = 'masked_loss'\n",
    "        self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=True, reduction='none')\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(y_true, ('batch', 't'))\n",
    "        shape_checker(y_pred, ('batch', 't', 'logits'))\n",
    "        # 计算该批次中每一项的损失。\n",
    "        loss = self.loss(y_true, y_pred)\n",
    "        shape_checker(loss, ('batch', 't'))\n",
    "        # 屏蔽掉填充物上的损失。\n",
    "        mask = tf.cast(y_true != 0, tf.float32)\n",
    "        shape_checker(mask, ('batch', 't'))\n",
    "        loss *= mask\n",
    "        # 返回总的loss。\n",
    "        return tf.reduce_sum(loss)"
   ],
   "id": "85110b82afcc49e5",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:16.415070Z",
     "start_time": "2024-04-29T12:03:16.401329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TrainTranslator(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, units,\n",
    "                 input_text_processor,\n",
    "                 output_text_processor,\n",
    "                 use_tf_function=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # 构建编码器和解码器\n",
    "        encoder = Encoder(input_text_processor.vocabulary_size(),\n",
    "                          embedding_dim, units)\n",
    "        decoder = Decoder(output_text_processor.vocabulary_size(),\n",
    "                          embedding_dim, units)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.input_text_processor = input_text_processor\n",
    "        self.output_text_processor = output_text_processor\n",
    "        self.use_tf_function = use_tf_function\n",
    "        self.shape_checker = ShapeChecker()\n",
    "\n",
    "    def train_step(self, inputs):\n",
    "        self.shape_checker = ShapeChecker()\n",
    "\n",
    "        if self.use_tf_function:\n",
    "            return self._tf_train_step(inputs)\n",
    "        else:\n",
    "            return self._train_step(inputs)"
   ],
   "id": "ff17f8833ae094f1",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:16.430274Z",
     "start_time": "2024-04-29T12:03:16.416801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _preprocess(self, input_text, target_text):\n",
    "    self.shape_checker(input_text, ('batch',))\n",
    "    self.shape_checker(target_text, ('batch',))\n",
    "    # 将文本转换为tokens ID\n",
    "    input_tokens = self.input_text_processor(input_text)\n",
    "    target_tokens = self.output_text_processor(target_text)\n",
    "    self.shape_checker(input_tokens, ('batch', 's'))\n",
    "    self.shape_checker(target_tokens, ('batch', 't'))\n",
    "    # 将ID转换为掩码\n",
    "    input_mask = input_tokens != 0\n",
    "    self.shape_checker(input_mask, ('batch', 's'))\n",
    "    target_mask = target_tokens != 0\n",
    "\n",
    "    self.shape_checker(target_mask, ('batch', 't'))\n",
    "    return input_tokens, input_mask, target_tokens, target_mask\n",
    "\n",
    "\n",
    "TrainTranslator._preprocess = _preprocess"
   ],
   "id": "b22885ddaad01bde",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:16.445746Z",
     "start_time": "2024-04-29T12:03:16.432770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _train_step(self, inputs):\n",
    "    input_text, target_text = inputs\n",
    "    (input_tokens, input_mask,\n",
    "     target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
    "    max_target_length = tf.shape(target_tokens)[1]\n",
    "    with tf.GradientTape() as tape:\n",
    "        #对输入进行编码\n",
    "        enc_output, enc_state = self.encoder(input_tokens)\n",
    "        self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
    "        self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
    "        #将解码器的状态初始化为编码器的最终状态。\n",
    "        # 这只有在编码器和解码器有相同数量的单位时生效。\n",
    "        dec_state = enc_state\n",
    "        loss = tf.constant(0.0)\n",
    "        for t in tf.range(max_target_length - 1):\n",
    "            #从目标序列中传入两个token:\n",
    "            # 1.解码器的当前输入.\n",
    "            # 2.解码器下次预测的目标.\n",
    "            new_tokens = target_tokens[:, t:t + 2]\n",
    "            step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
    "                                                   enc_output, dec_state)\n",
    "            loss = loss + step_loss\n",
    "        #对所有非填充token的损失进行平均计算。\n",
    "        average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
    "    #设置优化步骤\n",
    "    variables = self.trainable_variables\n",
    "    gradients = tape.gradient(average_loss, variables)\n",
    "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "    # 返回一个映射到当前值的字典\n",
    "    return {'batch_loss': average_loss}\n",
    "\n",
    "\n",
    "TrainTranslator._train_step = _train_step"
   ],
   "id": "1b5e4efe9a0e1199",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:16.461217Z",
     "start_time": "2024-04-29T12:03:16.447743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
    "    input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
    "    # Run the decoder one step.\n",
    "    decoder_input = DecoderInput(new_tokens=input_token,\n",
    "                                 enc_output=enc_output,\n",
    "                                 mask=input_mask)\n",
    "    dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
    "    self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
    "    self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
    "    self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
    "    # `self.loss`返回非填充token的总数。\n",
    "    y = target_token\n",
    "    y_pred = dec_result.logits\n",
    "    step_loss = self.loss(y, y_pred)\n",
    "    return step_loss, dec_state"
   ],
   "id": "e465f8ce36d52d36",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:16.523102Z",
     "start_time": "2024-04-29T12:03:16.463214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TrainTranslator._loop_step = _loop_step\n",
    "\n",
    "translator = TrainTranslator(\n",
    "    embedding_dim, units,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor,\n",
    "    use_tf_function=False)\n",
    "#配置损失和优化器\n",
    "translator.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss=MaskedLoss(),\n",
    ")"
   ],
   "id": "dc4b406d5021713e",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:16.538575Z",
     "start_time": "2024-04-29T12:03:16.525598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.log(output_text_processor.vocabulary_size())\n",
    "# 输出结果:\n",
    "# 8.517193191416238"
   ],
   "id": "7bf520a8b78487e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.517193191416238"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:03:56.235010Z",
     "start_time": "2024-04-29T12:03:16.540571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "for n in range(10):\n",
    "    print(translator.train_step([example_input_batch, example_target_batch]))\n",
    "print()\n",
    "\n",
    "\n",
    "# 输出结果:\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.6101117>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.5797815>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.522971>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.3605533>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.785821>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.0904937>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.8641896>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.3120656>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.264642>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.112561>}"
   ],
   "id": "f3b7de43543b6286",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.639651>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.6114674>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.5589623>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.4096403>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.88526>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.235115>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.1976542>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.3875957>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.549182>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.259236>}\n",
      "\n",
      "Wall time: 39.7 s\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:04:03.040224Z",
     "start_time": "2024-04-29T12:03:56.237357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
    "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
    "def _tf_train_step(self, inputs):\n",
    "    return self._train_step(inputs)\n",
    "\n",
    "\n",
    "TrainTranslator._tf_train_step = _tf_train_step\n",
    "\n",
    "translator.use_tf_function = True\n",
    "#第一次运行由于需要对函数进行追踪，故速度会比较慢\n",
    "translator.train_step([example_input_batch, example_target_batch])"
   ],
   "id": "42fdf1c2de5edb31",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.248304>}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:04:28.342239Z",
     "start_time": "2024-04-29T12:04:03.043218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "for n in range(10):\n",
    "    print(translator.train_step([example_input_batch, example_target_batch]))\n",
    "print()"
   ],
   "id": "9fe3db5cde852fd6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.272426>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.2297215>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.127991>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.0735254>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.9900968>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.9074275>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.8745506>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.8343768>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.792659>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.7839115>}\n",
      "\n",
      "Wall time: 25.3 s\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:08:41.410313Z",
     "start_time": "2024-04-29T12:04:28.344237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "losses = []\n",
    "for n in range(100):\n",
    "    print('.', end='')\n",
    "    logs = translator.train_step([example_input_batch, example_target_batch])\n",
    "    losses.append(logs['batch_loss'].numpy())\n",
    "print()\n",
    "plt.plot(losses)\n",
    "# 输出结果:\n",
    "#\n",
    "# [<matplotlib.lines.Line2D at 0x20c362c3c70>]"
   ],
   "id": "19970613f8d38394",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x253befc4710>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:08:41.441419Z",
     "start_time": "2024-04-29T12:08:41.412309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_translator = TrainTranslator(\n",
    "    embedding_dim, units,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor)\n",
    "# Configure the loss and optimizer\n",
    "train_translator.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss=MaskedLoss(),\n",
    ")"
   ],
   "id": "90aa79f7a87dae47",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:09:04.503089Z",
     "start_time": "2024-04-29T12:08:41.443750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BatchLogs(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.logs = []\n",
    "\n",
    "    def on_train_batch_end(self, n, logs):\n",
    "        self.logs.append(logs[self.key])\n",
    "\n",
    "\n",
    "batch_loss = BatchLogs('batch_loss')\n",
    "\n",
    "train_translator.fit(dataset, epochs=3,\n",
    "                     steps_per_epoch=3,\n",
    "                     callbacks=[batch_loss])"
   ],
   "id": "d36e523c918388c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3/3 [==============================] - 11s 2s/step - batch_loss: 7.5697\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 5s 2s/step - batch_loss: 6.2834\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 6s 2s/step - batch_loss: 5.5557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x253bf0088d0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:09:04.642331Z",
     "start_time": "2024-04-29T12:09:04.504587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 如果上一个cell中的epoches和steps_per_epoch过小，此处没有绘图效果。\n",
    "plt.plot(batch_loss.logs)\n",
    "plt.ylim([0, 3])\n",
    "plt.xlabel('Batch #')\n",
    "plt.ylabel('CE/token')"
   ],
   "id": "7b6aa847d2c0f673",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'CE/token')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:09:04.858764Z",
     "start_time": "2024-04-29T12:09:04.644329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Translator(tf.Module):\n",
    "    def __init__(self, encoder, decoder, input_text_processor,\n",
    "                 output_text_processor):\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.input_text_processor = input_text_processor\n",
    "        self.output_text_processor = output_text_processor\n",
    "        self.output_token_string_from_index = (\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=output_text_processor.get_vocabulary(),\n",
    "                mask_token='',\n",
    "                invert=True))\n",
    "\n",
    "        # 输出不应该产生padding、unknown或start。\n",
    "        index_from_string = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "            vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
    "        token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
    "        token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
    "\n",
    "        token_mask[np.array(token_mask_ids)] = True\n",
    "        self.token_mask = token_mask\n",
    "        self.start_token = index_from_string(tf.constant('[START]'))\n",
    "        self.end_token = index_from_string(tf.constant('[END]'))\n",
    "\n",
    "\n",
    "translator = Translator(\n",
    "    encoder=train_translator.encoder,\n",
    "    decoder=train_translator.decoder,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor,\n",
    ")"
   ],
   "id": "2038dd2fdcf63973",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:09:04.889688Z",
     "start_time": "2024-04-29T12:09:04.860638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokens_to_text(self, result_tokens):\n",
    "    shape_checker = ShapeChecker()\n",
    "    shape_checker(result_tokens, ('batch', 't'))\n",
    "    result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
    "    shape_checker(result_text_tokens, ('batch', 't'))\n",
    "    result_text = tf.strings.reduce_join(result_text_tokens,\n",
    "                                         axis=1, separator=' ')\n",
    "    shape_checker(result_text, 'batch')\n",
    "    result_text = tf.strings.strip(result_text)\n",
    "    shape_checker(result_text, ('batch',))\n",
    "    return result_text\n",
    "\n",
    "\n",
    "Translator.tokens_to_text = tokens_to_text\n",
    "\n",
    "example_output_tokens = tf.random.uniform(\n",
    "    shape=[5, 2], minval=0, dtype=tf.int64,\n",
    "    maxval=output_text_processor.vocabulary_size())\n",
    "\n",
    "translator.tokens_to_text(example_output_tokens).numpy()"
   ],
   "id": "1e1ee7a796c37760",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'scratch words', b'invaded atlantic', b'culture pretty',\n",
       "       b'start prisoner', b'attacked loud'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:09:04.920528Z",
     "start_time": "2024-04-29T12:09:04.891589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sample(self, logits, temperature):\n",
    "    shape_checker = ShapeChecker()\n",
    "    shape_checker(logits, ('batch', 't', 'vocab'))\n",
    "    shape_checker(self.token_mask, ('vocab',))\n",
    "    token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
    "    shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n",
    "    logits = tf.where(self.token_mask, -np.inf, logits)\n",
    "    if temperature == 0.0:\n",
    "        new_tokens = tf.argmax(logits, axis=-1)\n",
    "    else:\n",
    "        logits = tf.squeeze(logits, axis=1)\n",
    "        new_tokens = tf.random.categorical(logits / temperature,\n",
    "                                           num_samples=1)\n",
    "        shape_checker(new_tokens, ('batch', 't'))\n",
    "        return new_tokens\n",
    "\n",
    "Translator.sample = sample\n",
    "\n",
    "example_logits = tf.random.normal([5, 1,\n",
    "                                   output_text_processor.vocabulary_size()])\n",
    "example_output_tokens = translator.sample(example_logits, temperature=1.0)\n",
    "example_output_tokens"
   ],
   "id": "128f292dfeb3d484",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
       "array([[ 822],\n",
       "       [1846],\n",
       "       [4591],\n",
       "       [4055],\n",
       "       [4753]], dtype=int64)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:09:04.936163Z",
     "start_time": "2024-04-29T12:09:04.923024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def translate_unrolled(self,\n",
    "                       input_text, *,\n",
    "                       max_length=50,\n",
    "                       return_attention=True,\n",
    "                       temperature=1.0):\n",
    "    batch_size = tf.shape(input_text)[0]\n",
    "    input_tokens = self.input_text_processor(input_text)\n",
    "    enc_output, enc_state = self.encoder(input_tokens)\n",
    "    dec_state = enc_state\n",
    "    new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
    "    result_tokens = []\n",
    "    attention = []\n",
    "    done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
    "    for _ in range(max_length):\n",
    "        dec_input = DecoderInput(new_tokens=new_tokens,\n",
    "                                 enc_output=enc_output,\n",
    "                                 mask=(input_tokens != 0))\n",
    "        dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
    "        attention.append(dec_result.attention_weights)\n",
    "        new_tokens = self.sample(dec_result.logits, temperature)\n",
    "        done = done | (new_tokens == self.end_token)\n",
    "        # 一旦一个序列完成，它只产生0-padding。\n",
    "        new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
    "        result_tokens.append(new_tokens)\n",
    "        if tf.executing_eagerly() and tf.reduce_all(done):\n",
    "            break\n",
    "    # 将生成的token id列表转换为字符串列表。\n",
    "\n",
    "    result_tokens = tf.concat(result_tokens, axis=-1)\n",
    "    result_text = self.tokens_to_text(result_tokens)\n",
    "    if return_attention:\n",
    "        attention_stack = tf.concat(attention, axis=1)\n",
    "        return {'text': result_text, 'attention': attention_stack}\n",
    "    else:\n",
    "        return {'text': result_text}"
   ],
   "id": "dadd9bc7fdbf4891",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T12:09:04.951689Z",
     "start_time": "2024-04-29T12:09:04.937994Z"
    }
   },
   "cell_type": "code",
   "source": "Translator.translate = translate_unrolled",
   "id": "93752e7e36f8a821",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T13:48:50.584651Z",
     "start_time": "2024-04-29T13:48:49.336968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "input_text = tf.constant([\n",
    "    'hace mucho frio aqui.',  # \"It's freezing here.\"\n",
    "    'Esta es mi vida.',  # \"This is my life.\"\"\n",
    "])\n",
    "result = translator.translate(\n",
    "    input_text=input_text)\n",
    "\n",
    "# print(result)\n",
    "print(result['text'][0].numpy().decode())\n",
    "print(result['text'][1].numpy().decode())\n",
    "print()\n",
    "# 实验结果:\n",
    "# it is very cold here .\n",
    "# this is my life .\n",
    "# Wall time: 266 ms\n"
   ],
   "id": "e69544db06379360",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': <tf.Tensor: shape=(2,), dtype=string, numpy=\n",
      "array([b'times youre working semester true blamed me quiet children raised you ?',\n",
      "       b'suspiciously congratulate band visiting daughters were is just the to that . im to mary to the we the to thought'],\n",
      "      dtype=object)>, 'attention': <tf.Tensor: shape=(2, 22, 7), dtype=float32, numpy=\n",
      "array([[[0.16798447, 0.15657383, 0.1527461 , 0.14327456, 0.12872632,\n",
      "         0.12972283, 0.1209719 ],\n",
      "        [0.16806002, 0.1566215 , 0.15276507, 0.14328238, 0.1287463 ,\n",
      "         0.12965065, 0.12087414],\n",
      "        [0.16815458, 0.15668833, 0.15278639, 0.14329687, 0.12879424,\n",
      "         0.12954411, 0.12073549],\n",
      "        [0.16829023, 0.15678498, 0.15281142, 0.14332126, 0.12888093,\n",
      "         0.12938526, 0.12052585],\n",
      "        [0.16846424, 0.15691493, 0.15284175, 0.1433545 , 0.12902395,\n",
      "         0.12915997, 0.12024073],\n",
      "        [0.16871476, 0.15710591, 0.15287669, 0.14340009, 0.12924306,\n",
      "         0.12882833, 0.11983111],\n",
      "        [0.16898303, 0.15733394, 0.15290318, 0.143451  , 0.12956193,\n",
      "         0.12842235, 0.11934455],\n",
      "        [0.16922294, 0.15758388, 0.15290065, 0.14350937, 0.12999333,\n",
      "         0.12796463, 0.11882519],\n",
      "        [0.16930522, 0.15776478, 0.1528518 , 0.14356703, 0.1305086 ,\n",
      "         0.1275749 , 0.11842769],\n",
      "        [0.1692024 , 0.15784492, 0.15276067, 0.14361504, 0.13104363,\n",
      "         0.12731631, 0.11821703],\n",
      "        [0.16894278, 0.15781602, 0.15263934, 0.14365207, 0.13154043,\n",
      "         0.12721035, 0.11819901],\n",
      "        [0.16861187, 0.15772481, 0.1525095 , 0.14367956, 0.13197069,\n",
      "         0.12720536, 0.1182982 ],\n",
      "        [0.16828474, 0.1576065 , 0.15238588, 0.14369719, 0.13230662,\n",
      "         0.12726383, 0.11845519],\n",
      "        [0.16799822, 0.15749101, 0.15228188, 0.14370681, 0.13256592,\n",
      "         0.12733889, 0.11861733],\n",
      "        [0.16776034, 0.1573909 , 0.1521985 , 0.14371252, 0.1327598 ,\n",
      "         0.12741534, 0.11876263],\n",
      "        [0.16756931, 0.15730822, 0.15213272, 0.14371581, 0.13290486,\n",
      "         0.12748417, 0.11888494],\n",
      "        [0.16741788, 0.15724163, 0.15208113, 0.14371753, 0.13301422,\n",
      "         0.12754281, 0.11898489],\n",
      "        [0.16729814, 0.15718833, 0.15204073, 0.14371821, 0.13309756,\n",
      "         0.12759142, 0.11906565],\n",
      "        [0.16720337, 0.1571457 , 0.15200892, 0.14371842, 0.13316174,\n",
      "         0.1276313 , 0.11913057],\n",
      "        [0.16712782, 0.15711159, 0.15198368, 0.14371814, 0.13321176,\n",
      "         0.1276639 , 0.11918303],\n",
      "        [0.16706732, 0.1570841 , 0.15196355, 0.14371765, 0.13325135,\n",
      "         0.12769057, 0.11922544],\n",
      "        [0.16701835, 0.15706187, 0.1519472 , 0.143717  , 0.13328302,\n",
      "         0.12771252, 0.11926001]],\n",
      "\n",
      "       [[0.16141209, 0.15815692, 0.14986701, 0.14615057, 0.13241772,\n",
      "         0.13100697, 0.12098869],\n",
      "        [0.16150747, 0.1582001 , 0.14987488, 0.14614227, 0.13242689,\n",
      "         0.13094087, 0.12090745],\n",
      "        [0.16165604, 0.15826344, 0.14988485, 0.14612572, 0.13245177,\n",
      "         0.13083585, 0.1207823 ],\n",
      "        [0.16187792, 0.15834787, 0.14988849, 0.14609905, 0.1325006 ,\n",
      "         0.13067992, 0.12060609],\n",
      "        [0.16220291, 0.15846483, 0.14989178, 0.14605665, 0.13257186,\n",
      "         0.13045406, 0.12035795],\n",
      "        [0.162664  , 0.15862161, 0.14988914, 0.14599538, 0.13269009,\n",
      "         0.13012938, 0.12001039],\n",
      "        [0.16324782, 0.15879251, 0.1498649 , 0.14590092, 0.13286959,\n",
      "         0.12972254, 0.1196018 ],\n",
      "        [0.16389324, 0.15893891, 0.14980063, 0.14577346, 0.13313127,\n",
      "         0.12927693, 0.11918553],\n",
      "        [0.16444278, 0.15899955, 0.1496927 , 0.14561084, 0.13345563,\n",
      "         0.12889937, 0.11889917],\n",
      "        [0.16480923, 0.15894216, 0.14955023, 0.14544259, 0.1338214 ,\n",
      "         0.12864406, 0.11879034],\n",
      "        [0.16496098, 0.15879683, 0.14939803, 0.14528565, 0.13417204,\n",
      "         0.12853357, 0.1188528 ],\n",
      "        [0.16494705, 0.15860021, 0.14925903, 0.1451638 , 0.1344777 ,\n",
      "         0.12853248, 0.11901967],\n",
      "        [0.16484971, 0.15840487, 0.14914705, 0.14506757, 0.1347329 ,\n",
      "         0.12857793, 0.11921991],\n",
      "        [0.16473506, 0.15824556, 0.1490574 , 0.14499648, 0.13490945,\n",
      "         0.12865216, 0.11940389],\n",
      "        [0.16461945, 0.15811561, 0.14898805, 0.14494354, 0.13504356,\n",
      "         0.12872405, 0.11956573],\n",
      "        [0.16451415, 0.15800986, 0.14893667, 0.14491017, 0.13514432,\n",
      "         0.1287875 , 0.11969727],\n",
      "        [0.16442534, 0.15792975, 0.14889762, 0.14488265, 0.13521804,\n",
      "         0.12884142, 0.11980519],\n",
      "        [0.16434729, 0.15786354, 0.14886904, 0.14486773, 0.13527447,\n",
      "         0.12888657, 0.1198913 ],\n",
      "        [0.16429062, 0.15781668, 0.14884491, 0.1448539 , 0.13531782,\n",
      "         0.12892073, 0.11995537],\n",
      "        [0.16423927, 0.15777582, 0.1488284 , 0.14484547, 0.1353492 ,\n",
      "         0.12895031, 0.12001157],\n",
      "        [0.16420096, 0.15774679, 0.14881392, 0.14483517, 0.13537365,\n",
      "         0.12897344, 0.12005603],\n",
      "        [0.16416971, 0.15772547, 0.1488054 , 0.1448323 , 0.13539173,\n",
      "         0.12899008, 0.12008537]]], dtype=float32)>}\n",
      "times youre working semester true blamed me quiet children raised you ?\n",
      "suspiciously congratulate band visiting daughters were is just the to that . im to mary to the we the to thought\n",
      "\n",
      "Wall time: 1.24 s\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T13:51:17.579695Z",
     "start_time": "2024-04-29T13:51:17.561231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "# 获取当前运行的笔记本\n",
    "notebook = get_ipython().get_ipython().user_ns['In']\n",
    "\n",
    "# 打印所有输入单元格的内容\n",
    "for cell in notebook:\n",
    "    print(cell)\n"
   ],
   "id": "4eddb182287e1870",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dec_result, dec_state = decoder(\n",
      "    DecoderInput(sampled_token,\n",
      "                 example_enc_output,\n",
      "                 mask=(example_tokens != 0)),\n",
      "    state=dec_state)\n",
      "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
      "first_word = vocab[sampled_token.numpy()]\n",
      "print(first_word[:5])\n",
      "# tensorflow_text, tensorflow, matplotlib\n",
      "import numpy as np\n",
      "\n",
      "import typing\n",
      "from typing import Any, Tuple\n",
      "# Customize types\n",
      "import tensorflow as tf\n",
      "from tensorflow.keras.layers.experimental import preprocessing\n",
      "# import preprocess module\n",
      "import tensorflow_text as tf_text\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.ticker as ticker\n",
      "class ShapeChecker:\n",
      "    def __init__(self):\n",
      "        # save every cache\n",
      "        self.shapes = {}\n",
      "\n",
      "    def __call__(self, tensor, names, broadcast=False):\n",
      "        if not tf.executing_eagerly():\n",
      "            return\n",
      "\n",
      "        if isinstance(names, str):\n",
      "            names = (names,)\n",
      "\n",
      "        shape = tf.shape(tensor)\n",
      "        rank = tf.rank(tensor)\n",
      "\n",
      "        if rank != len(names):\n",
      "            raise ValueError(f'Rank mismatch:\\n'\n",
      "                             f'    found {rank}: {shape.numpy()}\\n'\n",
      "                             f'    expected {len(names)}: {names}\\n')\n",
      "\n",
      "        for i, name in enumerate(names):\n",
      "            if isinstance(name, int):\n",
      "                old_dim = name\n",
      "            else:\n",
      "                old_dim = self.shapes.get(name, None)\n",
      "            new_dim = shape[i]\n",
      "\n",
      "            if broadcast and new_dim == 1:\n",
      "                continue\n",
      "\n",
      "            if old_dim is None:\n",
      "                # if the name is new, save it to the cache\n",
      "                self.shapes[name] = new_dim\n",
      "                continue\n",
      "\n",
      "            if new_dim != old_dim:\n",
      "                raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
      "                                 f\"    found: {new_dim}\\n\"\n",
      "                                 f\"    expected: {old_dim}\\n\")\n",
      "# Download the file\n",
      "import pathlib\n",
      "\n",
      "path_to_zip = tf.keras.utils.get_file(\n",
      "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
      "    extract=True)\n",
      "\n",
      "path_to_file = pathlib.Path(path_to_zip).parent /'spa-eng/spa.txt'\n",
      "def load_data(path):\n",
      "    text = path.read_text(encoding='utf-8')\n",
      "\n",
      "    lines = text.splitlines()\n",
      "    pairs = [line.split('\\t') for line in lines]\n",
      "\n",
      "    inp = [inp for targ, inp in pairs]\n",
      "    targ = [targ for targ, inp in pairs]\n",
      "\n",
      "    return targ, inp\n",
      "targ, inp = load_data(path_to_file)\n",
      "BUFFER_SIZE = len(inp)\n",
      "BATCH_SIZE = 64\n",
      "# create a tf.data.Dataset string to wash the data and batch it efficiently\n",
      "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
      "dataset = dataset.batch(BATCH_SIZE)\n",
      "for example_input_batch, example_target_batch in dataset.take(1):\n",
      "    print(example_input_batch[:5])\n",
      "    print()\n",
      "    print(example_target_batch[:5])\n",
      "    break\n",
      "example_text = tf.constant('¿Todavía está en casa?')\n",
      "\n",
      "print(example_text.numpy())\n",
      "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())\n",
      "def tf_lower_and_split_punct(text):\n",
      "    # 对字符进行切分\n",
      "    text = tf_text.normalize_utf8(text, 'NFKD')\n",
      "    text = tf.strings.lower(text)\n",
      "    # 保持空格，从a到z，并选择标点符号。\n",
      "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
      "    # 在标点符号周围添加空格。\n",
      "    text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
      "    # 去空格。\n",
      "    text = tf.strings.strip(text)\n",
      "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
      "    return text\n",
      "print(example_text.numpy().decode())\n",
      "# 输出解码结果(德语)\n",
      "print(tf_lower_and_split_punct(example_text).numpy().decode())\n",
      "# 对句子进行头尾标注\n",
      "# 输出结果：\n",
      "# ¿Todavía está en casa?\n",
      "# [START] ¿ todavia esta en casa ? [END]\n",
      "max_vocab_size = 5000\n",
      "\n",
      "input_text_processor = preprocessing.TextVectorization(\n",
      "    standardize=tf_lower_and_split_punct,\n",
      "    max_tokens=max_vocab_size)\n",
      "input_text_processor.adapt(inp)\n",
      "# this is first 10 words in vocabulary\n",
      "print(input_text_processor.get_vocabulary()[:10])\n",
      "output_text_processor = preprocessing.TextVectorization(\n",
      "    standardize=tf_lower_and_split_punct,\n",
      "    max_tokens=max_vocab_size)\n",
      "output_text_processor.adapt(targ)\n",
      "print(output_text_processor.get_vocabulary()[:10])\n",
      "example_tokens = input_text_processor(example_input_batch)\n",
      "print(example_tokens[:3, :10])\n",
      "input_vocab = np.array(input_text_processor.get_vocabulary())\n",
      "tokens = input_vocab[example_tokens[0].numpy()]\n",
      "' '.join(tokens)\n",
      "plt.subplot(1, 2, 1)\n",
      "plt.pcolormesh(example_tokens)\n",
      "plt.title('Token IDs')\n",
      "plt.subplot(1, 2, 2)\n",
      "plt.pcolormesh(example_tokens != 0)\n",
      "plt.title('Mask')\n",
      "#嵌入维度\n",
      "embedding_dim = 256\n",
      "#隐藏单元个数\n",
      "units = 1024\n",
      "class Encoder(tf.keras.layers.Layer):\n",
      "    def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
      "        super(Encoder, self).__init__()\n",
      "        self.enc_units = enc_units\n",
      "        self.input_vocab_size = input_vocab_size\n",
      "        # 嵌入层将令牌转换为向量\n",
      "        self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
      "                                                   embedding_dim)\n",
      "        # GRU RNN层依次处理这些向量。\n",
      "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
      "                                       return_sequences=True,\n",
      "                                       return_state=True,\n",
      "                                       recurrent_initializer='glorot_uniform')\n",
      "\n",
      "    def call(self, tokens, state=None):\n",
      "        shape_checker = ShapeChecker()\n",
      "        shape_checker(tokens, ('batch', 's'))\n",
      "        # 嵌入层查找每个标记的嵌入情况。\n",
      "        vectors = self.embedding(tokens)\n",
      "        shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
      "        output, state = self.gru(vectors, initial_state=state)\n",
      "        shape_checker(output, ('batch', 's', 'enc_units'))\n",
      "        shape_checker(state, ('batch', 'enc_units'))\n",
      "        # 返回新的序列和它的状态。\n",
      "        return output, state\n",
      "# 将输入的文本转换为token。\n",
      "example_tokens = input_text_processor(example_input_batch)\n",
      "# 对输入序列进行编码。\n",
      "encoder = Encoder(input_text_processor.vocabulary_size(),\n",
      "                  embedding_dim, units)\n",
      "example_enc_output, example_enc_state = encoder(example_tokens)\n",
      "print(f'Input batch, shape (batch): {example_input_batch.shape}')\n",
      "print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\n",
      "print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\n",
      "print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')\n",
      "class BahdanauAttention(tf.keras.layers.Layer):\n",
      "    def __init__(self, units):\n",
      "        super().__init__()\n",
      "        self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
      "        self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
      "        self.attention = tf.keras.layers.AdditiveAttention()\n",
      "\n",
      "    def call(self, query, value, mask):\n",
      "        shape_checker = ShapeChecker()\n",
      "        shape_checker(query, ('batch', 't', 'query_units'))\n",
      "        shape_checker(value, ('batch', 's', 'value_units'))\n",
      "        shape_checker(mask, ('batch', 's'))\n",
      "        # 构建Query矩阵\n",
      "        w1_query = self.W1(query)\n",
      "        shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
      "        # 构建Key矩阵\n",
      "        w2_key = self.W2(value)\n",
      "        shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
      "        # 构建mask矩阵\n",
      "        query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
      "        value_mask = mask\n",
      "        # 计算得到注意力图谱\n",
      "        context_vector, attention_weights = self.attention(\n",
      "            inputs=[w1_query, value, w2_key],\n",
      "            mask=[query_mask, value_mask],\n",
      "            return_attention_scores=True,\n",
      "        )\n",
      "        shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
      "        shape_checker(attention_weights, ('batch', 't', 's'))\n",
      "        return context_vector, attention_weights\n",
      "# test attention\n",
      "# 创建一个BahdanauAttention层\n",
      "attention_layer = BahdanauAttention(units)\n",
      "# 后续解码器将产生这个attention查询(Query矩阵)\n",
      "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n",
      "# 添加到编码tokens\n",
      "context_vector, attention_weights = attention_layer(\n",
      "    query=example_attention_query,\n",
      "    value=example_enc_output,\n",
      "    mask=(example_tokens != 0))\n",
      "\n",
      "print(f'Attention result shape: (batch_size, query_seq_length, units): {context_vector.shape}')\n",
      "\n",
      "print(f'Attention weights shape: (batch_size, query_seq_length,value_seq_length): {attention_weights.shape}')\n",
      "plt.subplot(1, 2, 1)\n",
      "plt.pcolormesh(attention_weights[:, 0, :])\n",
      "plt.title('Attention weights')\n",
      "plt.subplot(1, 2, 2)\n",
      "plt.pcolormesh(example_tokens != 0)\n",
      "plt.title('Mask')\n",
      "# 输出结果：\n",
      "# Text(0.5, 1.0, 'Mask')\n",
      "#取出部分attention用于展示\n",
      "attention_slice = attention_weights[0, 0].numpy()\n",
      "attention_slice = attention_slice[attention_slice != 0]\n",
      "plt.suptitle('Attention weights for one sequence')\n",
      "plt.figure(figsize=(12, 6))\n",
      "a1 = plt.subplot(1, 2, 1)\n",
      "plt.bar(range(len(attention_slice)), attention_slice)\n",
      "# 固定x轴\n",
      "plt.xlim(plt.xlim())\n",
      "plt.xlabel('Attention weights')\n",
      "a2 = plt.subplot(1, 2, 2)\n",
      "plt.bar(range(len(attention_slice)), attention_slice)\n",
      "plt.xlabel('Attention weights, zoomed')\n",
      "# 放大结果\n",
      "top = max(a1.get_ylim())\n",
      "zoom = 0.85 * top\n",
      "a2.set_ylim([0.90 * top, top])\n",
      "a1.plot(a1.get_xlim(), [zoom, zoom], color='k')\n",
      "\n",
      "\n",
      "# 输出结果：\n",
      "# [<matplotlib.lines.Line2D at 0x20c356a9670>]\n",
      "# <Figure size 432x288 with 0 Axes>\n",
      "class Decoder(tf.keras.layers.Layer):\n",
      "    def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
      "        super(Decoder, self).__init__()\n",
      "        self.dec_units = dec_units\n",
      "        self.output_vocab_size = output_vocab_size\n",
      "        self.embedding_dim = embedding_dim\n",
      "\n",
      "        # 嵌入层将令牌ID转为向量\n",
      "        self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
      "                                                   embedding_dim)\n",
      "        # RNN会记录到目前为止已经生成的内容。\n",
      "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
      "                                       return_sequences=True,\n",
      "                                       return_state=True,\n",
      "                                       recurrent_initializer='glorot_uniform')\n",
      "        # RNN的输出将是注意力层的查询。\n",
      "        self.attention = BahdanauAttention(self.dec_units)\n",
      "        self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
      "                                        use_bias=False)\n",
      "        self.fc = tf.keras.layers.Dense(self.output_vocab_size)\n",
      "class DecoderInput(typing.NamedTuple):\n",
      "    new_tokens: Any\n",
      "    enc_output: Any\n",
      "    mask: Any\n",
      "\n",
      "\n",
      "class DecoderOutput(typing.NamedTuple):\n",
      "    logits: Any\n",
      "    attention_weights: Any\n",
      "def call(self,\n",
      "         inputs: DecoderInput,\n",
      "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
      "    shape_checker = ShapeChecker()\n",
      "    shape_checker(inputs.new_tokens, ('batch', 't'))\n",
      "    shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n",
      "    shape_checker(inputs.mask, ('batch', 's'))\n",
      "    if state is not None:\n",
      "        shape_checker(state, ('batch', 'dec_units'))\n",
      "    #查询词嵌入\n",
      "    vectors = self.embedding(inputs.new_tokens)\n",
      "    shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n",
      "    #用RNN处理一个步骤\n",
      "    rnn_output, state = self.gru(vectors, initial_state=state)\n",
      "    shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n",
      "    shape_checker(state, ('batch', 'dec_units'))\n",
      "    #使用RNN输出作为关注的查询，超过了编码器的输出。\n",
      "\n",
      "    context_vector, attention_weights = self.attention(\n",
      "        query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
      "    shape_checker(context_vector, ('batch', 't', 'dec_units'))\n",
      "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
      "    # 加入context_vector和rnn_output\n",
      "    context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
      "    attention_vector = self.Wc(context_and_rnn_output)\n",
      "    shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n",
      "    # 生成logit预测\n",
      "    logits = self.fc(attention_vector)\n",
      "    shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n",
      "    return DecoderOutput(logits, attention_weights), state\n",
      "Decoder.call = call\n",
      "decoder = Decoder(output_text_processor.vocabulary_size(),\n",
      "                  embedding_dim, units)\n",
      "#转换目标序列，并收集[START]标记。\n",
      "example_output_tokens = output_text_processor(example_target_batch)\n",
      "start_index = output_text_processor.get_vocabulary().index('[START]')\n",
      "first_token = tf.constant([[start_index]] * example_output_tokens.shape[0])\n",
      "#运行decoder\n",
      "dec_result, dec_state = decoder(\n",
      "    inputs=DecoderInput(new_tokens=first_token,\n",
      "                        enc_output=example_enc_output,\n",
      "                        mask=(example_tokens != 0)),\n",
      "    state=example_enc_state\n",
      ")\n",
      "print(f'logits shape: (batch_size, t, output_vocab_size)'\n",
      "      f'{dec_result.logits.shape}')\n",
      "print(f'state shape: (batch_size, dec_units) {dec_state.shape}')\n",
      "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
      "#将令牌解码为输出的第一个单词。\n",
      "vocab = np.array(output_text_processor.get_vocabulary())\n",
      "first_word = vocab[sampled_token.numpy()]\n",
      "print(first_word[:5])\n",
      "dec_result, dec_state = decoder(\n",
      "    DecoderInput(sampled_token,\n",
      "                 example_enc_output,\n",
      "                 mask=(example_tokens != 0)),\n",
      "    state=dec_state)\n",
      "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
      "first_word = vocab[sampled_token.numpy()]\n",
      "print(first_word[:5])\n",
      "class MaskedLoss(tf.keras.losses.Loss):\n",
      "    def __init__(self):\n",
      "        self.name = 'masked_loss'\n",
      "        self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
      "            from_logits=True, reduction='none')\n",
      "\n",
      "    def __call__(self, y_true, y_pred):\n",
      "        shape_checker = ShapeChecker()\n",
      "        shape_checker(y_true, ('batch', 't'))\n",
      "        shape_checker(y_pred, ('batch', 't', 'logits'))\n",
      "        # 计算该批次中每一项的损失。\n",
      "        loss = self.loss(y_true, y_pred)\n",
      "        shape_checker(loss, ('batch', 't'))\n",
      "        # 屏蔽掉填充物上的损失。\n",
      "        mask = tf.cast(y_true != 0, tf.float32)\n",
      "        shape_checker(mask, ('batch', 't'))\n",
      "        loss *= mask\n",
      "        # 返回总的loss。\n",
      "        return tf.reduce_sum(loss)\n",
      "class TrainTranslator(tf.keras.Model):\n",
      "    def __init__(self, embedding_dim, units,\n",
      "                 input_text_processor,\n",
      "                 output_text_processor,\n",
      "                 use_tf_function=True):\n",
      "        super().__init__()\n",
      "\n",
      "        # 构建编码器和解码器\n",
      "        encoder = Encoder(input_text_processor.vocabulary_size(),\n",
      "                          embedding_dim, units)\n",
      "        decoder = Decoder(output_text_processor.vocabulary_size(),\n",
      "                          embedding_dim, units)\n",
      "        self.encoder = encoder\n",
      "        self.decoder = decoder\n",
      "        self.input_text_processor = input_text_processor\n",
      "        self.output_text_processor = output_text_processor\n",
      "        self.use_tf_function = use_tf_function\n",
      "        self.shape_checker = ShapeChecker()\n",
      "\n",
      "    def train_step(self, inputs):\n",
      "        self.shape_checker = ShapeChecker()\n",
      "\n",
      "        if self.use_tf_function:\n",
      "            return self._tf_train_step(inputs)\n",
      "        else:\n",
      "            return self._train_step(inputs)\n",
      "def _preprocess(self, input_text, target_text):\n",
      "    self.shape_checker(input_text, ('batch',))\n",
      "    self.shape_checker(target_text, ('batch',))\n",
      "    # 将文本转换为tokens ID\n",
      "    input_tokens = self.input_text_processor(input_text)\n",
      "    target_tokens = self.output_text_processor(target_text)\n",
      "    self.shape_checker(input_tokens, ('batch', 's'))\n",
      "    self.shape_checker(target_tokens, ('batch', 't'))\n",
      "    # 将ID转换为掩码\n",
      "    input_mask = input_tokens != 0\n",
      "    self.shape_checker(input_mask, ('batch', 's'))\n",
      "    target_mask = target_tokens != 0\n",
      "\n",
      "    self.shape_checker(target_mask, ('batch', 't'))\n",
      "    return input_tokens, input_mask, target_tokens, target_mask\n",
      "\n",
      "\n",
      "TrainTranslator._preprocess = _preprocess\n",
      "def _train_step(self, inputs):\n",
      "    input_text, target_text = inputs\n",
      "    (input_tokens, input_mask,\n",
      "     target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
      "    max_target_length = tf.shape(target_tokens)[1]\n",
      "    with tf.GradientTape() as tape:\n",
      "        #对输入进行编码\n",
      "        enc_output, enc_state = self.encoder(input_tokens)\n",
      "        self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
      "        self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
      "        #将解码器的状态初始化为编码器的最终状态。\n",
      "        # 这只有在编码器和解码器有相同数量的单位时生效。\n",
      "        dec_state = enc_state\n",
      "        loss = tf.constant(0.0)\n",
      "        for t in tf.range(max_target_length - 1):\n",
      "            #从目标序列中传入两个token:\n",
      "            # 1.解码器的当前输入.\n",
      "            # 2.解码器下次预测的目标.\n",
      "            new_tokens = target_tokens[:, t:t + 2]\n",
      "            step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
      "                                                   enc_output, dec_state)\n",
      "            loss = loss + step_loss\n",
      "        #对所有非填充token的损失进行平均计算。\n",
      "        average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
      "    #设置优化步骤\n",
      "    variables = self.trainable_variables\n",
      "    gradients = tape.gradient(average_loss, variables)\n",
      "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
      "    # 返回一个映射到当前值的字典\n",
      "    return {'batch_loss': average_loss}\n",
      "\n",
      "\n",
      "TrainTranslator._train_step = _train_step\n",
      "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
      "    input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
      "    # Run the decoder one step.\n",
      "    decoder_input = DecoderInput(new_tokens=input_token,\n",
      "                                 enc_output=enc_output,\n",
      "                                 mask=input_mask)\n",
      "    dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
      "    self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
      "    self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
      "    self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
      "    # `self.loss`返回非填充token的总数。\n",
      "    y = target_token\n",
      "    y_pred = dec_result.logits\n",
      "    step_loss = self.loss(y, y_pred)\n",
      "    return step_loss, dec_state\n",
      "TrainTranslator._loop_step = _loop_step\n",
      "\n",
      "translator = TrainTranslator(\n",
      "    embedding_dim, units,\n",
      "    input_text_processor=input_text_processor,\n",
      "    output_text_processor=output_text_processor,\n",
      "    use_tf_function=False)\n",
      "#配置损失和优化器\n",
      "translator.compile(\n",
      "    optimizer=tf.optimizers.Adam(),\n",
      "    loss=MaskedLoss(),\n",
      ")\n",
      "np.log(output_text_processor.vocabulary_size())\n",
      "# 输出结果:\n",
      "# 8.517193191416238\n",
      "get_ipython().run_cell_magic('time', '', \"for n in range(10):\\n    print(translator.train_step([example_input_batch, example_target_batch]))\\nprint()\\n\\n\\n# 输出结果:\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.6101117>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.5797815>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.522971>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.3605533>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.785821>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.0904937>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.8641896>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.3120656>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.264642>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.112561>}\\n\")\n",
      "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
      "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
      "def _tf_train_step(self, inputs):\n",
      "    return self._train_step(inputs)\n",
      "\n",
      "\n",
      "TrainTranslator._tf_train_step = _tf_train_step\n",
      "\n",
      "translator.use_tf_function = True\n",
      "#第一次运行由于需要对函数进行追踪，故速度会比较慢\n",
      "translator.train_step([example_input_batch, example_target_batch])\n",
      "get_ipython().run_cell_magic('time', '', 'for n in range(10):\\n    print(translator.train_step([example_input_batch, example_target_batch]))\\nprint()\\n')\n",
      "losses = []\n",
      "for n in range(100):\n",
      "    print('.', end='')\n",
      "    logs = translator.train_step([example_input_batch, example_target_batch])\n",
      "    losses.append(logs['batch_loss'].numpy())\n",
      "print()\n",
      "plt.plot(losses)\n",
      "# 输出结果:\n",
      "#\n",
      "# [<matplotlib.lines.Line2D at 0x20c362c3c70>]\n",
      "train_translator = TrainTranslator(\n",
      "    embedding_dim, units,\n",
      "    input_text_processor=input_text_processor,\n",
      "    output_text_processor=output_text_processor)\n",
      "# Configure the loss and optimizer\n",
      "train_translator.compile(\n",
      "    optimizer=tf.optimizers.Adam(),\n",
      "    loss=MaskedLoss(),\n",
      ")\n",
      "class BatchLogs(tf.keras.callbacks.Callback):\n",
      "    def __init__(self, key):\n",
      "        self.key = key\n",
      "        self.logs = []\n",
      "\n",
      "    def on_train_batch_end(self, n, logs):\n",
      "        self.logs.append(logs[self.key])\n",
      "\n",
      "\n",
      "batch_loss = BatchLogs('batch_loss')\n",
      "\n",
      "train_translator.fit(dataset, epochs=3,\n",
      "                     steps_per_epoch=3,\n",
      "                     callbacks=[batch_loss])\n",
      "# 如果上一个cell中的epoches和steps_per_epoch过小，此处没有绘图效果。\n",
      "plt.plot(batch_loss.logs)\n",
      "plt.ylim([0, 3])\n",
      "plt.xlabel('Batch #')\n",
      "plt.ylabel('CE/token')\n",
      "class Translator(tf.Module):\n",
      "    def __init__(self, encoder, decoder, input_text_processor,\n",
      "                 output_text_processor):\n",
      "        self.encoder = encoder\n",
      "        self.decoder = decoder\n",
      "        self.input_text_processor = input_text_processor\n",
      "        self.output_text_processor = output_text_processor\n",
      "        self.output_token_string_from_index = (\n",
      "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
      "                vocabulary=output_text_processor.get_vocabulary(),\n",
      "                mask_token='',\n",
      "                invert=True))\n",
      "\n",
      "        # 输出不应该产生padding、unknown或start。\n",
      "        index_from_string = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
      "            vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
      "        token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
      "        token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
      "\n",
      "        token_mask[np.array(token_mask_ids)] = True\n",
      "        self.token_mask = token_mask\n",
      "        self.start_token = index_from_string(tf.constant('[START]'))\n",
      "        self.end_token = index_from_string(tf.constant('[END]'))\n",
      "\n",
      "\n",
      "translator = Translator(\n",
      "    encoder=train_translator.encoder,\n",
      "    decoder=train_translator.decoder,\n",
      "    input_text_processor=input_text_processor,\n",
      "    output_text_processor=output_text_processor,\n",
      ")\n",
      "def tokens_to_text(self, result_tokens):\n",
      "    shape_checker = ShapeChecker()\n",
      "    shape_checker(result_tokens, ('batch', 't'))\n",
      "    result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
      "    shape_checker(result_text_tokens, ('batch', 't'))\n",
      "    result_text = tf.strings.reduce_join(result_text_tokens,\n",
      "                                         axis=1, separator=' ')\n",
      "    shape_checker(result_text, 'batch')\n",
      "    result_text = tf.strings.strip(result_text)\n",
      "    shape_checker(result_text, ('batch',))\n",
      "    return result_text\n",
      "\n",
      "\n",
      "Translator.tokens_to_text = tokens_to_text\n",
      "\n",
      "example_output_tokens = tf.random.uniform(\n",
      "    shape=[5, 2], minval=0, dtype=tf.int64,\n",
      "    maxval=output_text_processor.vocabulary_size())\n",
      "\n",
      "translator.tokens_to_text(example_output_tokens).numpy()\n",
      "def sample(self, logits, temperature):\n",
      "    shape_checker = ShapeChecker()\n",
      "    shape_checker(logits, ('batch', 't', 'vocab'))\n",
      "    shape_checker(self.token_mask, ('vocab',))\n",
      "    token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
      "    shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n",
      "    logits = tf.where(self.token_mask, -np.inf, logits)\n",
      "    if temperature == 0.0:\n",
      "        new_tokens = tf.argmax(logits, axis=-1)\n",
      "    else:\n",
      "        logits = tf.squeeze(logits, axis=1)\n",
      "        new_tokens = tf.random.categorical(logits / temperature,\n",
      "                                           num_samples=1)\n",
      "        shape_checker(new_tokens, ('batch', 't'))\n",
      "        return new_tokens\n",
      "\n",
      "Translator.sample = sample\n",
      "\n",
      "example_logits = tf.random.normal([5, 1,\n",
      "                                   output_text_processor.vocabulary_size()])\n",
      "example_output_tokens = translator.sample(example_logits, temperature=1.0)\n",
      "example_output_tokens\n",
      "def translate_unrolled(self,\n",
      "                       input_text, *,\n",
      "                       max_length=50,\n",
      "                       return_attention=True,\n",
      "                       temperature=1.0):\n",
      "    batch_size = tf.shape(input_text)[0]\n",
      "    input_tokens = self.input_text_processor(input_text)\n",
      "    enc_output, enc_state = self.encoder(input_tokens)\n",
      "    dec_state = enc_state\n",
      "    new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
      "    result_tokens = []\n",
      "    attention = []\n",
      "    done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
      "    for _ in range(max_length):\n",
      "        dec_input = DecoderInput(new_tokens=new_tokens,\n",
      "                                 enc_output=enc_output,\n",
      "                                 mask=(input_tokens != 0))\n",
      "        dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
      "        attention.append(dec_result.attention_weights)\n",
      "        new_tokens = self.sample(dec_result.logits, temperature)\n",
      "        done = done | (new_tokens == self.end_token)\n",
      "        # 一旦一个序列完成，它只产生0-padding。\n",
      "        new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
      "        result_tokens.append(new_tokens)\n",
      "        if tf.executing_eagerly() and tf.reduce_all(done):\n",
      "            break\n",
      "    # 将生成的token id列表转换为字符串列表。\n",
      "\n",
      "    result_tokens = tf.concat(result_tokens, axis=-1)\n",
      "    result_text = self.tokens_to_text(result_tokens)\n",
      "    if return_attention:\n",
      "        attention_stack = tf.concat(attention, axis=1)\n",
      "        return {'text': result_text, 'attention': attention_stack}\n",
      "    else:\n",
      "        return {'text': result_text}\n",
      "Translator.translate = translate_unrolled\n",
      "get_ipython().run_cell_magic('time', '', 'input_text = tf.constant([\\n    \\'hace mucho frio aqui.\\',  # \"It\\'s freezing here.\"\\n    \\'Esta es mi vida.\\',  # \"This is my life.\"\"\\n])\\nresult = translator.translate(\\n    input_text=input_text)\\n\\nprint(result[\\'text\\'][0].numpy().decode())\\nprint(result[\\'text\\'][1].numpy().decode())\\nprint()\\n# 实验结果:\\n# it is very cold here .\\n# this is my life .\\n# Wall time: 266 ms\\n\\n')\n",
      "get_ipython().run_cell_magic('time', '', 'input_text = tf.constant([\\n    \\'hola\\',  # \"It\\'s freezing here.\"\\n    \\'Esta es mi vida.\\',  # \"This is my life.\"\"\\n])\\nresult = translator.translate(\\n    input_text=input_text)\\n\\nprint(result[\\'text\\'][0].numpy().decode())\\nprint(result[\\'text\\'][1].numpy().decode())\\nprint()\\n# 实验结果:\\n# it is very cold here .\\n# this is my life .\\n# Wall time: 266 ms\\n\\n')\n",
      "get_ipython().run_cell_magic('time', '', 'input_text = tf.constant([\\n    \\'hola\\',  # \"It\\'s freezing here.\"\\n    \\'Esta es mi vida.\\',  # \"This is my life.\"\"\\n])\\nresult = translator.translate(\\n    input_text=input_text)\\n\\nprint(result[\\'text\\'][0].numpy().decode())\\nprint(result[\\'text\\'][1].numpy().decode())\\nprint()\\n# 实验结果:\\n# it is very cold here .\\n# this is my life .\\n# Wall time: 266 ms\\n\\n')\n",
      "get_ipython().run_cell_magic('time', '', 'input_text = tf.constant([\\n    \\'hace mucho frio aqui.\\',  # \"It\\'s freezing here.\"\\n    \\'Esta es mi vida.\\',  # \"This is my life.\"\"\\n])\\nresult = translator.translate(\\n    input_text=input_text)\\n\\nprint(result)\\nprint(result[\\'text\\'][0].numpy().decode())\\nprint(result[\\'text\\'][1].numpy().decode())\\nprint()\\n# 实验结果:\\n# it is very cold here .\\n# this is my life .\\n# Wall time: 266 ms\\n\\n')\n",
      "from IPython import get_ipython\n",
      "\n",
      "# 获取当前运行的笔记本\n",
      "notebook = get_ipython().get_ipython().user_ns['In']\n",
      "\n",
      "# 打印所有输入单元格的内容\n",
      "for cell in notebook:\n",
      "    print(cell)\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5520434f3d758c9d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
