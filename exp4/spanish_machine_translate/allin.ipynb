{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:32.313048Z",
     "start_time": "2024-05-01T12:05:32.297903Z"
    }
   },
   "source": [
    "# tensorflow_text, tensorflow, matplotlib\n",
    "import numpy as np\n",
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "import typing\n",
    "from typing import Any, Tuple\n",
    "# Customize types\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "# import preprocess module\n",
    "import tensorflow_text as tf_text\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import os\n",
    "print(\"Available GPUs:\", tf.config.list_physical_devices('GPU'))\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_policy(policy)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:32.811200Z",
     "start_time": "2024-05-01T12:05:32.792548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ShapeChecker:\n",
    "    def __init__(self):\n",
    "        # save every cache\n",
    "        self.shapes = {}\n",
    "\n",
    "    def __call__(self, tensor, names, broadcast=False):\n",
    "        if not tf.executing_eagerly():\n",
    "            return\n",
    "\n",
    "        if isinstance(names, str):\n",
    "            names = (names,)\n",
    "\n",
    "        shape = tf.shape(tensor)\n",
    "        rank = tf.rank(tensor)\n",
    "\n",
    "        if rank != len(names):\n",
    "            raise ValueError(f'Rank mismatch:\\n'\n",
    "                             f'    found {rank}: {shape.numpy()}\\n'\n",
    "                             f'    expected {len(names)}: {names}\\n')\n",
    "\n",
    "        for i, name in enumerate(names):\n",
    "            if isinstance(name, int):\n",
    "                old_dim = name\n",
    "            else:\n",
    "                old_dim = self.shapes.get(name, None)\n",
    "            new_dim = shape[i]\n",
    "\n",
    "            if broadcast and new_dim == 1:\n",
    "                continue\n",
    "\n",
    "            if old_dim is None:\n",
    "                # if the name is new, save it to the cache\n",
    "                self.shapes[name] = new_dim\n",
    "                continue\n",
    "\n",
    "            if new_dim != old_dim:\n",
    "                raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
    "                                 f\"    found: {new_dim}\\n\"\n",
    "                                 f\"    expected: {old_dim}\\n\")\n"
   ],
   "id": "42a9b1393d063af2",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:32.959638Z",
     "start_time": "2024-05-01T12:05:32.883661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download the file\n",
    "import pathlib\n",
    "\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = pathlib.Path(path_to_zip).parent /'spa-eng/spa.txt'\n",
    "print(path_to_file)\n"
   ],
   "id": "485b5de119708900",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zhousc66/.keras/datasets/spa-eng/spa.txt\n"
     ]
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:33.009588Z",
     "start_time": "2024-05-01T12:05:32.997764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def load_data(path):\n",
    "    text = path.read_text(encoding='utf-8')\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    pairs = [line.split('\\t') for line in lines]\n",
    "\n",
    "    inp = [inp for targ, inp in pairs]\n",
    "    targ = [targ for targ, inp in pairs]\n",
    "    # with open('/home/zhousc66/spa.txt', 'w', encoding='utf-8') as f:\n",
    "    #     for i in range(len(inp)):\n",
    "    #         f.write(f\"{targ[i]}\\t{inp[i]}\\n\")\n",
    "\n",
    "    return targ, inp"
   ],
   "id": "5956e97d2c6a4eb8",
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:35.482431Z",
     "start_time": "2024-05-01T12:05:33.132138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "targ, inp = load_data(path_to_file)\n",
    "BUFFER_SIZE = len(inp)\n",
    "BATCH_SIZE = 256\n",
    "# create a tf.data.Dataset string to wash the data and batch it efficiently\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ],
   "id": "4475a6549acef647",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:35.757748Z",
     "start_time": "2024-05-01T12:05:35.484986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for example_input_batch, example_target_batch in dataset.take(1):\n",
    "    print(example_input_batch[:5])\n",
    "    print()\n",
    "    print(example_target_batch[:5])\n",
    "    break\n"
   ],
   "id": "ac17296a84086aed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'Puedo hacer eso si me dejas.'\n",
      " b'\\xc2\\xbfDe qui\\xc3\\xa9n es esta guitarra?' b'Estoy sin bencina.'\n",
      " b'Todos estaban presentes excepto Tom.' b'Estoy en el octavo piso.'], shape=(5,), dtype=string)\n",
      "\n",
      "tf.Tensor(\n",
      "[b'I can do that if you let me.' b'Whose guitar is this?'\n",
      " b\"I'm out of gas.\" b'Everyone except Tom was present.'\n",
      " b\"I'm on the eighth floor.\"], shape=(5,), dtype=string)\n"
     ]
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:35.770462Z",
     "start_time": "2024-05-01T12:05:35.762312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example_text = tf.constant('¿Todavía está en casa?')\n",
    "\n",
    "print(example_text.numpy())\n",
    "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
   ],
   "id": "68b40f0e4e351426",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xc2\\xbfTodav\\xc3\\xada est\\xc3\\xa1 en casa?'\n",
      "b'\\xc2\\xbfTodavi\\xcc\\x81a esta\\xcc\\x81 en casa?'\n"
     ]
    }
   ],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:35.779608Z",
     "start_time": "2024-05-01T12:05:35.773045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tf_lower_and_split_punct(text):\n",
    "    # 对字符进行切分\n",
    "    text = tf_text.normalize_utf8(text, 'NFKD')\n",
    "    text = tf.strings.lower(text)\n",
    "    # 保持空格，从a到z，并选择标点符号。\n",
    "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
    "    # 在标点符号周围添加空格。\n",
    "    text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
    "    # 去空格。\n",
    "    text = tf.strings.strip(text)\n",
    "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
    "    return text"
   ],
   "id": "e7b1bf603f12b66",
   "outputs": [],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:35.788802Z",
     "start_time": "2024-05-01T12:05:35.781529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(example_text.numpy().decode())\n",
    "# 输出解码结果(德语)\n",
    "print(tf_lower_and_split_punct(example_text).numpy().decode())\n",
    "# 对句子进行头尾标注\n",
    "# 输出结果：\n",
    "# ¿Todavía está en casa?\n",
    "# [START] ¿ todavia esta en casa ? [END]"
   ],
   "id": "56aa451228bda03b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Todavía está en casa?\n",
      "[START] ¿ todavia esta en casa ? [END]\n"
     ]
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:35.800227Z",
     "start_time": "2024-05-01T12:05:35.791653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_vocab_size = 5000\n",
    "\n",
    "input_text_processor = preprocessing.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size)"
   ],
   "id": "1e45d49e8b42afe0",
   "outputs": [],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:42.090125Z",
     "start_time": "2024-05-01T12:05:35.801986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_text_processor.adapt(inp)\n",
    "# this is first 10 words in vocabulary\n",
    "print(input_text_processor.get_vocabulary()[:10])"
   ],
   "id": "ba1992dcbd1177aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', '[START]', '[END]', '.', 'que', 'de', 'el', 'a', 'no']\n"
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:48.140963Z",
     "start_time": "2024-05-01T12:05:42.095127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_text_processor = preprocessing.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size)\n",
    "output_text_processor.adapt(targ)\n",
    "print(output_text_processor.get_vocabulary()[:10])"
   ],
   "id": "8a1b40bc6a8a00a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', '[START]', '[END]', '.', 'the', 'i', 'to', 'you', 'tom']\n"
     ]
    }
   ],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:48.165908Z",
     "start_time": "2024-05-01T12:05:48.146293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example_tokens = input_text_processor(example_input_batch)\n",
    "print(example_tokens[:3, :10])"
   ],
   "id": "7ec369b4228b2eeb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[   2   55   54   43   45   18 2790    4    3    0]\n",
      " [   2   13    6   80   15   20  719   12    3    0]\n",
      " [   2   41  139    1    4    3    0    0    0    0]], shape=(3, 10), dtype=int64)\n"
     ]
    }
   ],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:48.197564Z",
     "start_time": "2024-05-01T12:05:48.167729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_vocab = np.array(input_text_processor.get_vocabulary())\n",
    "tokens = input_vocab[example_tokens[0].numpy()]\n",
    "' '.join(tokens)"
   ],
   "id": "91ebdba501f9f30e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[START] puedo hacer eso si me dejas . [END]               '"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:48.571627Z",
     "start_time": "2024-05-01T12:05:48.199406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(example_tokens)\n",
    "plt.title('Token IDs')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(example_tokens != 0)\n",
    "plt.title('Mask')"
   ],
   "id": "94279d9c634fd979",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mask')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:48.577825Z",
     "start_time": "2024-05-01T12:05:48.573695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#嵌入维度\n",
    "embedding_dim = 256\n",
    "#隐藏单元个数\n",
    "units = 1024"
   ],
   "id": "92b008892c8694cc",
   "outputs": [],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:48.592035Z",
     "start_time": "2024-05-01T12:05:48.579805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "        # 嵌入层将令牌转换为向量\n",
    "        self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
    "                                                   embedding_dim)\n",
    "        # GRU RNN层依次处理这些向量。\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, tokens, state=None):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(tokens, ('batch', 's'))\n",
    "        # 嵌入层查找每个标记的嵌入情况。\n",
    "        vectors = self.embedding(tokens)\n",
    "        shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
    "        output, state = self.gru(vectors, initial_state=state)\n",
    "        shape_checker(output, ('batch', 's', 'enc_units'))\n",
    "        shape_checker(state, ('batch', 'enc_units'))\n",
    "        # 返回新的序列和它的状态。\n",
    "        return output, state\n"
   ],
   "id": "33858f34e8e65108",
   "outputs": [],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:48.627066Z",
     "start_time": "2024-05-01T12:05:48.594411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 将输入的文本转换为token。\n",
    "example_tokens = input_text_processor(example_input_batch)\n",
    "# 对输入序列进行编码。\n",
    "encoder = Encoder(input_text_processor.vocabulary_size(),\n",
    "                  embedding_dim, units)\n",
    "example_enc_output, example_enc_state = encoder(example_tokens)\n",
    "print(f'Input batch, shape (batch): {example_input_batch.shape}')\n",
    "print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\n",
    "print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\n",
    "print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')"
   ],
   "id": "d1b80a889960f0bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch, shape (batch): (256,)\n",
      "Input batch tokens, shape (batch, s): (256, 24)\n",
      "Encoder output, shape (batch, s, units): (256, 24, 1024)\n",
      "Encoder state, shape (batch, units): (256, 1024)\n"
     ]
    }
   ],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:48.643803Z",
     "start_time": "2024-05-01T12:05:48.629216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.attention = tf.keras.layers.AdditiveAttention()\n",
    "\n",
    "    def call(self, query, value, mask):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(query, ('batch', 't', 'query_units'))\n",
    "        shape_checker(value, ('batch', 's', 'value_units'))\n",
    "        shape_checker(mask, ('batch', 's'))\n",
    "        # 构建Query矩阵\n",
    "        w1_query = self.W1(query)\n",
    "        shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
    "        # 构建Key矩阵\n",
    "        w2_key = self.W2(value)\n",
    "        shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
    "        # 构建mask矩阵\n",
    "        query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
    "        value_mask = mask\n",
    "        # 计算得到注意力图谱\n",
    "        context_vector, attention_weights = self.attention(\n",
    "            inputs=[w1_query, value, w2_key],\n",
    "            mask=[query_mask, value_mask],\n",
    "            return_attention_scores=True,\n",
    "        )\n",
    "        shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
    "        shape_checker(attention_weights, ('batch', 't', 's'))\n",
    "        return context_vector, attention_weights"
   ],
   "id": "70fd654762f0305",
   "outputs": [],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:48.676346Z",
     "start_time": "2024-05-01T12:05:48.646335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test attention\n",
    "# 创建一个BahdanauAttention层\n",
    "attention_layer = BahdanauAttention(units)\n",
    "# 后续解码器将产生这个attention查询(Query矩阵)\n",
    "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n",
    "# 添加到编码tokens\n",
    "context_vector, attention_weights = attention_layer(\n",
    "    query=example_attention_query,\n",
    "    value=example_enc_output,\n",
    "    mask=(example_tokens != 0))\n",
    "\n",
    "print(f'Attention result shape: (batch_size, query_seq_length, units): {context_vector.shape}')\n",
    "\n",
    "print(f'Attention weights shape: (batch_size, query_seq_length,value_seq_length): {attention_weights.shape}')"
   ],
   "id": "376e9c3e42ba190e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch_size, query_seq_length, units): (256, 2, 1024)\n",
      "Attention weights shape: (batch_size, query_seq_length,value_seq_length): (256, 2, 24)\n"
     ]
    }
   ],
   "execution_count": 142
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:49.019690Z",
     "start_time": "2024-05-01T12:05:48.678721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(attention_weights[:, 0, :])\n",
    "plt.title('Attention weights')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(example_tokens != 0)\n",
    "plt.title('Mask')\n",
    "# 输出结果：\n",
    "# Text(0.5, 1.0, 'Mask')"
   ],
   "id": "99c4dd2e35ab31b9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mask')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "execution_count": 143
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:49.437378Z",
     "start_time": "2024-05-01T12:05:49.021558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#取出部分attention用于展示\n",
    "attention_slice = attention_weights[0, 0].numpy()\n",
    "attention_slice = attention_slice[attention_slice != 0]\n",
    "plt.suptitle('Attention weights for one sequence')\n",
    "plt.figure(figsize=(12, 6))\n",
    "a1 = plt.subplot(1, 2, 1)\n",
    "plt.bar(range(len(attention_slice)), attention_slice)\n",
    "# 固定x轴\n",
    "plt.xlim(plt.xlim())\n",
    "plt.xlabel('Attention weights')\n",
    "a2 = plt.subplot(1, 2, 2)\n",
    "plt.bar(range(len(attention_slice)), attention_slice)\n",
    "plt.xlabel('Attention weights, zoomed')\n",
    "# 放大结果\n",
    "top = max(a1.get_ylim())\n",
    "zoom = 0.85 * top\n",
    "a2.set_ylim([0.90 * top, top])\n",
    "a1.plot(a1.get_xlim(), [zoom, zoom], color='k')\n",
    "\n",
    "\n",
    "# 输出结果：\n",
    "# [<matplotlib.lines.Line2D at 0x20c356a9670>]\n",
    "# <Figure size 432x288 with 0 Axes>"
   ],
   "id": "4099e18f7321e049",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb940798080>]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:49.449275Z",
     "start_time": "2024-05-01T12:05:49.439486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.output_vocab_size = output_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # 嵌入层将令牌ID转为向量\n",
    "        self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
    "                                                   embedding_dim)\n",
    "        # RNN会记录到目前为止已经生成的内容。\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        # RNN的输出将是注意力层的查询。\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "        self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
    "                                        use_bias=False)\n",
    "        self.fc = tf.keras.layers.Dense(self.output_vocab_size)"
   ],
   "id": "b09fb5c11dbc3e3b",
   "outputs": [],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:49.457734Z",
     "start_time": "2024-05-01T12:05:49.451551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DecoderInput(typing.NamedTuple):\n",
    "    new_tokens: Any\n",
    "    enc_output: Any\n",
    "    mask: Any\n",
    "\n",
    "\n",
    "class DecoderOutput(typing.NamedTuple):\n",
    "    logits: Any\n",
    "    attention_weights: Any"
   ],
   "id": "b7895dcff51bc6bd",
   "outputs": [],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:49.475685Z",
     "start_time": "2024-05-01T12:05:49.459936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def call(self,\n",
    "         inputs: DecoderInput,\n",
    "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
    "    shape_checker = ShapeChecker()\n",
    "    shape_checker(inputs.new_tokens, ('batch', 't'))\n",
    "    shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n",
    "    shape_checker(inputs.mask, ('batch', 's'))\n",
    "    if state is not None:\n",
    "        shape_checker(state, ('batch', 'dec_units'))\n",
    "    #查询词嵌入\n",
    "    vectors = self.embedding(inputs.new_tokens)\n",
    "    shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n",
    "    #用RNN处理一个步骤\n",
    "    rnn_output, state = self.gru(vectors, initial_state=state)\n",
    "    shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n",
    "    shape_checker(state, ('batch', 'dec_units'))\n",
    "    #使用RNN输出作为关注的查询，超过了编码器的输出。\n",
    "\n",
    "    context_vector, attention_weights = self.attention(\n",
    "        query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
    "    shape_checker(context_vector, ('batch', 't', 'dec_units'))\n",
    "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
    "    # 加入context_vector和rnn_output\n",
    "    context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
    "    attention_vector = self.Wc(context_and_rnn_output)\n",
    "    shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n",
    "    # 生成logit预测\n",
    "    logits = self.fc(attention_vector)\n",
    "    shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n",
    "    return DecoderOutput(logits, attention_weights), state"
   ],
   "id": "2a090632c7f1f4cc",
   "outputs": [],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:49.500374Z",
     "start_time": "2024-05-01T12:05:49.477657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Decoder.call = call\n",
    "decoder = Decoder(output_text_processor.vocabulary_size(),\n",
    "                  embedding_dim, units)"
   ],
   "id": "6ca491eaa79919bc",
   "outputs": [],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:49.540099Z",
     "start_time": "2024-05-01T12:05:49.508252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#转换目标序列，并收集[START]标记。\n",
    "example_output_tokens = output_text_processor(example_target_batch)\n",
    "start_index = output_text_processor.get_vocabulary().index('[START]')\n",
    "first_token = tf.constant([[start_index]] * example_output_tokens.shape[0])"
   ],
   "id": "8f9d744a6f575879",
   "outputs": [],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:49.587657Z",
     "start_time": "2024-05-01T12:05:49.543324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#运行decoder\n",
    "dec_result, dec_state = decoder(\n",
    "    inputs=DecoderInput(new_tokens=first_token,\n",
    "                        enc_output=example_enc_output,\n",
    "                        mask=(example_tokens != 0)),\n",
    "    state=example_enc_state\n",
    ")\n",
    "print(f'logits shape: (batch_size, t, output_vocab_size)'\n",
    "      f'{dec_result.logits.shape}')\n",
    "print(f'state shape: (batch_size, dec_units) {dec_state.shape}')"
   ],
   "id": "ac8670868f7d900e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape: (batch_size, t, output_vocab_size)(256, 1, 5000)\n",
      "state shape: (batch_size, dec_units) (256, 1024)\n"
     ]
    }
   ],
   "execution_count": 150
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:49.620960Z",
     "start_time": "2024-05-01T12:05:49.589802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
    "#将令牌解码为输出的第一个单词。\n",
    "vocab = np.array(output_text_processor.get_vocabulary())\n",
    "first_word = vocab[sampled_token.numpy()]\n",
    "print(first_word[:5])"
   ],
   "id": "20eaa1a478485039",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['monkey']\n",
      " ['pencil']\n",
      " ['slightly']\n",
      " ['cardboard']\n",
      " ['battery']]\n"
     ]
    }
   ],
   "execution_count": 151
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:49.654928Z",
     "start_time": "2024-05-01T12:05:49.622911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dec_result, dec_state = decoder(\n",
    "    DecoderInput(sampled_token,\n",
    "                 example_enc_output,\n",
    "                 mask=(example_tokens != 0)),\n",
    "    state=dec_state)\n",
    "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
    "first_word = vocab[sampled_token.numpy()]\n",
    "print(first_word[:5])"
   ],
   "id": "d8cb160a6cb9cbe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['shrugged']\n",
      " ['strawberry']\n",
      " ['crack']\n",
      " ['balloon']\n",
      " ['sometime']]\n"
     ]
    }
   ],
   "execution_count": 152
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:49.666571Z",
     "start_time": "2024-05-01T12:05:49.656929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MaskedLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        self.name = 'masked_loss'\n",
    "        self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=True, reduction='none')\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(y_true, ('batch', 't'))\n",
    "        shape_checker(y_pred, ('batch', 't', 'logits'))\n",
    "        # 计算该批次中每一项的损失。\n",
    "        loss = self.loss(y_true, y_pred)\n",
    "        shape_checker(loss, ('batch', 't'))\n",
    "        # 屏蔽掉填充物上的损失。\n",
    "        mask = tf.cast(y_true != 0, tf.float32)\n",
    "        shape_checker(mask, ('batch', 't'))\n",
    "        loss *= mask\n",
    "        # 返回总的loss。\n",
    "        return tf.reduce_sum(loss)"
   ],
   "id": "85110b82afcc49e5",
   "outputs": [],
   "execution_count": 153
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:49.678289Z",
     "start_time": "2024-05-01T12:05:49.668656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TrainTranslator(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, units,\n",
    "                 input_text_processor,\n",
    "                 output_text_processor,\n",
    "                 use_tf_function=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # 构建编码器和解码器\n",
    "        encoder = Encoder(input_text_processor.vocabulary_size(),\n",
    "                          embedding_dim, units)\n",
    "        decoder = Decoder(output_text_processor.vocabulary_size(),\n",
    "                          embedding_dim, units)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.input_text_processor = input_text_processor\n",
    "        self.output_text_processor = output_text_processor\n",
    "        self.use_tf_function = use_tf_function\n",
    "        self.shape_checker = ShapeChecker()\n",
    "\n",
    "    def train_step(self, inputs):\n",
    "        self.shape_checker = ShapeChecker()\n",
    "\n",
    "        if self.use_tf_function:\n",
    "            return self._tf_train_step(inputs)\n",
    "        else:\n",
    "            return self._train_step(inputs)"
   ],
   "id": "ff17f8833ae094f1",
   "outputs": [],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:49.690075Z",
     "start_time": "2024-05-01T12:05:49.680463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _preprocess(self, input_text, target_text):\n",
    "    self.shape_checker(input_text, ('batch',))\n",
    "    self.shape_checker(target_text, ('batch',))\n",
    "    # 将文本转换为tokens ID\n",
    "    input_tokens = self.input_text_processor(input_text)\n",
    "    target_tokens = self.output_text_processor(target_text)\n",
    "    self.shape_checker(input_tokens, ('batch', 's'))\n",
    "    self.shape_checker(target_tokens, ('batch', 't'))\n",
    "    # 将ID转换为掩码\n",
    "    input_mask = input_tokens != 0\n",
    "    self.shape_checker(input_mask, ('batch', 's'))\n",
    "    target_mask = target_tokens != 0\n",
    "\n",
    "    self.shape_checker(target_mask, ('batch', 't'))\n",
    "    return input_tokens, input_mask, target_tokens, target_mask\n",
    "\n",
    "\n",
    "TrainTranslator._preprocess = _preprocess"
   ],
   "id": "b22885ddaad01bde",
   "outputs": [],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:49.705928Z",
     "start_time": "2024-05-01T12:05:49.692626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _train_step(self, inputs):\n",
    "    input_text, target_text = inputs\n",
    "    (input_tokens, input_mask,\n",
    "     target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
    "    max_target_length = tf.shape(target_tokens)[1]\n",
    "    with tf.GradientTape() as tape:\n",
    "        #对输入进行编码\n",
    "        enc_output, enc_state = self.encoder(input_tokens)\n",
    "        self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
    "        self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
    "        #将解码器的状态初始化为编码器的最终状态。\n",
    "        # 这只有在编码器和解码器有相同数量的单位时生效。\n",
    "        dec_state = enc_state\n",
    "        loss = tf.constant(0.0)\n",
    "        for t in tf.range(max_target_length - 1):\n",
    "            #从目标序列中传入两个token:\n",
    "            # 1.解码器的当前输入.\n",
    "            # 2.解码器下次预测的目标.\n",
    "            new_tokens = target_tokens[:, t:t + 2]\n",
    "            step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
    "                                                   enc_output, dec_state)\n",
    "            loss = loss + step_loss\n",
    "        #对所有非填充token的损失进行平均计算。\n",
    "        average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
    "    #设置优化步骤\n",
    "    variables = self.trainable_variables\n",
    "    gradients = tape.gradient(average_loss, variables)\n",
    "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "    # 返回一个映射到当前值的字典\n",
    "    return {'batch_loss': average_loss}\n",
    "\n",
    "\n",
    "TrainTranslator._train_step = _train_step"
   ],
   "id": "1b5e4efe9a0e1199",
   "outputs": [],
   "execution_count": 156
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:49.717298Z",
     "start_time": "2024-05-01T12:05:49.707831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
    "    input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
    "    # Run the decoder one step.\n",
    "    decoder_input = DecoderInput(new_tokens=input_token,\n",
    "                                 enc_output=enc_output,\n",
    "                                 mask=input_mask)\n",
    "    dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
    "    self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
    "    self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
    "    self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
    "    # `self.loss`返回非填充token的总数。\n",
    "    y = target_token\n",
    "    y_pred = dec_result.logits\n",
    "    step_loss = self.loss(y, y_pred)\n",
    "    return step_loss, dec_state"
   ],
   "id": "e465f8ce36d52d36",
   "outputs": [],
   "execution_count": 157
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:49.768351Z",
     "start_time": "2024-05-01T12:05:49.719673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TrainTranslator._loop_step = _loop_step\n",
    "\n",
    "translator = TrainTranslator(\n",
    "    embedding_dim, units,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor,\n",
    "    use_tf_function=False)\n",
    "#配置损失和优化器\n",
    "translator.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss=MaskedLoss(),\n",
    ")"
   ],
   "id": "dc4b406d5021713e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 158
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:49.776876Z",
     "start_time": "2024-05-01T12:05:49.770347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.log(output_text_processor.vocabulary_size())\n",
    "# 输出结果:\n",
    "# 8.517193191416238"
   ],
   "id": "7bf520a8b78487e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.517193191416238"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 159
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:49.943661Z",
     "start_time": "2024-05-01T12:05:49.778979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "for n in range(10):\n",
    "    print(translator.train_step([example_input_batch, example_target_batch]))\n",
    "print()\n",
    "\n",
    "\n",
    "# 输出结果:\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.6101117>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.5797815>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.522971>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.3605533>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.785821>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.0904937>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.8641896>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.3120656>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.264642>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.112561>}"
   ],
   "id": "f3b7de43543b6286",
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Mul as input #1(zero-based) was expected to be a half tensor but is a float tensor [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[0;32m<timed exec>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-154-0f33d8646412>\u001B[0m in \u001B[0;36mtrain_step\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m     24\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_tf_train_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_train_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-156-41a96a4c6af2>\u001B[0m in \u001B[0;36m_train_step\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m     19\u001B[0m             \u001B[0mnew_tokens\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtarget_tokens\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mt\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m             step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n\u001B[0;32m---> 21\u001B[0;31m                                                    enc_output, dec_state)\n\u001B[0m\u001B[1;32m     22\u001B[0m             \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloss\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mstep_loss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m         \u001B[0;31m#对所有非填充token的损失进行平均计算。\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-157-1b6d38c15e26>\u001B[0m in \u001B[0;36m_loop_step\u001B[0;34m(self, new_tokens, input_mask, enc_output, dec_state)\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtarget_token\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0my_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdec_result\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlogits\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m     \u001B[0mstep_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mstep_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdec_state\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-153-d37f6c4cfb8c>\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, y_true, y_pred)\u001B[0m\n\u001B[1;32m     15\u001B[0m         \u001B[0mmask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0mshape_checker\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m'batch'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m't'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m         \u001B[0mloss\u001B[0m \u001B[0;34m*=\u001B[0m \u001B[0mmask\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m         \u001B[0;31m# 返回总的loss。\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreduce_sum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001B[0m in \u001B[0;36mbinary_op_wrapper\u001B[0;34m(x, y)\u001B[0m\n\u001B[1;32m   1365\u001B[0m         \u001B[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1366\u001B[0m         \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmaybe_promote_tensors\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mforce_same_dtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1367\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1368\u001B[0m       \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1369\u001B[0m         \u001B[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001B[0m in \u001B[0;36m_mul_dispatch\u001B[0;34m(x, y, name)\u001B[0m\n\u001B[1;32m   1708\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0msparse_tensor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSparseTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindices\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnew_vals\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdense_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1709\u001B[0m   \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1710\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mmultiply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1711\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1712\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    204\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    205\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 206\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    207\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    208\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001B[0m in \u001B[0;36mmultiply\u001B[0;34m(x, y, name)\u001B[0m\n\u001B[1;32m    528\u001B[0m   \"\"\"\n\u001B[1;32m    529\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 530\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mgen_math_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmul\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    531\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    532\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001B[0m in \u001B[0;36mmul\u001B[0;34m(x, y, name)\u001B[0m\n\u001B[1;32m   6234\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6235\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6236\u001B[0;31m       \u001B[0m_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from_not_ok_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   6237\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_FallbackException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6238\u001B[0m       \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36mraise_from_not_ok_status\u001B[0;34m(e, name)\u001B[0m\n\u001B[1;32m   6939\u001B[0m   \u001B[0mmessage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmessage\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m\" name: \"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6940\u001B[0m   \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6941\u001B[0;31m   \u001B[0msix\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_status_to_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   6942\u001B[0m   \u001B[0;31m# pylint: enable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6943\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/atten/lib/python3.6/site-packages/six.py\u001B[0m in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: cannot compute Mul as input #1(zero-based) was expected to be a half tensor but is a float tensor [Op:Mul]"
     ]
    }
   ],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T12:05:50.930908Z",
     "start_time": "2024-05-01T12:05:49.945499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
    "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
    "def _tf_train_step(self, inputs):\n",
    "    return self._train_step(inputs)\n",
    "\n",
    "\n",
    "TrainTranslator._tf_train_step = _tf_train_step\n",
    "\n",
    "translator.use_tf_function = True\n",
    "#第一次运行由于需要对函数进行追踪，故速度会比较慢\n",
    "translator.train_step([example_input_batch, example_target_batch])"
   ],
   "id": "42fdf1c2de5edb31",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    <ipython-input-40-8e95aa551e08>:4 _tf_train_step  *\n        return self._train_step(inputs)\n    <ipython-input-35-41a96a4c6af2>:20 _train_step  *\n        step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n    <ipython-input-36-1b6d38c15e26>:14 _loop_step  *\n        step_loss = self.loss(y, y_pred)\n    <ipython-input-32-d37f6c4cfb8c>:17 __call__  *\n        loss *= mask\n    /home/zhousc66/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n        raise e\n    /home/zhousc66/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n        return func(x, y, name=name)\n    /home/zhousc66/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:1710 _mul_dispatch\n        return multiply(x, y, name=name)\n    /home/zhousc66/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/zhousc66/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:530 multiply\n        return gen_math_ops.mul(x, y, name)\n    /home/zhousc66/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py:6246 mul\n        \"Mul\", x=x, y=y, name=name)\n    /home/zhousc66/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n        inferred_from[input_arg.type_attr]))\n\n    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-161-8e95aa551e08>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0mtranslator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muse_tf_function\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;31m#第一次运行由于需要对函数进行追踪，故速度会比较慢\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0mtranslator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mexample_input_batch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexample_target_batch\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-154-0f33d8646412>\u001B[0m in \u001B[0;36mtrain_step\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muse_tf_function\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 24\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_tf_train_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     25\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_train_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    883\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    884\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 885\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    886\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    887\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    931\u001B[0m       \u001B[0;31m# This is the first call of __call__, so we have to initialize.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    932\u001B[0m       \u001B[0minitializers\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 933\u001B[0;31m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_initialize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0madd_initializers_to\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minitializers\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    934\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    935\u001B[0m       \u001B[0;31m# At this point we know that the initialization is complete (or less\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_initialize\u001B[0;34m(self, args, kwds, add_initializers_to)\u001B[0m\n\u001B[1;32m    758\u001B[0m     self._concrete_stateful_fn = (\n\u001B[1;32m    759\u001B[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001B[0;32m--> 760\u001B[0;31m             *args, **kwds))\n\u001B[0m\u001B[1;32m    761\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    762\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0minvalid_creator_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0munused_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0munused_kwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_get_concrete_function_internal_garbage_collected\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3064\u001B[0m       \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3065\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3066\u001B[0;31m       \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3067\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3068\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   3461\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3462\u001B[0m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmissed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcall_context_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3463\u001B[0;31m           \u001B[0mgraph_function\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_graph_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3464\u001B[0m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprimary\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcache_key\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3465\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_create_graph_function\u001B[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m   3306\u001B[0m             \u001B[0marg_names\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0marg_names\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3307\u001B[0m             \u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3308\u001B[0;31m             capture_by_value=self._capture_by_value),\n\u001B[0m\u001B[1;32m   3309\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_attributes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3310\u001B[0m         \u001B[0mfunction_spec\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction_spec\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001B[0m\n\u001B[1;32m   1005\u001B[0m         \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moriginal_func\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munwrap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpython_func\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1006\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1007\u001B[0;31m       \u001B[0mfunc_outputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpython_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mfunc_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfunc_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1008\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1009\u001B[0m       \u001B[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36mwrapped_fn\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m    666\u001B[0m         \u001B[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    667\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcompile_with_xla\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 668\u001B[0;31m           \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mweak_wrapped_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    669\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    670\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mbound_method_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   3988\u001B[0m     \u001B[0;31m# However, the replacer is still responsible for attaching self properly.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3989\u001B[0m     \u001B[0;31m# TODO(mdan): Is it possible to do it here instead?\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3990\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mwrapped_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3991\u001B[0m   \u001B[0mweak_bound_method_wrapper\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mweakref\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mref\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbound_method_wrapper\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3992\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    992\u001B[0m           \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint:disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    993\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"ag_error_metadata\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 994\u001B[0;31m               \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    995\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    996\u001B[0m               \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: in user code:\n\n    <ipython-input-40-8e95aa551e08>:4 _tf_train_step  *\n        return self._train_step(inputs)\n    <ipython-input-35-41a96a4c6af2>:20 _train_step  *\n        step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n    <ipython-input-36-1b6d38c15e26>:14 _loop_step  *\n        step_loss = self.loss(y, y_pred)\n    <ipython-input-32-d37f6c4cfb8c>:17 __call__  *\n        loss *= mask\n    /home/zhousc66/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n        raise e\n    /home/zhousc66/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n        return func(x, y, name=name)\n    /home/zhousc66/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:1710 _mul_dispatch\n        return multiply(x, y, name=name)\n    /home/zhousc66/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/zhousc66/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:530 multiply\n        return gen_math_ops.mul(x, y, name)\n    /home/zhousc66/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py:6246 mul\n        \"Mul\", x=x, y=y, name=name)\n    /home/zhousc66/miniconda3/envs/atten/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n        inferred_from[input_arg.type_attr]))\n\n    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.\n"
     ]
    }
   ],
   "execution_count": 161
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "for n in range(10):\n",
    "    print(translator.train_step([example_input_batch, example_target_batch]))\n",
    "print()"
   ],
   "id": "9fe3db5cde852fd6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "losses = []\n",
    "for n in range(100):\n",
    "    print('.', end='')\n",
    "    logs = translator.train_step([example_input_batch, example_target_batch])\n",
    "    losses.append(logs['batch_loss'].numpy())\n",
    "print()\n",
    "plt.plot(losses)\n",
    "# 输出结果:\n",
    "#\n",
    "# [<matplotlib.lines.Line2D at 0x20c362c3c70>]"
   ],
   "id": "19970613f8d38394",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_translator = TrainTranslator(\n",
    "    embedding_dim, units,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor)\n",
    "# Configure the loss and optimizer\n",
    "train_translator.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss=MaskedLoss(),\n",
    ")"
   ],
   "id": "90aa79f7a87dae47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class BatchLogs(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.logs = []\n",
    "\n",
    "    def on_train_batch_end(self, n, logs):\n",
    "        self.logs.append(logs[self.key])\n",
    "\n",
    "\n",
    "batch_loss = BatchLogs('batch_loss')\n",
    "\n",
    "train_translator.fit(dataset, epochs=40,\n",
    "                     # steps_per_epoch=50,\n",
    "                     callbacks=[batch_loss])"
   ],
   "id": "d36e523c918388c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 如果上一个cell中的epoches和steps_per_epoch过小，此处没有绘图效果。\n",
    "plt.plot(batch_loss.logs)\n",
    "plt.ylim([0, 3])\n",
    "plt.xlabel('Batch #')\n",
    "plt.ylabel('CE/token')"
   ],
   "id": "7b6aa847d2c0f673",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Translator(tf.Module):\n",
    "    def __init__(self, encoder, decoder, input_text_processor,\n",
    "                 output_text_processor):\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.input_text_processor = input_text_processor\n",
    "        self.output_text_processor = output_text_processor\n",
    "        self.output_token_string_from_index = (\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=output_text_processor.get_vocabulary(),\n",
    "                mask_token='',\n",
    "                invert=True))\n",
    "\n",
    "        # 输出不应该产生padding、unknown或start。\n",
    "        index_from_string = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "            vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
    "        token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
    "        token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
    "\n",
    "        token_mask[np.array(token_mask_ids)] = True\n",
    "        self.token_mask = token_mask\n",
    "        self.start_token = index_from_string(tf.constant('[START]'))\n",
    "        self.end_token = index_from_string(tf.constant('[END]'))\n",
    "\n",
    "\n",
    "translator = Translator(\n",
    "    encoder=train_translator.encoder,\n",
    "    decoder=train_translator.decoder,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor,\n",
    ")"
   ],
   "id": "2038dd2fdcf63973",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def tokens_to_text(self, result_tokens):\n",
    "    shape_checker = ShapeChecker()\n",
    "    shape_checker(result_tokens, ('batch', 't'))\n",
    "    result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
    "    shape_checker(result_text_tokens, ('batch', 't'))\n",
    "    result_text = tf.strings.reduce_join(result_text_tokens,\n",
    "                                         axis=1, separator=' ')\n",
    "    shape_checker(result_text, 'batch')\n",
    "    result_text = tf.strings.strip(result_text)\n",
    "    shape_checker(result_text, ('batch',))\n",
    "    return result_text\n",
    "\n",
    "\n",
    "Translator.tokens_to_text = tokens_to_text\n",
    "\n",
    "example_output_tokens = tf.random.uniform(\n",
    "    shape=[5, 2], minval=0, dtype=tf.int64,\n",
    "    maxval=output_text_processor.vocabulary_size())\n",
    "\n",
    "translator.tokens_to_text(example_output_tokens).numpy()"
   ],
   "id": "1e1ee7a796c37760",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sample(self, logits, temperature):\n",
    "    shape_checker = ShapeChecker()\n",
    "    shape_checker(logits, ('batch', 't', 'vocab'))\n",
    "    shape_checker(self.token_mask, ('vocab',))\n",
    "    token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
    "    shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n",
    "    logits = tf.where(self.token_mask, -np.inf, logits)\n",
    "    if temperature == 0.0:\n",
    "        new_tokens = tf.argmax(logits, axis=-1)\n",
    "    else:\n",
    "        logits = tf.squeeze(logits, axis=1)\n",
    "        new_tokens = tf.random.categorical(logits / temperature,\n",
    "                                           num_samples=1)\n",
    "        shape_checker(new_tokens, ('batch', 't'))\n",
    "        return new_tokens\n",
    "\n",
    "Translator.sample = sample\n",
    "\n",
    "example_logits = tf.random.normal([5, 1,\n",
    "                                   output_text_processor.vocabulary_size()])\n",
    "example_output_tokens = translator.sample(example_logits, temperature=1.0)\n",
    "example_output_tokens"
   ],
   "id": "128f292dfeb3d484",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def translate_unrolled(self,\n",
    "                       input_text, *,\n",
    "                       max_length=50,\n",
    "                       return_attention=True,\n",
    "                       temperature=1.0):\n",
    "    batch_size = tf.shape(input_text)[0]\n",
    "    input_tokens = self.input_text_processor(input_text)\n",
    "    enc_output, enc_state = self.encoder(input_tokens)\n",
    "    dec_state = enc_state\n",
    "    new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
    "    result_tokens = []\n",
    "    attention = []\n",
    "    done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
    "    for _ in range(max_length):\n",
    "        dec_input = DecoderInput(new_tokens=new_tokens,\n",
    "                                 enc_output=enc_output,\n",
    "                                 mask=(input_tokens != 0))\n",
    "        dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
    "        attention.append(dec_result.attention_weights)\n",
    "        new_tokens = self.sample(dec_result.logits, temperature)\n",
    "        done = done | (new_tokens == self.end_token)\n",
    "        # 一旦一个序列完成，它只产生0-padding。\n",
    "        new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
    "        result_tokens.append(new_tokens)\n",
    "        if tf.executing_eagerly() and tf.reduce_all(done):\n",
    "            break\n",
    "    # 将生成的token id列表转换为字符串列表。\n",
    "\n",
    "    result_tokens = tf.concat(result_tokens, axis=-1)\n",
    "    result_text = self.tokens_to_text(result_tokens)\n",
    "    if return_attention:\n",
    "        attention_stack = tf.concat(attention, axis=1)\n",
    "        return {'text': result_text, 'attention': attention_stack}\n",
    "    else:\n",
    "        return {'text': result_text}"
   ],
   "id": "dadd9bc7fdbf4891",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Translator.translate = translate_unrolled",
   "id": "93752e7e36f8a821",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "input_text = tf.constant([\n",
    "    'hace mucho frio aqui.',  # \"It's freezing here.\"\n",
    "    'Esta es mi vida.',  # \"This is my life.\"\"\n",
    "])\n",
    "result = translator.translate(\n",
    "    input_text=input_text)\n",
    "\n",
    "# print(result)\n",
    "print(result['text'][0].numpy().decode())\n",
    "print(result['text'][1].numpy().decode())\n",
    "print()\n",
    "# 实验结果:\n",
    "# it is very cold here .\n",
    "# this is my life .\n",
    "# Wall time: 266 ms\n"
   ],
   "id": "e69544db06379360",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "# 获取当前运行的笔记本\n",
    "notebook = get_ipython().get_ipython().user_ns['In']\n",
    "\n",
    "# 打印所有输入单元格的内容\n",
    "for cell in notebook:\n",
    "    print(cell)\n"
   ],
   "id": "4eddb182287e1870",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5520434f3d758c9d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
