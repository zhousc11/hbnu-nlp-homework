{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:43.111527Z",
     "start_time": "2024-05-01T09:43:43.100442Z"
    }
   },
   "source": [
    "# tensorflow_text, tensorflow, matplotlib\n",
    "import numpy as np\n",
    "\n",
    "import typing\n",
    "from typing import Any, Tuple\n",
    "# Customize types\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "# import preprocess module\n",
    "import tensorflow_text as tf_text\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:43.399606Z",
     "start_time": "2024-05-01T09:43:43.380410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ShapeChecker:\n",
    "    def __init__(self):\n",
    "        # save every cache\n",
    "        self.shapes = {}\n",
    "\n",
    "    def __call__(self, tensor, names, broadcast=False):\n",
    "        if not tf.executing_eagerly():\n",
    "            return\n",
    "\n",
    "        if isinstance(names, str):\n",
    "            names = (names,)\n",
    "\n",
    "        shape = tf.shape(tensor)\n",
    "        rank = tf.rank(tensor)\n",
    "\n",
    "        if rank != len(names):\n",
    "            raise ValueError(f'Rank mismatch:\\n'\n",
    "                             f'    found {rank}: {shape.numpy()}\\n'\n",
    "                             f'    expected {len(names)}: {names}\\n')\n",
    "\n",
    "        for i, name in enumerate(names):\n",
    "            if isinstance(name, int):\n",
    "                old_dim = name\n",
    "            else:\n",
    "                old_dim = self.shapes.get(name, None)\n",
    "            new_dim = shape[i]\n",
    "\n",
    "            if broadcast and new_dim == 1:\n",
    "                continue\n",
    "\n",
    "            if old_dim is None:\n",
    "                # if the name is new, save it to the cache\n",
    "                self.shapes[name] = new_dim\n",
    "                continue\n",
    "\n",
    "            if new_dim != old_dim:\n",
    "                raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
    "                                 f\"    found: {new_dim}\\n\"\n",
    "                                 f\"    expected: {old_dim}\\n\")\n"
   ],
   "id": "42a9b1393d063af2",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:43.698720Z",
     "start_time": "2024-05-01T09:43:43.621682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download the file\n",
    "import pathlib\n",
    "\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = pathlib.Path(path_to_zip).parent /'spa-eng/spa.txt'\n",
    "print(path_to_file)\n"
   ],
   "id": "485b5de119708900",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zhousc66/.keras/datasets/spa-eng/spa.txt\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:43.725554Z",
     "start_time": "2024-05-01T09:43:43.713164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def load_data(path):\n",
    "    text = path.read_text(encoding='utf-8')\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    pairs = [line.split('\\t') for line in lines]\n",
    "\n",
    "    inp = [inp for targ, inp in pairs]\n",
    "    targ = [targ for targ, inp in pairs]\n",
    "    # with open('/home/zhousc66/spa.txt', 'w', encoding='utf-8') as f:\n",
    "    #     for i in range(len(inp)):\n",
    "    #         f.write(f\"{targ[i]}\\t{inp[i]}\\n\")\n",
    "\n",
    "    return targ, inp"
   ],
   "id": "5956e97d2c6a4eb8",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:46.204932Z",
     "start_time": "2024-05-01T09:43:43.783972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "targ, inp = load_data(path_to_file)\n",
    "BUFFER_SIZE = len(inp)\n",
    "BATCH_SIZE = 64\n",
    "# create a tf.data.Dataset string to wash the data and batch it efficiently\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ],
   "id": "4475a6549acef647",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:46.487390Z",
     "start_time": "2024-05-01T09:43:46.207444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for example_input_batch, example_target_batch in dataset.take(1):\n",
    "    print(example_input_batch[:5])\n",
    "    print()\n",
    "    print(example_target_batch[:5])\n",
    "    break\n"
   ],
   "id": "ac17296a84086aed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'Tiene muchos celos de su mujer.'\n",
      " b'Mi hermana es demasiado peque\\xc3\\xb1a para ir a la escuela.'\n",
      " b'\\xc2\\xbfQu\\xc3\\xa9 es aquello?' b'Fue agradable hablar con usted.'\n",
      " b'Tom no pod\\xc3\\xada decidir qu\\xc3\\xa9 ordenar.'], shape=(5,), dtype=string)\n",
      "\n",
      "tf.Tensor(\n",
      "[b\"He's very jealous of his wife.\"\n",
      " b'My sister is too young to go to school.' b\"What's that there?\"\n",
      " b'Nice talking with you.' b\"Tom couldn't decide what to order.\"], shape=(5,), dtype=string)\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:46.498950Z",
     "start_time": "2024-05-01T09:43:46.491841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example_text = tf.constant('¿Todavía está en casa?')\n",
    "\n",
    "print(example_text.numpy())\n",
    "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
   ],
   "id": "68b40f0e4e351426",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xc2\\xbfTodav\\xc3\\xada est\\xc3\\xa1 en casa?'\n",
      "b'\\xc2\\xbfTodavi\\xcc\\x81a esta\\xcc\\x81 en casa?'\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:46.509598Z",
     "start_time": "2024-05-01T09:43:46.501599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tf_lower_and_split_punct(text):\n",
    "    # 对字符进行切分\n",
    "    text = tf_text.normalize_utf8(text, 'NFKD')\n",
    "    text = tf.strings.lower(text)\n",
    "    # 保持空格，从a到z，并选择标点符号。\n",
    "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
    "    # 在标点符号周围添加空格。\n",
    "    text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
    "    # 去空格。\n",
    "    text = tf.strings.strip(text)\n",
    "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
    "    return text"
   ],
   "id": "e7b1bf603f12b66",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:46.517158Z",
     "start_time": "2024-05-01T09:43:46.511530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(example_text.numpy().decode())\n",
    "# 输出解码结果(德语)\n",
    "print(tf_lower_and_split_punct(example_text).numpy().decode())\n",
    "# 对句子进行头尾标注\n",
    "# 输出结果：\n",
    "# ¿Todavía está en casa?\n",
    "# [START] ¿ todavia esta en casa ? [END]"
   ],
   "id": "56aa451228bda03b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Todavía está en casa?\n",
      "[START] ¿ todavia esta en casa ? [END]\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:46.528089Z",
     "start_time": "2024-05-01T09:43:46.520078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_vocab_size = 5000\n",
    "\n",
    "input_text_processor = preprocessing.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size)"
   ],
   "id": "1e45d49e8b42afe0",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:51.796710Z",
     "start_time": "2024-05-01T09:43:46.529709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_text_processor.adapt(inp)\n",
    "# this is first 10 words in vocabulary\n",
    "print(input_text_processor.get_vocabulary()[:10])"
   ],
   "id": "ba1992dcbd1177aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', '[START]', '[END]', '.', 'que', 'de', 'el', 'a', 'no']\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:56.311416Z",
     "start_time": "2024-05-01T09:43:51.801355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_text_processor = preprocessing.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size)\n",
    "output_text_processor.adapt(targ)\n",
    "print(output_text_processor.get_vocabulary()[:10])"
   ],
   "id": "8a1b40bc6a8a00a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', '[START]', '[END]', '.', 'the', 'i', 'to', 'you', 'tom']\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:56.324470Z",
     "start_time": "2024-05-01T09:43:56.314819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example_tokens = input_text_processor(example_input_batch)\n",
    "print(example_tokens[:3, :10])"
   ],
   "id": "7ec369b4228b2eeb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[   2   44  205    1    6   25  292    4    3    0]\n",
      " [   2   24  280   15  126  644   31   68    8   11]\n",
      " [   2   13    5   15 2693   12    3    0    0    0]], shape=(3, 10), dtype=int64)\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:56.357341Z",
     "start_time": "2024-05-01T09:43:56.326602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_vocab = np.array(input_text_processor.get_vocabulary())\n",
    "tokens = input_vocab[example_tokens[0].numpy()]\n",
    "' '.join(tokens)"
   ],
   "id": "91ebdba501f9f30e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[START] tiene muchos [UNK] de su mujer . [END]       '"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:56.712026Z",
     "start_time": "2024-05-01T09:43:56.359172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(example_tokens)\n",
    "plt.title('Token IDs')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(example_tokens != 0)\n",
    "plt.title('Mask')"
   ],
   "id": "94279d9c634fd979",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mask')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:56.718001Z",
     "start_time": "2024-05-01T09:43:56.714002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#嵌入维度\n",
    "embedding_dim = 256\n",
    "#隐藏单元个数\n",
    "units = 1024"
   ],
   "id": "92b008892c8694cc",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:56.734355Z",
     "start_time": "2024-05-01T09:43:56.720175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "        # 嵌入层将令牌转换为向量\n",
    "        self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
    "                                                   embedding_dim)\n",
    "        # GRU RNN层依次处理这些向量。\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, tokens, state=None):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(tokens, ('batch', 's'))\n",
    "        # 嵌入层查找每个标记的嵌入情况。\n",
    "        vectors = self.embedding(tokens)\n",
    "        shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
    "        output, state = self.gru(vectors, initial_state=state)\n",
    "        shape_checker(output, ('batch', 's', 'enc_units'))\n",
    "        shape_checker(state, ('batch', 'enc_units'))\n",
    "        # 返回新的序列和它的状态。\n",
    "        return output, state\n"
   ],
   "id": "33858f34e8e65108",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:56.845820Z",
     "start_time": "2024-05-01T09:43:56.736123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 将输入的文本转换为token。\n",
    "example_tokens = input_text_processor(example_input_batch)\n",
    "# 对输入序列进行编码。\n",
    "encoder = Encoder(input_text_processor.vocabulary_size(),\n",
    "                  embedding_dim, units)\n",
    "example_enc_output, example_enc_state = encoder(example_tokens)\n",
    "print(f'Input batch, shape (batch): {example_input_batch.shape}')\n",
    "print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\n",
    "print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\n",
    "print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')"
   ],
   "id": "d1b80a889960f0bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch, shape (batch): (64,)\n",
      "Input batch tokens, shape (batch, s): (64, 16)\n",
      "Encoder output, shape (batch, s, units): (64, 16, 1024)\n",
      "Encoder state, shape (batch, units): (64, 1024)\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:56.864546Z",
     "start_time": "2024-05-01T09:43:56.848088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.attention = tf.keras.layers.AdditiveAttention()\n",
    "\n",
    "    def call(self, query, value, mask):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(query, ('batch', 't', 'query_units'))\n",
    "        shape_checker(value, ('batch', 's', 'value_units'))\n",
    "        shape_checker(mask, ('batch', 's'))\n",
    "        # 构建Query矩阵\n",
    "        w1_query = self.W1(query)\n",
    "        shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
    "        # 构建Key矩阵\n",
    "        w2_key = self.W2(value)\n",
    "        shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
    "        # 构建mask矩阵\n",
    "        query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
    "        value_mask = mask\n",
    "        # 计算得到注意力图谱\n",
    "        context_vector, attention_weights = self.attention(\n",
    "            inputs=[w1_query, value, w2_key],\n",
    "            mask=[query_mask, value_mask],\n",
    "            return_attention_scores=True,\n",
    "        )\n",
    "        shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
    "        shape_checker(attention_weights, ('batch', 't', 's'))\n",
    "        return context_vector, attention_weights"
   ],
   "id": "70fd654762f0305",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:56.899101Z",
     "start_time": "2024-05-01T09:43:56.867112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test attention\n",
    "# 创建一个BahdanauAttention层\n",
    "attention_layer = BahdanauAttention(units)\n",
    "# 后续解码器将产生这个attention查询(Query矩阵)\n",
    "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n",
    "# 添加到编码tokens\n",
    "context_vector, attention_weights = attention_layer(\n",
    "    query=example_attention_query,\n",
    "    value=example_enc_output,\n",
    "    mask=(example_tokens != 0))\n",
    "\n",
    "print(f'Attention result shape: (batch_size, query_seq_length, units): {context_vector.shape}')\n",
    "\n",
    "print(f'Attention weights shape: (batch_size, query_seq_length,value_seq_length): {attention_weights.shape}')"
   ],
   "id": "376e9c3e42ba190e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch_size, query_seq_length, units): (64, 2, 1024)\n",
      "Attention weights shape: (batch_size, query_seq_length,value_seq_length): (64, 2, 16)\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:57.223178Z",
     "start_time": "2024-05-01T09:43:56.901166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(attention_weights[:, 0, :])\n",
    "plt.title('Attention weights')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(example_tokens != 0)\n",
    "plt.title('Mask')\n",
    "# 输出结果：\n",
    "# Text(0.5, 1.0, 'Mask')"
   ],
   "id": "99c4dd2e35ab31b9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mask')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:57.635353Z",
     "start_time": "2024-05-01T09:43:57.225185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#取出部分attention用于展示\n",
    "attention_slice = attention_weights[0, 0].numpy()\n",
    "attention_slice = attention_slice[attention_slice != 0]\n",
    "plt.suptitle('Attention weights for one sequence')\n",
    "plt.figure(figsize=(12, 6))\n",
    "a1 = plt.subplot(1, 2, 1)\n",
    "plt.bar(range(len(attention_slice)), attention_slice)\n",
    "# 固定x轴\n",
    "plt.xlim(plt.xlim())\n",
    "plt.xlabel('Attention weights')\n",
    "a2 = plt.subplot(1, 2, 2)\n",
    "plt.bar(range(len(attention_slice)), attention_slice)\n",
    "plt.xlabel('Attention weights, zoomed')\n",
    "# 放大结果\n",
    "top = max(a1.get_ylim())\n",
    "zoom = 0.85 * top\n",
    "a2.set_ylim([0.90 * top, top])\n",
    "a1.plot(a1.get_xlim(), [zoom, zoom], color='k')\n",
    "\n",
    "\n",
    "# 输出结果：\n",
    "# [<matplotlib.lines.Line2D at 0x20c356a9670>]\n",
    "# <Figure size 432x288 with 0 Axes>"
   ],
   "id": "4099e18f7321e049",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f328b8cbb00>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:57.647403Z",
     "start_time": "2024-05-01T09:43:57.637355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.output_vocab_size = output_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # 嵌入层将令牌ID转为向量\n",
    "        self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
    "                                                   embedding_dim)\n",
    "        # RNN会记录到目前为止已经生成的内容。\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        # RNN的输出将是注意力层的查询。\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "        self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
    "                                        use_bias=False)\n",
    "        self.fc = tf.keras.layers.Dense(self.output_vocab_size)"
   ],
   "id": "b09fb5c11dbc3e3b",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:57.655101Z",
     "start_time": "2024-05-01T09:43:57.649466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DecoderInput(typing.NamedTuple):\n",
    "    new_tokens: Any\n",
    "    enc_output: Any\n",
    "    mask: Any\n",
    "\n",
    "\n",
    "class DecoderOutput(typing.NamedTuple):\n",
    "    logits: Any\n",
    "    attention_weights: Any"
   ],
   "id": "b7895dcff51bc6bd",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:57.672846Z",
     "start_time": "2024-05-01T09:43:57.657243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def call(self,\n",
    "         inputs: DecoderInput,\n",
    "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
    "    shape_checker = ShapeChecker()\n",
    "    shape_checker(inputs.new_tokens, ('batch', 't'))\n",
    "    shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n",
    "    shape_checker(inputs.mask, ('batch', 's'))\n",
    "    if state is not None:\n",
    "        shape_checker(state, ('batch', 'dec_units'))\n",
    "    #查询词嵌入\n",
    "    vectors = self.embedding(inputs.new_tokens)\n",
    "    shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n",
    "    #用RNN处理一个步骤\n",
    "    rnn_output, state = self.gru(vectors, initial_state=state)\n",
    "    shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n",
    "    shape_checker(state, ('batch', 'dec_units'))\n",
    "    #使用RNN输出作为关注的查询，超过了编码器的输出。\n",
    "\n",
    "    context_vector, attention_weights = self.attention(\n",
    "        query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
    "    shape_checker(context_vector, ('batch', 't', 'dec_units'))\n",
    "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
    "    # 加入context_vector和rnn_output\n",
    "    context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
    "    attention_vector = self.Wc(context_and_rnn_output)\n",
    "    shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n",
    "    # 生成logit预测\n",
    "    logits = self.fc(attention_vector)\n",
    "    shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n",
    "    return DecoderOutput(logits, attention_weights), state"
   ],
   "id": "2a090632c7f1f4cc",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:57.696833Z",
     "start_time": "2024-05-01T09:43:57.674841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Decoder.call = call\n",
    "decoder = Decoder(output_text_processor.vocabulary_size(),\n",
    "                  embedding_dim, units)"
   ],
   "id": "6ca491eaa79919bc",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:57.732294Z",
     "start_time": "2024-05-01T09:43:57.704301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#转换目标序列，并收集[START]标记。\n",
    "example_output_tokens = output_text_processor(example_target_batch)\n",
    "start_index = output_text_processor.get_vocabulary().index('[START]')\n",
    "first_token = tf.constant([[start_index]] * example_output_tokens.shape[0])"
   ],
   "id": "8f9d744a6f575879",
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:57.809018Z",
     "start_time": "2024-05-01T09:43:57.735538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#运行decoder\n",
    "dec_result, dec_state = decoder(\n",
    "    inputs=DecoderInput(new_tokens=first_token,\n",
    "                        enc_output=example_enc_output,\n",
    "                        mask=(example_tokens != 0)),\n",
    "    state=example_enc_state\n",
    ")\n",
    "print(f'logits shape: (batch_size, t, output_vocab_size)'\n",
    "      f'{dec_result.logits.shape}')\n",
    "print(f'state shape: (batch_size, dec_units) {dec_state.shape}')"
   ],
   "id": "ac8670868f7d900e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape: (batch_size, t, output_vocab_size)(64, 1, 5000)\n",
      "state shape: (batch_size, dec_units) (64, 1024)\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:57.842488Z",
     "start_time": "2024-05-01T09:43:57.811137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
    "#将令牌解码为输出的第一个单词。\n",
    "vocab = np.array(output_text_processor.get_vocabulary())\n",
    "first_word = vocab[sampled_token.numpy()]\n",
    "print(first_word[:5])"
   ],
   "id": "20eaa1a478485039",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['release']\n",
      " ['understands']\n",
      " ['each']\n",
      " ['filipino']\n",
      " ['neighbor']]\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:57.896287Z",
     "start_time": "2024-05-01T09:43:57.845950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dec_result, dec_state = decoder(\n",
    "    DecoderInput(sampled_token,\n",
    "                 example_enc_output,\n",
    "                 mask=(example_tokens != 0)),\n",
    "    state=dec_state)\n",
    "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
    "first_word = vocab[sampled_token.numpy()]\n",
    "print(first_word[:5])"
   ],
   "id": "d8cb160a6cb9cbe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['leaks']\n",
      " ['harsh']\n",
      " ['hes']\n",
      " ['restaurant']\n",
      " ['ourselves']]\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:57.909311Z",
     "start_time": "2024-05-01T09:43:57.898609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MaskedLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        self.name = 'masked_loss'\n",
    "        self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=True, reduction='none')\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(y_true, ('batch', 't'))\n",
    "        shape_checker(y_pred, ('batch', 't', 'logits'))\n",
    "        # 计算该批次中每一项的损失。\n",
    "        loss = self.loss(y_true, y_pred)\n",
    "        shape_checker(loss, ('batch', 't'))\n",
    "        # 屏蔽掉填充物上的损失。\n",
    "        mask = tf.cast(y_true != 0, tf.float32)\n",
    "        shape_checker(mask, ('batch', 't'))\n",
    "        loss *= mask\n",
    "        # 返回总的loss。\n",
    "        return tf.reduce_sum(loss)"
   ],
   "id": "85110b82afcc49e5",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:57.921931Z",
     "start_time": "2024-05-01T09:43:57.911750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TrainTranslator(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, units,\n",
    "                 input_text_processor,\n",
    "                 output_text_processor,\n",
    "                 use_tf_function=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # 构建编码器和解码器\n",
    "        encoder = Encoder(input_text_processor.vocabulary_size(),\n",
    "                          embedding_dim, units)\n",
    "        decoder = Decoder(output_text_processor.vocabulary_size(),\n",
    "                          embedding_dim, units)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.input_text_processor = input_text_processor\n",
    "        self.output_text_processor = output_text_processor\n",
    "        self.use_tf_function = use_tf_function\n",
    "        self.shape_checker = ShapeChecker()\n",
    "\n",
    "    def train_step(self, inputs):\n",
    "        self.shape_checker = ShapeChecker()\n",
    "\n",
    "        if self.use_tf_function:\n",
    "            return self._tf_train_step(inputs)\n",
    "        else:\n",
    "            return self._train_step(inputs)"
   ],
   "id": "ff17f8833ae094f1",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:57.933235Z",
     "start_time": "2024-05-01T09:43:57.923725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _preprocess(self, input_text, target_text):\n",
    "    self.shape_checker(input_text, ('batch',))\n",
    "    self.shape_checker(target_text, ('batch',))\n",
    "    # 将文本转换为tokens ID\n",
    "    input_tokens = self.input_text_processor(input_text)\n",
    "    target_tokens = self.output_text_processor(target_text)\n",
    "    self.shape_checker(input_tokens, ('batch', 's'))\n",
    "    self.shape_checker(target_tokens, ('batch', 't'))\n",
    "    # 将ID转换为掩码\n",
    "    input_mask = input_tokens != 0\n",
    "    self.shape_checker(input_mask, ('batch', 's'))\n",
    "    target_mask = target_tokens != 0\n",
    "\n",
    "    self.shape_checker(target_mask, ('batch', 't'))\n",
    "    return input_tokens, input_mask, target_tokens, target_mask\n",
    "\n",
    "\n",
    "TrainTranslator._preprocess = _preprocess"
   ],
   "id": "b22885ddaad01bde",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:57.948815Z",
     "start_time": "2024-05-01T09:43:57.934983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _train_step(self, inputs):\n",
    "    input_text, target_text = inputs\n",
    "    (input_tokens, input_mask,\n",
    "     target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
    "    max_target_length = tf.shape(target_tokens)[1]\n",
    "    with tf.GradientTape() as tape:\n",
    "        #对输入进行编码\n",
    "        enc_output, enc_state = self.encoder(input_tokens)\n",
    "        self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
    "        self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
    "        #将解码器的状态初始化为编码器的最终状态。\n",
    "        # 这只有在编码器和解码器有相同数量的单位时生效。\n",
    "        dec_state = enc_state\n",
    "        loss = tf.constant(0.0)\n",
    "        for t in tf.range(max_target_length - 1):\n",
    "            #从目标序列中传入两个token:\n",
    "            # 1.解码器的当前输入.\n",
    "            # 2.解码器下次预测的目标.\n",
    "            new_tokens = target_tokens[:, t:t + 2]\n",
    "            step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
    "                                                   enc_output, dec_state)\n",
    "            loss = loss + step_loss\n",
    "        #对所有非填充token的损失进行平均计算。\n",
    "        average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
    "    #设置优化步骤\n",
    "    variables = self.trainable_variables\n",
    "    gradients = tape.gradient(average_loss, variables)\n",
    "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "    # 返回一个映射到当前值的字典\n",
    "    return {'batch_loss': average_loss}\n",
    "\n",
    "\n",
    "TrainTranslator._train_step = _train_step"
   ],
   "id": "1b5e4efe9a0e1199",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:57.959777Z",
     "start_time": "2024-05-01T09:43:57.950517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
    "    input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
    "    # Run the decoder one step.\n",
    "    decoder_input = DecoderInput(new_tokens=input_token,\n",
    "                                 enc_output=enc_output,\n",
    "                                 mask=input_mask)\n",
    "    dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
    "    self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
    "    self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
    "    self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
    "    # `self.loss`返回非填充token的总数。\n",
    "    y = target_token\n",
    "    y_pred = dec_result.logits\n",
    "    step_loss = self.loss(y, y_pred)\n",
    "    return step_loss, dec_state"
   ],
   "id": "e465f8ce36d52d36",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:58.006850Z",
     "start_time": "2024-05-01T09:43:57.961488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TrainTranslator._loop_step = _loop_step\n",
    "\n",
    "translator = TrainTranslator(\n",
    "    embedding_dim, units,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor,\n",
    "    use_tf_function=False)\n",
    "#配置损失和优化器\n",
    "translator.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss=MaskedLoss(),\n",
    ")"
   ],
   "id": "dc4b406d5021713e",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:43:58.014976Z",
     "start_time": "2024-05-01T09:43:58.008947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.log(output_text_processor.vocabulary_size())\n",
    "# 输出结果:\n",
    "# 8.517193191416238"
   ],
   "id": "7bf520a8b78487e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.517193191416238"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:44:11.905009Z",
     "start_time": "2024-05-01T09:43:58.017101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "for n in range(10):\n",
    "    print(translator.train_step([example_input_batch, example_target_batch]))\n",
    "print()\n",
    "\n",
    "\n",
    "# 输出结果:\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.6101117>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.5797815>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.522971>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.3605533>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.785821>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.0904937>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.8641896>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.3120656>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.264642>}\n",
    "# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.112561>}"
   ],
   "id": "f3b7de43543b6286",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.5950165>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.565028>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.5088153>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.349754>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.805463>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.2475924>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.945118>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.543022>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.3282876>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.101766>}\n",
      "\n",
      "CPU times: user 2min 53s, sys: 42.5 s, total: 3min 35s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:44:17.147332Z",
     "start_time": "2024-05-01T09:44:11.907265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
    "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
    "def _tf_train_step(self, inputs):\n",
    "    return self._train_step(inputs)\n",
    "\n",
    "\n",
    "TrainTranslator._tf_train_step = _tf_train_step\n",
    "\n",
    "translator.use_tf_function = True\n",
    "#第一次运行由于需要对函数进行追踪，故速度会比较慢\n",
    "translator.train_step([example_input_batch, example_target_batch])"
   ],
   "id": "42fdf1c2de5edb31",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.9866855>}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:44:21.473782Z",
     "start_time": "2024-05-01T09:44:17.149651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "for n in range(10):\n",
    "    print(translator.train_step([example_input_batch, example_target_batch]))\n",
    "print()"
   ],
   "id": "9fe3db5cde852fd6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.0140643>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.029606>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.9476018>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.8669016>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.8145373>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.76592>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.6985269>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.6646805>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.6396337>}\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.587369>}\n",
      "\n",
      "CPU times: user 2min 53s, sys: 19.3 s, total: 3min 12s\n",
      "Wall time: 4.32 s\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:45:04.081423Z",
     "start_time": "2024-05-01T09:44:21.476209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "losses = []\n",
    "for n in range(100):\n",
    "    print('.', end='')\n",
    "    logs = translator.train_step([example_input_batch, example_target_batch])\n",
    "    losses.append(logs['batch_loss'].numpy())\n",
    "print()\n",
    "plt.plot(losses)\n",
    "# 输出结果:\n",
    "#\n",
    "# [<matplotlib.lines.Line2D at 0x20c362c3c70>]"
   ],
   "id": "19970613f8d38394",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f316870bc18>]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:45:04.118013Z",
     "start_time": "2024-05-01T09:45:04.084125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_translator = TrainTranslator(\n",
    "    embedding_dim, units,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor)\n",
    "# Configure the loss and optimizer\n",
    "train_translator.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss=MaskedLoss(),\n",
    ")"
   ],
   "id": "90aa79f7a87dae47",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:45:16.475061Z",
     "start_time": "2024-05-01T09:45:04.120078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BatchLogs(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.logs = []\n",
    "\n",
    "    def on_train_batch_end(self, n, logs):\n",
    "        self.logs.append(logs[self.key])\n",
    "\n",
    "\n",
    "batch_loss = BatchLogs('batch_loss')\n",
    "\n",
    "train_translator.fit(dataset, epochs=50,\n",
    "                     steps_per_epoch=50,\n",
    "                     callbacks=[batch_loss])"
   ],
   "id": "d36e523c918388c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3/3 [==============================] - 9s 526ms/step - batch_loss: 7.5632\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 2s 578ms/step - batch_loss: 6.4422\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 2s 541ms/step - batch_loss: 5.1057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f31c8528d68>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:45:16.699712Z",
     "start_time": "2024-05-01T09:45:16.477558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 如果上一个cell中的epoches和steps_per_epoch过小，此处没有绘图效果。\n",
    "plt.plot(batch_loss.logs)\n",
    "plt.ylim([0, 3])\n",
    "plt.xlabel('Batch #')\n",
    "plt.ylabel('CE/token')"
   ],
   "id": "7b6aa847d2c0f673",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'CE/token')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:45:17.053528Z",
     "start_time": "2024-05-01T09:45:16.701690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Translator(tf.Module):\n",
    "    def __init__(self, encoder, decoder, input_text_processor,\n",
    "                 output_text_processor):\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.input_text_processor = input_text_processor\n",
    "        self.output_text_processor = output_text_processor\n",
    "        self.output_token_string_from_index = (\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=output_text_processor.get_vocabulary(),\n",
    "                mask_token='',\n",
    "                invert=True))\n",
    "\n",
    "        # 输出不应该产生padding、unknown或start。\n",
    "        index_from_string = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "            vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
    "        token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
    "        token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
    "\n",
    "        token_mask[np.array(token_mask_ids)] = True\n",
    "        self.token_mask = token_mask\n",
    "        self.start_token = index_from_string(tf.constant('[START]'))\n",
    "        self.end_token = index_from_string(tf.constant('[END]'))\n",
    "\n",
    "\n",
    "translator = Translator(\n",
    "    encoder=train_translator.encoder,\n",
    "    decoder=train_translator.decoder,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor,\n",
    ")"
   ],
   "id": "2038dd2fdcf63973",
   "outputs": [],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:45:17.085013Z",
     "start_time": "2024-05-01T09:45:17.057468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokens_to_text(self, result_tokens):\n",
    "    shape_checker = ShapeChecker()\n",
    "    shape_checker(result_tokens, ('batch', 't'))\n",
    "    result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
    "    shape_checker(result_text_tokens, ('batch', 't'))\n",
    "    result_text = tf.strings.reduce_join(result_text_tokens,\n",
    "                                         axis=1, separator=' ')\n",
    "    shape_checker(result_text, 'batch')\n",
    "    result_text = tf.strings.strip(result_text)\n",
    "    shape_checker(result_text, ('batch',))\n",
    "    return result_text\n",
    "\n",
    "\n",
    "Translator.tokens_to_text = tokens_to_text\n",
    "\n",
    "example_output_tokens = tf.random.uniform(\n",
    "    shape=[5, 2], minval=0, dtype=tf.int64,\n",
    "    maxval=output_text_processor.vocabulary_size())\n",
    "\n",
    "translator.tokens_to_text(example_output_tokens).numpy()"
   ],
   "id": "1e1ee7a796c37760",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'sapporo miles', b'weak arrive', b'spying oath', b'nap march',\n",
       "       b'exist build'], dtype=object)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:45:17.107928Z",
     "start_time": "2024-05-01T09:45:17.087530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sample(self, logits, temperature):\n",
    "    shape_checker = ShapeChecker()\n",
    "    shape_checker(logits, ('batch', 't', 'vocab'))\n",
    "    shape_checker(self.token_mask, ('vocab',))\n",
    "    token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
    "    shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n",
    "    logits = tf.where(self.token_mask, -np.inf, logits)\n",
    "    if temperature == 0.0:\n",
    "        new_tokens = tf.argmax(logits, axis=-1)\n",
    "    else:\n",
    "        logits = tf.squeeze(logits, axis=1)\n",
    "        new_tokens = tf.random.categorical(logits / temperature,\n",
    "                                           num_samples=1)\n",
    "        shape_checker(new_tokens, ('batch', 't'))\n",
    "        return new_tokens\n",
    "\n",
    "Translator.sample = sample\n",
    "\n",
    "example_logits = tf.random.normal([5, 1,\n",
    "                                   output_text_processor.vocabulary_size()])\n",
    "example_output_tokens = translator.sample(example_logits, temperature=1.0)\n",
    "example_output_tokens"
   ],
   "id": "128f292dfeb3d484",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
       "array([[1360],\n",
       "       [2479],\n",
       "       [ 873],\n",
       "       [1542],\n",
       "       [ 181]])>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:45:17.125985Z",
     "start_time": "2024-05-01T09:45:17.109831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def translate_unrolled(self,\n",
    "                       input_text, *,\n",
    "                       max_length=50,\n",
    "                       return_attention=True,\n",
    "                       temperature=1.0):\n",
    "    batch_size = tf.shape(input_text)[0]\n",
    "    input_tokens = self.input_text_processor(input_text)\n",
    "    enc_output, enc_state = self.encoder(input_tokens)\n",
    "    dec_state = enc_state\n",
    "    new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
    "    result_tokens = []\n",
    "    attention = []\n",
    "    done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
    "    for _ in range(max_length):\n",
    "        dec_input = DecoderInput(new_tokens=new_tokens,\n",
    "                                 enc_output=enc_output,\n",
    "                                 mask=(input_tokens != 0))\n",
    "        dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
    "        attention.append(dec_result.attention_weights)\n",
    "        new_tokens = self.sample(dec_result.logits, temperature)\n",
    "        done = done | (new_tokens == self.end_token)\n",
    "        # 一旦一个序列完成，它只产生0-padding。\n",
    "        new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
    "        result_tokens.append(new_tokens)\n",
    "        if tf.executing_eagerly() and tf.reduce_all(done):\n",
    "            break\n",
    "    # 将生成的token id列表转换为字符串列表。\n",
    "\n",
    "    result_tokens = tf.concat(result_tokens, axis=-1)\n",
    "    result_text = self.tokens_to_text(result_tokens)\n",
    "    if return_attention:\n",
    "        attention_stack = tf.concat(attention, axis=1)\n",
    "        return {'text': result_text, 'attention': attention_stack}\n",
    "    else:\n",
    "        return {'text': result_text}"
   ],
   "id": "dadd9bc7fdbf4891",
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:45:17.132569Z",
     "start_time": "2024-05-01T09:45:17.128168Z"
    }
   },
   "cell_type": "code",
   "source": "Translator.translate = translate_unrolled",
   "id": "93752e7e36f8a821",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:45:18.381187Z",
     "start_time": "2024-05-01T09:45:17.134423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "input_text = tf.constant([\n",
    "    'hace mucho frio aqui.',  # \"It's freezing here.\"\n",
    "    'Esta es mi vida.',  # \"This is my life.\"\"\n",
    "])\n",
    "result = translator.translate(\n",
    "    input_text=input_text)\n",
    "\n",
    "# print(result)\n",
    "print(result['text'][0].numpy().decode())\n",
    "print(result['text'][1].numpy().decode())\n",
    "print()\n",
    "# 实验结果:\n",
    "# it is very cold here .\n",
    "# this is my life .\n",
    "# Wall time: 266 ms\n"
   ],
   "id": "e69544db06379360",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denied volunteer would happy vacant ignored simpler tidy mary other boy dont gang problems something like have each goats her contest passport the rate french interrupt you came ? relative we that in mary teacher fun . this up we\n",
      "after asking private reservation sushi count which fairly store ears trees bells shoulder brother are hardly is youre kissing many when born is sorrow i answer long she for lies want ? mahjong is him\n",
      "\n",
      "CPU times: user 1.91 s, sys: 24.3 ms, total: 1.94 s\n",
      "Wall time: 1.24 s\n"
     ]
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:45:18.421674Z",
     "start_time": "2024-05-01T09:45:18.383443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "# 获取当前运行的笔记本\n",
    "notebook = get_ipython().get_ipython().user_ns['In']\n",
    "\n",
    "# 打印所有输入单元格的内容\n",
    "for cell in notebook:\n",
    "    print(cell)\n"
   ],
   "id": "4eddb182287e1870",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# tensorflow_text, tensorflow, matplotlib\n",
      "import numpy as np\n",
      "\n",
      "import typing\n",
      "from typing import Any, Tuple\n",
      "# Customize types\n",
      "import tensorflow as tf\n",
      "from tensorflow.keras.layers.experimental import preprocessing\n",
      "# import preprocess module\n",
      "import tensorflow_text as tf_text\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.ticker as ticker\n",
      "class ShapeChecker:\n",
      "    def __init__(self):\n",
      "        # save every cache\n",
      "        self.shapes = {}\n",
      "\n",
      "    def __call__(self, tensor, names, broadcast=False):\n",
      "        if not tf.executing_eagerly():\n",
      "            return\n",
      "\n",
      "        if isinstance(names, str):\n",
      "            names = (names,)\n",
      "\n",
      "        shape = tf.shape(tensor)\n",
      "        rank = tf.rank(tensor)\n",
      "\n",
      "        if rank != len(names):\n",
      "            raise ValueError(f'Rank mismatch:\\n'\n",
      "                             f'    found {rank}: {shape.numpy()}\\n'\n",
      "                             f'    expected {len(names)}: {names}\\n')\n",
      "\n",
      "        for i, name in enumerate(names):\n",
      "            if isinstance(name, int):\n",
      "                old_dim = name\n",
      "            else:\n",
      "                old_dim = self.shapes.get(name, None)\n",
      "            new_dim = shape[i]\n",
      "\n",
      "            if broadcast and new_dim == 1:\n",
      "                continue\n",
      "\n",
      "            if old_dim is None:\n",
      "                # if the name is new, save it to the cache\n",
      "                self.shapes[name] = new_dim\n",
      "                continue\n",
      "\n",
      "            if new_dim != old_dim:\n",
      "                raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
      "                                 f\"    found: {new_dim}\\n\"\n",
      "                                 f\"    expected: {old_dim}\\n\")\n",
      "# Download the file\n",
      "import pathlib\n",
      "\n",
      "path_to_zip = tf.keras.utils.get_file(\n",
      "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
      "    extract=True)\n",
      "\n",
      "path_to_file = pathlib.Path(path_to_zip).parent /'spa-eng/spa.txt'\n",
      "print(path_to_file)\n",
      "def load_data(path):\n",
      "    text = path.read_text(encoding='utf-8')\n",
      "\n",
      "    lines = text.splitlines()\n",
      "    pairs = [line.split('\\t') for line in lines]\n",
      "\n",
      "    inp = [inp for targ, inp in pairs]\n",
      "    targ = [targ for targ, inp in pairs]\n",
      "\n",
      "    return targ, inp\n",
      "targ, inp = load_data(path_to_file)\n",
      "BUFFER_SIZE = len(inp)\n",
      "BATCH_SIZE = 64\n",
      "# create a tf.data.Dataset string to wash the data and batch it efficiently\n",
      "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
      "dataset = dataset.batch(BATCH_SIZE)\n",
      "def tf_lower_and_split_punct(text):\n",
      "    # 对字符进行切分\n",
      "    text = tf_text.normalize_utf8(text, 'NFKD')\n",
      "    text = tf.strings.lower(text)\n",
      "    # 保持空格，从a到z，并选择标点符号。\n",
      "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
      "    # 在标点符号周围添加空格。\n",
      "    text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
      "    # 去空格。\n",
      "    text = tf.strings.strip(text)\n",
      "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
      "    return text\n",
      "# tensorflow_text, tensorflow, matplotlib\n",
      "import numpy as np\n",
      "\n",
      "import typing\n",
      "from typing import Any, Tuple\n",
      "# Customize types\n",
      "import tensorflow as tf\n",
      "from tensorflow.keras.layers.experimental import preprocessing\n",
      "# import preprocess module\n",
      "import tensorflow_text as tf_text\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.ticker as ticker\n",
      "class ShapeChecker:\n",
      "    def __init__(self):\n",
      "        # save every cache\n",
      "        self.shapes = {}\n",
      "\n",
      "    def __call__(self, tensor, names, broadcast=False):\n",
      "        if not tf.executing_eagerly():\n",
      "            return\n",
      "\n",
      "        if isinstance(names, str):\n",
      "            names = (names,)\n",
      "\n",
      "        shape = tf.shape(tensor)\n",
      "        rank = tf.rank(tensor)\n",
      "\n",
      "        if rank != len(names):\n",
      "            raise ValueError(f'Rank mismatch:\\n'\n",
      "                             f'    found {rank}: {shape.numpy()}\\n'\n",
      "                             f'    expected {len(names)}: {names}\\n')\n",
      "\n",
      "        for i, name in enumerate(names):\n",
      "            if isinstance(name, int):\n",
      "                old_dim = name\n",
      "            else:\n",
      "                old_dim = self.shapes.get(name, None)\n",
      "            new_dim = shape[i]\n",
      "\n",
      "            if broadcast and new_dim == 1:\n",
      "                continue\n",
      "\n",
      "            if old_dim is None:\n",
      "                # if the name is new, save it to the cache\n",
      "                self.shapes[name] = new_dim\n",
      "                continue\n",
      "\n",
      "            if new_dim != old_dim:\n",
      "                raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
      "                                 f\"    found: {new_dim}\\n\"\n",
      "                                 f\"    expected: {old_dim}\\n\")\n",
      "# Download the file\n",
      "import pathlib\n",
      "\n",
      "path_to_zip = tf.keras.utils.get_file(\n",
      "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
      "    extract=True)\n",
      "\n",
      "path_to_file = pathlib.Path(path_to_zip).parent /'spa-eng/spa.txt'\n",
      "print(path_to_file)\n",
      "def load_data(path):\n",
      "    text = path.read_text(encoding='utf-8')\n",
      "\n",
      "    lines = text.splitlines()\n",
      "    pairs = [line.split('\\t') for line in lines]\n",
      "\n",
      "    inp = [inp for targ, inp in pairs]\n",
      "    targ = [targ for targ, inp in pairs]\n",
      "\n",
      "    return targ, inp\n",
      "targ, inp = load_data(path_to_file)\n",
      "BUFFER_SIZE = len(inp)\n",
      "BATCH_SIZE = 64\n",
      "# create a tf.data.Dataset string to wash the data and batch it efficiently\n",
      "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
      "dataset = dataset.batch(BATCH_SIZE)\n",
      "for example_input_batch, example_target_batch in dataset.take(1):\n",
      "    print(example_input_batch[:5])\n",
      "    print()\n",
      "    print(example_target_batch[:5])\n",
      "    break\n",
      "example_text = tf.constant('¿Todavía está en casa?')\n",
      "\n",
      "print(example_text.numpy())\n",
      "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())\n",
      "def tf_lower_and_split_punct(text):\n",
      "    # 对字符进行切分\n",
      "    text = tf_text.normalize_utf8(text, 'NFKD')\n",
      "    text = tf.strings.lower(text)\n",
      "    # 保持空格，从a到z，并选择标点符号。\n",
      "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
      "    # 在标点符号周围添加空格。\n",
      "    text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
      "    # 去空格。\n",
      "    text = tf.strings.strip(text)\n",
      "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
      "    return text\n",
      "print(example_text.numpy().decode())\n",
      "# 输出解码结果(德语)\n",
      "print(tf_lower_and_split_punct(example_text).numpy().decode())\n",
      "# 对句子进行头尾标注\n",
      "# 输出结果：\n",
      "# ¿Todavía está en casa?\n",
      "# [START] ¿ todavia esta en casa ? [END]\n",
      "max_vocab_size = 5000\n",
      "\n",
      "input_text_processor = preprocessing.TextVectorization(\n",
      "    standardize=tf_lower_and_split_punct,\n",
      "    max_tokens=max_vocab_size)\n",
      "input_text_processor.adapt(inp)\n",
      "# this is first 10 words in vocabulary\n",
      "print(input_text_processor.get_vocabulary()[:10])\n",
      "output_text_processor = preprocessing.TextVectorization(\n",
      "    standardize=tf_lower_and_split_punct,\n",
      "    max_tokens=max_vocab_size)\n",
      "output_text_processor.adapt(targ)\n",
      "print(output_text_processor.get_vocabulary()[:10])\n",
      "example_tokens = input_text_processor(example_input_batch)\n",
      "print(example_tokens[:3, :10])\n",
      "input_vocab = np.array(input_text_processor.get_vocabulary())\n",
      "tokens = input_vocab[example_tokens[0].numpy()]\n",
      "' '.join(tokens)\n",
      "plt.subplot(1, 2, 1)\n",
      "plt.pcolormesh(example_tokens)\n",
      "plt.title('Token IDs')\n",
      "plt.subplot(1, 2, 2)\n",
      "plt.pcolormesh(example_tokens != 0)\n",
      "plt.title('Mask')\n",
      "#嵌入维度\n",
      "embedding_dim = 256\n",
      "#隐藏单元个数\n",
      "units = 1024\n",
      "class Encoder(tf.keras.layers.Layer):\n",
      "    def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
      "        super(Encoder, self).__init__()\n",
      "        self.enc_units = enc_units\n",
      "        self.input_vocab_size = input_vocab_size\n",
      "        # 嵌入层将令牌转换为向量\n",
      "        self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
      "                                                   embedding_dim)\n",
      "        # GRU RNN层依次处理这些向量。\n",
      "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
      "                                       return_sequences=True,\n",
      "                                       return_state=True,\n",
      "                                       recurrent_initializer='glorot_uniform')\n",
      "\n",
      "    def call(self, tokens, state=None):\n",
      "        shape_checker = ShapeChecker()\n",
      "        shape_checker(tokens, ('batch', 's'))\n",
      "        # 嵌入层查找每个标记的嵌入情况。\n",
      "        vectors = self.embedding(tokens)\n",
      "        shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
      "        output, state = self.gru(vectors, initial_state=state)\n",
      "        shape_checker(output, ('batch', 's', 'enc_units'))\n",
      "        shape_checker(state, ('batch', 'enc_units'))\n",
      "        # 返回新的序列和它的状态。\n",
      "        return output, state\n",
      "# 将输入的文本转换为token。\n",
      "example_tokens = input_text_processor(example_input_batch)\n",
      "# 对输入序列进行编码。\n",
      "encoder = Encoder(input_text_processor.vocabulary_size(),\n",
      "                  embedding_dim, units)\n",
      "example_enc_output, example_enc_state = encoder(example_tokens)\n",
      "print(f'Input batch, shape (batch): {example_input_batch.shape}')\n",
      "print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\n",
      "print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\n",
      "print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')\n",
      "class BahdanauAttention(tf.keras.layers.Layer):\n",
      "    def __init__(self, units):\n",
      "        super().__init__()\n",
      "        self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
      "        self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
      "        self.attention = tf.keras.layers.AdditiveAttention()\n",
      "\n",
      "    def call(self, query, value, mask):\n",
      "        shape_checker = ShapeChecker()\n",
      "        shape_checker(query, ('batch', 't', 'query_units'))\n",
      "        shape_checker(value, ('batch', 's', 'value_units'))\n",
      "        shape_checker(mask, ('batch', 's'))\n",
      "        # 构建Query矩阵\n",
      "        w1_query = self.W1(query)\n",
      "        shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
      "        # 构建Key矩阵\n",
      "        w2_key = self.W2(value)\n",
      "        shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
      "        # 构建mask矩阵\n",
      "        query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
      "        value_mask = mask\n",
      "        # 计算得到注意力图谱\n",
      "        context_vector, attention_weights = self.attention(\n",
      "            inputs=[w1_query, value, w2_key],\n",
      "            mask=[query_mask, value_mask],\n",
      "            return_attention_scores=True,\n",
      "        )\n",
      "        shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
      "        shape_checker(attention_weights, ('batch', 't', 's'))\n",
      "        return context_vector, attention_weights\n",
      "# test attention\n",
      "# 创建一个BahdanauAttention层\n",
      "attention_layer = BahdanauAttention(units)\n",
      "# 后续解码器将产生这个attention查询(Query矩阵)\n",
      "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n",
      "# 添加到编码tokens\n",
      "context_vector, attention_weights = attention_layer(\n",
      "    query=example_attention_query,\n",
      "    value=example_enc_output,\n",
      "    mask=(example_tokens != 0))\n",
      "\n",
      "print(f'Attention result shape: (batch_size, query_seq_length, units): {context_vector.shape}')\n",
      "\n",
      "print(f'Attention weights shape: (batch_size, query_seq_length,value_seq_length): {attention_weights.shape}')\n",
      "plt.subplot(1, 2, 1)\n",
      "plt.pcolormesh(attention_weights[:, 0, :])\n",
      "plt.title('Attention weights')\n",
      "plt.subplot(1, 2, 2)\n",
      "plt.pcolormesh(example_tokens != 0)\n",
      "plt.title('Mask')\n",
      "# 输出结果：\n",
      "# Text(0.5, 1.0, 'Mask')\n",
      "#取出部分attention用于展示\n",
      "attention_slice = attention_weights[0, 0].numpy()\n",
      "attention_slice = attention_slice[attention_slice != 0]\n",
      "plt.suptitle('Attention weights for one sequence')\n",
      "plt.figure(figsize=(12, 6))\n",
      "a1 = plt.subplot(1, 2, 1)\n",
      "plt.bar(range(len(attention_slice)), attention_slice)\n",
      "# 固定x轴\n",
      "plt.xlim(plt.xlim())\n",
      "plt.xlabel('Attention weights')\n",
      "a2 = plt.subplot(1, 2, 2)\n",
      "plt.bar(range(len(attention_slice)), attention_slice)\n",
      "plt.xlabel('Attention weights, zoomed')\n",
      "# 放大结果\n",
      "top = max(a1.get_ylim())\n",
      "zoom = 0.85 * top\n",
      "a2.set_ylim([0.90 * top, top])\n",
      "a1.plot(a1.get_xlim(), [zoom, zoom], color='k')\n",
      "\n",
      "\n",
      "# 输出结果：\n",
      "# [<matplotlib.lines.Line2D at 0x20c356a9670>]\n",
      "# <Figure size 432x288 with 0 Axes>\n",
      "class Decoder(tf.keras.layers.Layer):\n",
      "    def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
      "        super(Decoder, self).__init__()\n",
      "        self.dec_units = dec_units\n",
      "        self.output_vocab_size = output_vocab_size\n",
      "        self.embedding_dim = embedding_dim\n",
      "\n",
      "        # 嵌入层将令牌ID转为向量\n",
      "        self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
      "                                                   embedding_dim)\n",
      "        # RNN会记录到目前为止已经生成的内容。\n",
      "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
      "                                       return_sequences=True,\n",
      "                                       return_state=True,\n",
      "                                       recurrent_initializer='glorot_uniform')\n",
      "        # RNN的输出将是注意力层的查询。\n",
      "        self.attention = BahdanauAttention(self.dec_units)\n",
      "        self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
      "                                        use_bias=False)\n",
      "        self.fc = tf.keras.layers.Dense(self.output_vocab_size)\n",
      "class DecoderInput(typing.NamedTuple):\n",
      "    new_tokens: Any\n",
      "    enc_output: Any\n",
      "    mask: Any\n",
      "\n",
      "\n",
      "class DecoderOutput(typing.NamedTuple):\n",
      "    logits: Any\n",
      "    attention_weights: Any\n",
      "def call(self,\n",
      "         inputs: DecoderInput,\n",
      "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
      "    shape_checker = ShapeChecker()\n",
      "    shape_checker(inputs.new_tokens, ('batch', 't'))\n",
      "    shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n",
      "    shape_checker(inputs.mask, ('batch', 's'))\n",
      "    if state is not None:\n",
      "        shape_checker(state, ('batch', 'dec_units'))\n",
      "    #查询词嵌入\n",
      "    vectors = self.embedding(inputs.new_tokens)\n",
      "    shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n",
      "    #用RNN处理一个步骤\n",
      "    rnn_output, state = self.gru(vectors, initial_state=state)\n",
      "    shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n",
      "    shape_checker(state, ('batch', 'dec_units'))\n",
      "    #使用RNN输出作为关注的查询，超过了编码器的输出。\n",
      "\n",
      "    context_vector, attention_weights = self.attention(\n",
      "        query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
      "    shape_checker(context_vector, ('batch', 't', 'dec_units'))\n",
      "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
      "    # 加入context_vector和rnn_output\n",
      "    context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
      "    attention_vector = self.Wc(context_and_rnn_output)\n",
      "    shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n",
      "    # 生成logit预测\n",
      "    logits = self.fc(attention_vector)\n",
      "    shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n",
      "    return DecoderOutput(logits, attention_weights), state\n",
      "Decoder.call = call\n",
      "decoder = Decoder(output_text_processor.vocabulary_size(),\n",
      "                  embedding_dim, units)\n",
      "#转换目标序列，并收集[START]标记。\n",
      "example_output_tokens = output_text_processor(example_target_batch)\n",
      "start_index = output_text_processor.get_vocabulary().index('[START]')\n",
      "first_token = tf.constant([[start_index]] * example_output_tokens.shape[0])\n",
      "#运行decoder\n",
      "dec_result, dec_state = decoder(\n",
      "    inputs=DecoderInput(new_tokens=first_token,\n",
      "                        enc_output=example_enc_output,\n",
      "                        mask=(example_tokens != 0)),\n",
      "    state=example_enc_state\n",
      ")\n",
      "print(f'logits shape: (batch_size, t, output_vocab_size)'\n",
      "      f'{dec_result.logits.shape}')\n",
      "print(f'state shape: (batch_size, dec_units) {dec_state.shape}')\n",
      "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
      "#将令牌解码为输出的第一个单词。\n",
      "vocab = np.array(output_text_processor.get_vocabulary())\n",
      "first_word = vocab[sampled_token.numpy()]\n",
      "print(first_word[:5])\n",
      "dec_result, dec_state = decoder(\n",
      "    DecoderInput(sampled_token,\n",
      "                 example_enc_output,\n",
      "                 mask=(example_tokens != 0)),\n",
      "    state=dec_state)\n",
      "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
      "first_word = vocab[sampled_token.numpy()]\n",
      "print(first_word[:5])\n",
      "class MaskedLoss(tf.keras.losses.Loss):\n",
      "    def __init__(self):\n",
      "        self.name = 'masked_loss'\n",
      "        self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
      "            from_logits=True, reduction='none')\n",
      "\n",
      "    def __call__(self, y_true, y_pred):\n",
      "        shape_checker = ShapeChecker()\n",
      "        shape_checker(y_true, ('batch', 't'))\n",
      "        shape_checker(y_pred, ('batch', 't', 'logits'))\n",
      "        # 计算该批次中每一项的损失。\n",
      "        loss = self.loss(y_true, y_pred)\n",
      "        shape_checker(loss, ('batch', 't'))\n",
      "        # 屏蔽掉填充物上的损失。\n",
      "        mask = tf.cast(y_true != 0, tf.float32)\n",
      "        shape_checker(mask, ('batch', 't'))\n",
      "        loss *= mask\n",
      "        # 返回总的loss。\n",
      "        return tf.reduce_sum(loss)\n",
      "class TrainTranslator(tf.keras.Model):\n",
      "    def __init__(self, embedding_dim, units,\n",
      "                 input_text_processor,\n",
      "                 output_text_processor,\n",
      "                 use_tf_function=True):\n",
      "        super().__init__()\n",
      "\n",
      "        # 构建编码器和解码器\n",
      "        encoder = Encoder(input_text_processor.vocabulary_size(),\n",
      "                          embedding_dim, units)\n",
      "        decoder = Decoder(output_text_processor.vocabulary_size(),\n",
      "                          embedding_dim, units)\n",
      "        self.encoder = encoder\n",
      "        self.decoder = decoder\n",
      "        self.input_text_processor = input_text_processor\n",
      "        self.output_text_processor = output_text_processor\n",
      "        self.use_tf_function = use_tf_function\n",
      "        self.shape_checker = ShapeChecker()\n",
      "\n",
      "    def train_step(self, inputs):\n",
      "        self.shape_checker = ShapeChecker()\n",
      "\n",
      "        if self.use_tf_function:\n",
      "            return self._tf_train_step(inputs)\n",
      "        else:\n",
      "            return self._train_step(inputs)\n",
      "def _preprocess(self, input_text, target_text):\n",
      "    self.shape_checker(input_text, ('batch',))\n",
      "    self.shape_checker(target_text, ('batch',))\n",
      "    # 将文本转换为tokens ID\n",
      "    input_tokens = self.input_text_processor(input_text)\n",
      "    target_tokens = self.output_text_processor(target_text)\n",
      "    self.shape_checker(input_tokens, ('batch', 's'))\n",
      "    self.shape_checker(target_tokens, ('batch', 't'))\n",
      "    # 将ID转换为掩码\n",
      "    input_mask = input_tokens != 0\n",
      "    self.shape_checker(input_mask, ('batch', 's'))\n",
      "    target_mask = target_tokens != 0\n",
      "\n",
      "    self.shape_checker(target_mask, ('batch', 't'))\n",
      "    return input_tokens, input_mask, target_tokens, target_mask\n",
      "\n",
      "\n",
      "TrainTranslator._preprocess = _preprocess\n",
      "def _train_step(self, inputs):\n",
      "    input_text, target_text = inputs\n",
      "    (input_tokens, input_mask,\n",
      "     target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
      "    max_target_length = tf.shape(target_tokens)[1]\n",
      "    with tf.GradientTape() as tape:\n",
      "        #对输入进行编码\n",
      "        enc_output, enc_state = self.encoder(input_tokens)\n",
      "        self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
      "        self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
      "        #将解码器的状态初始化为编码器的最终状态。\n",
      "        # 这只有在编码器和解码器有相同数量的单位时生效。\n",
      "        dec_state = enc_state\n",
      "        loss = tf.constant(0.0)\n",
      "        for t in tf.range(max_target_length - 1):\n",
      "            #从目标序列中传入两个token:\n",
      "            # 1.解码器的当前输入.\n",
      "            # 2.解码器下次预测的目标.\n",
      "            new_tokens = target_tokens[:, t:t + 2]\n",
      "            step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
      "                                                   enc_output, dec_state)\n",
      "            loss = loss + step_loss\n",
      "        #对所有非填充token的损失进行平均计算。\n",
      "        average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
      "    #设置优化步骤\n",
      "    variables = self.trainable_variables\n",
      "    gradients = tape.gradient(average_loss, variables)\n",
      "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
      "    # 返回一个映射到当前值的字典\n",
      "    return {'batch_loss': average_loss}\n",
      "\n",
      "\n",
      "TrainTranslator._train_step = _train_step\n",
      "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
      "    input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
      "    # Run the decoder one step.\n",
      "    decoder_input = DecoderInput(new_tokens=input_token,\n",
      "                                 enc_output=enc_output,\n",
      "                                 mask=input_mask)\n",
      "    dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
      "    self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
      "    self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
      "    self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
      "    # `self.loss`返回非填充token的总数。\n",
      "    y = target_token\n",
      "    y_pred = dec_result.logits\n",
      "    step_loss = self.loss(y, y_pred)\n",
      "    return step_loss, dec_state\n",
      "TrainTranslator._loop_step = _loop_step\n",
      "\n",
      "translator = TrainTranslator(\n",
      "    embedding_dim, units,\n",
      "    input_text_processor=input_text_processor,\n",
      "    output_text_processor=output_text_processor,\n",
      "    use_tf_function=False)\n",
      "#配置损失和优化器\n",
      "translator.compile(\n",
      "    optimizer=tf.optimizers.Adam(),\n",
      "    loss=MaskedLoss(),\n",
      ")\n",
      "np.log(output_text_processor.vocabulary_size())\n",
      "# 输出结果:\n",
      "# 8.517193191416238\n",
      "get_ipython().run_cell_magic('time', '', \"for n in range(10):\\n    print(translator.train_step([example_input_batch, example_target_batch]))\\nprint()\\n\\n\\n# 输出结果:\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.6101117>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.5797815>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.522971>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.3605533>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.785821>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.0904937>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.8641896>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.3120656>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.264642>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.112561>}\\n\")\n",
      "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
      "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
      "def _tf_train_step(self, inputs):\n",
      "    return self._train_step(inputs)\n",
      "\n",
      "\n",
      "TrainTranslator._tf_train_step = _tf_train_step\n",
      "\n",
      "translator.use_tf_function = True\n",
      "#第一次运行由于需要对函数进行追踪，故速度会比较慢\n",
      "translator.train_step([example_input_batch, example_target_batch])\n",
      "get_ipython().run_cell_magic('time', '', 'for n in range(10):\\n    print(translator.train_step([example_input_batch, example_target_batch]))\\nprint()\\n')\n",
      "losses = []\n",
      "for n in range(100):\n",
      "    print('.', end='')\n",
      "    logs = translator.train_step([example_input_batch, example_target_batch])\n",
      "    losses.append(logs['batch_loss'].numpy())\n",
      "print()\n",
      "plt.plot(losses)\n",
      "# 输出结果:\n",
      "#\n",
      "# [<matplotlib.lines.Line2D at 0x20c362c3c70>]\n",
      "train_translator = TrainTranslator(\n",
      "    embedding_dim, units,\n",
      "    input_text_processor=input_text_processor,\n",
      "    output_text_processor=output_text_processor)\n",
      "# Configure the loss and optimizer\n",
      "train_translator.compile(\n",
      "    optimizer=tf.optimizers.Adam(),\n",
      "    loss=MaskedLoss(),\n",
      ")\n",
      "class BatchLogs(tf.keras.callbacks.Callback):\n",
      "    def __init__(self, key):\n",
      "        self.key = key\n",
      "        self.logs = []\n",
      "\n",
      "    def on_train_batch_end(self, n, logs):\n",
      "        self.logs.append(logs[self.key])\n",
      "\n",
      "\n",
      "batch_loss = BatchLogs('batch_loss')\n",
      "\n",
      "train_translator.fit(dataset, epochs=3,\n",
      "                     steps_per_epoch=3,\n",
      "                     callbacks=[batch_loss])\n",
      "# 如果上一个cell中的epoches和steps_per_epoch过小，此处没有绘图效果。\n",
      "plt.plot(batch_loss.logs)\n",
      "plt.ylim([0, 3])\n",
      "plt.xlabel('Batch #')\n",
      "plt.ylabel('CE/token')\n",
      "class Translator(tf.Module):\n",
      "    def __init__(self, encoder, decoder, input_text_processor,\n",
      "                 output_text_processor):\n",
      "        self.encoder = encoder\n",
      "        self.decoder = decoder\n",
      "        self.input_text_processor = input_text_processor\n",
      "        self.output_text_processor = output_text_processor\n",
      "        self.output_token_string_from_index = (\n",
      "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
      "                vocabulary=output_text_processor.get_vocabulary(),\n",
      "                mask_token='',\n",
      "                invert=True))\n",
      "\n",
      "        # 输出不应该产生padding、unknown或start。\n",
      "        index_from_string = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
      "            vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
      "        token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
      "        token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
      "\n",
      "        token_mask[np.array(token_mask_ids)] = True\n",
      "        self.token_mask = token_mask\n",
      "        self.start_token = index_from_string(tf.constant('[START]'))\n",
      "        self.end_token = index_from_string(tf.constant('[END]'))\n",
      "\n",
      "\n",
      "translator = Translator(\n",
      "    encoder=train_translator.encoder,\n",
      "    decoder=train_translator.decoder,\n",
      "    input_text_processor=input_text_processor,\n",
      "    output_text_processor=output_text_processor,\n",
      ")\n",
      "def tokens_to_text(self, result_tokens):\n",
      "    shape_checker = ShapeChecker()\n",
      "    shape_checker(result_tokens, ('batch', 't'))\n",
      "    result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
      "    shape_checker(result_text_tokens, ('batch', 't'))\n",
      "    result_text = tf.strings.reduce_join(result_text_tokens,\n",
      "                                         axis=1, separator=' ')\n",
      "    shape_checker(result_text, 'batch')\n",
      "    result_text = tf.strings.strip(result_text)\n",
      "    shape_checker(result_text, ('batch',))\n",
      "    return result_text\n",
      "\n",
      "\n",
      "Translator.tokens_to_text = tokens_to_text\n",
      "\n",
      "example_output_tokens = tf.random.uniform(\n",
      "    shape=[5, 2], minval=0, dtype=tf.int64,\n",
      "    maxval=output_text_processor.vocabulary_size())\n",
      "\n",
      "translator.tokens_to_text(example_output_tokens).numpy()\n",
      "def sample(self, logits, temperature):\n",
      "    shape_checker = ShapeChecker()\n",
      "    shape_checker(logits, ('batch', 't', 'vocab'))\n",
      "    shape_checker(self.token_mask, ('vocab',))\n",
      "    token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
      "    shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n",
      "    logits = tf.where(self.token_mask, -np.inf, logits)\n",
      "    if temperature == 0.0:\n",
      "        new_tokens = tf.argmax(logits, axis=-1)\n",
      "    else:\n",
      "        logits = tf.squeeze(logits, axis=1)\n",
      "        new_tokens = tf.random.categorical(logits / temperature,\n",
      "                                           num_samples=1)\n",
      "        shape_checker(new_tokens, ('batch', 't'))\n",
      "        return new_tokens\n",
      "\n",
      "Translator.sample = sample\n",
      "\n",
      "example_logits = tf.random.normal([5, 1,\n",
      "                                   output_text_processor.vocabulary_size()])\n",
      "example_output_tokens = translator.sample(example_logits, temperature=1.0)\n",
      "example_output_tokens\n",
      "def translate_unrolled(self,\n",
      "                       input_text, *,\n",
      "                       max_length=50,\n",
      "                       return_attention=True,\n",
      "                       temperature=1.0):\n",
      "    batch_size = tf.shape(input_text)[0]\n",
      "    input_tokens = self.input_text_processor(input_text)\n",
      "    enc_output, enc_state = self.encoder(input_tokens)\n",
      "    dec_state = enc_state\n",
      "    new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
      "    result_tokens = []\n",
      "    attention = []\n",
      "    done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
      "    for _ in range(max_length):\n",
      "        dec_input = DecoderInput(new_tokens=new_tokens,\n",
      "                                 enc_output=enc_output,\n",
      "                                 mask=(input_tokens != 0))\n",
      "        dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
      "        attention.append(dec_result.attention_weights)\n",
      "        new_tokens = self.sample(dec_result.logits, temperature)\n",
      "        done = done | (new_tokens == self.end_token)\n",
      "        # 一旦一个序列完成，它只产生0-padding。\n",
      "        new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
      "        result_tokens.append(new_tokens)\n",
      "        if tf.executing_eagerly() and tf.reduce_all(done):\n",
      "            break\n",
      "    # 将生成的token id列表转换为字符串列表。\n",
      "\n",
      "    result_tokens = tf.concat(result_tokens, axis=-1)\n",
      "    result_text = self.tokens_to_text(result_tokens)\n",
      "    if return_attention:\n",
      "        attention_stack = tf.concat(attention, axis=1)\n",
      "        return {'text': result_text, 'attention': attention_stack}\n",
      "    else:\n",
      "        return {'text': result_text}\n",
      "Translator.translate = translate_unrolled\n",
      "get_ipython().run_cell_magic('time', '', 'input_text = tf.constant([\\n    \\'hace mucho frio aqui.\\',  # \"It\\'s freezing here.\"\\n    \\'Esta es mi vida.\\',  # \"This is my life.\"\"\\n])\\nresult = translator.translate(\\n    input_text=input_text)\\n\\n# print(result)\\nprint(result[\\'text\\'][0].numpy().decode())\\nprint(result[\\'text\\'][1].numpy().decode())\\nprint()\\n# 实验结果:\\n# it is very cold here .\\n# this is my life .\\n# Wall time: 266 ms\\n\\n')\n",
      "from IPython import get_ipython\n",
      "\n",
      "# 获取当前运行的笔记本\n",
      "notebook = get_ipython().get_ipython().user_ns['In']\n",
      "\n",
      "# 打印所有输入单元格的内容\n",
      "for cell in notebook:\n",
      "    print(cell)\n",
      "def load_data(path):\n",
      "    text = path.read_text(encoding='utf-8')\n",
      "\n",
      "    lines = text.splitlines()\n",
      "    pairs = [line.split('\\t') for line in lines]\n",
      "\n",
      "    inp = [inp for targ, inp in pairs]\n",
      "    targ = [targ for targ, inp in pairs]\n",
      "    with open('/home/zhousc66/spa.txt', 'w', encoding='utf-8') as f:\n",
      "        for i in range(len(inp)):\n",
      "            f.write(f\"{targ[i]}\\t{inp[i]}\\n\")\n",
      "\n",
      "    return targ, inp\n",
      "# tensorflow_text, tensorflow, matplotlib\n",
      "import numpy as np\n",
      "\n",
      "import typing\n",
      "from typing import Any, Tuple\n",
      "# Customize types\n",
      "import tensorflow as tf\n",
      "from tensorflow.keras.layers.experimental import preprocessing\n",
      "# import preprocess module\n",
      "import tensorflow_text as tf_text\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.ticker as ticker\n",
      "class ShapeChecker:\n",
      "    def __init__(self):\n",
      "        # save every cache\n",
      "        self.shapes = {}\n",
      "\n",
      "    def __call__(self, tensor, names, broadcast=False):\n",
      "        if not tf.executing_eagerly():\n",
      "            return\n",
      "\n",
      "        if isinstance(names, str):\n",
      "            names = (names,)\n",
      "\n",
      "        shape = tf.shape(tensor)\n",
      "        rank = tf.rank(tensor)\n",
      "\n",
      "        if rank != len(names):\n",
      "            raise ValueError(f'Rank mismatch:\\n'\n",
      "                             f'    found {rank}: {shape.numpy()}\\n'\n",
      "                             f'    expected {len(names)}: {names}\\n')\n",
      "\n",
      "        for i, name in enumerate(names):\n",
      "            if isinstance(name, int):\n",
      "                old_dim = name\n",
      "            else:\n",
      "                old_dim = self.shapes.get(name, None)\n",
      "            new_dim = shape[i]\n",
      "\n",
      "            if broadcast and new_dim == 1:\n",
      "                continue\n",
      "\n",
      "            if old_dim is None:\n",
      "                # if the name is new, save it to the cache\n",
      "                self.shapes[name] = new_dim\n",
      "                continue\n",
      "\n",
      "            if new_dim != old_dim:\n",
      "                raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
      "                                 f\"    found: {new_dim}\\n\"\n",
      "                                 f\"    expected: {old_dim}\\n\")\n",
      "# Download the file\n",
      "import pathlib\n",
      "\n",
      "path_to_zip = tf.keras.utils.get_file(\n",
      "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
      "    extract=True)\n",
      "\n",
      "path_to_file = pathlib.Path(path_to_zip).parent /'spa-eng/spa.txt'\n",
      "print(path_to_file)\n",
      "def load_data(path):\n",
      "    text = path.read_text(encoding='utf-8')\n",
      "\n",
      "    lines = text.splitlines()\n",
      "    pairs = [line.split('\\t') for line in lines]\n",
      "\n",
      "    inp = [inp for targ, inp in pairs]\n",
      "    targ = [targ for targ, inp in pairs]\n",
      "    with open('/home/zhousc66/spa.txt', 'w', encoding='utf-8') as f:\n",
      "        for i in range(len(inp)):\n",
      "            f.write(f\"{targ[i]}\\t{inp[i]}\\n\")\n",
      "\n",
      "    return targ, inp\n",
      "def load_data(path):\n",
      "    text = path.read_text(encoding='utf-8')\n",
      "\n",
      "    lines = text.splitlines()\n",
      "    pairs = [line.split('\\t') for line in lines]\n",
      "\n",
      "    inp = [inp for targ, inp in pairs]\n",
      "    targ = [targ for targ, inp in pairs]\n",
      "    with open('/home/zhousc66/spa.txt', 'w', encoding='utf-8') as f:\n",
      "        for i in range(len(inp)):\n",
      "            f.write(f\"{targ[i]}\\t{inp[i]}\\n\")\n",
      "\n",
      "    return targ, inp\n",
      "class ShapeChecker:\n",
      "    def __init__(self):\n",
      "        # save every cache\n",
      "        self.shapes = {}\n",
      "\n",
      "    def __call__(self, tensor, names, broadcast=False):\n",
      "        if not tf.executing_eagerly():\n",
      "            return\n",
      "\n",
      "        if isinstance(names, str):\n",
      "            names = (names,)\n",
      "\n",
      "        shape = tf.shape(tensor)\n",
      "        rank = tf.rank(tensor)\n",
      "\n",
      "        if rank != len(names):\n",
      "            raise ValueError(f'Rank mismatch:\\n'\n",
      "                             f'    found {rank}: {shape.numpy()}\\n'\n",
      "                             f'    expected {len(names)}: {names}\\n')\n",
      "\n",
      "        for i, name in enumerate(names):\n",
      "            if isinstance(name, int):\n",
      "                old_dim = name\n",
      "            else:\n",
      "                old_dim = self.shapes.get(name, None)\n",
      "            new_dim = shape[i]\n",
      "\n",
      "            if broadcast and new_dim == 1:\n",
      "                continue\n",
      "\n",
      "            if old_dim is None:\n",
      "                # if the name is new, save it to the cache\n",
      "                self.shapes[name] = new_dim\n",
      "                continue\n",
      "\n",
      "            if new_dim != old_dim:\n",
      "                raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
      "                                 f\"    found: {new_dim}\\n\"\n",
      "                                 f\"    expected: {old_dim}\\n\")\n",
      "# Download the file\n",
      "import pathlib\n",
      "\n",
      "path_to_zip = tf.keras.utils.get_file(\n",
      "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
      "    extract=True)\n",
      "\n",
      "path_to_file = pathlib.Path(path_to_zip).parent /'spa-eng/spa.txt'\n",
      "print(path_to_file)\n",
      "def load_data(path):\n",
      "    text = path.read_text(encoding='utf-8')\n",
      "\n",
      "    lines = text.splitlines()\n",
      "    pairs = [line.split('\\t') for line in lines]\n",
      "\n",
      "    inp = [inp for targ, inp in pairs]\n",
      "    targ = [targ for targ, inp in pairs]\n",
      "    with open('/home/zhousc66/spa.txt', 'w', encoding='utf-8') as f:\n",
      "        for i in range(len(inp)):\n",
      "            f.write(f\"{targ[i]}\\t{inp[i]}\\n\")\n",
      "\n",
      "    return targ, inp\n",
      "targ, inp = load_data(path_to_file)\n",
      "BUFFER_SIZE = len(inp)\n",
      "BATCH_SIZE = 64\n",
      "# create a tf.data.Dataset string to wash the data and batch it efficiently\n",
      "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
      "dataset = dataset.batch(BATCH_SIZE)\n",
      "# tensorflow_text, tensorflow, matplotlib\n",
      "import numpy as np\n",
      "\n",
      "import typing\n",
      "from typing import Any, Tuple\n",
      "# Customize types\n",
      "import tensorflow as tf\n",
      "from tensorflow.keras.layers.experimental import preprocessing\n",
      "# import preprocess module\n",
      "import tensorflow_text as tf_text\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.ticker as ticker\n",
      "class ShapeChecker:\n",
      "    def __init__(self):\n",
      "        # save every cache\n",
      "        self.shapes = {}\n",
      "\n",
      "    def __call__(self, tensor, names, broadcast=False):\n",
      "        if not tf.executing_eagerly():\n",
      "            return\n",
      "\n",
      "        if isinstance(names, str):\n",
      "            names = (names,)\n",
      "\n",
      "        shape = tf.shape(tensor)\n",
      "        rank = tf.rank(tensor)\n",
      "\n",
      "        if rank != len(names):\n",
      "            raise ValueError(f'Rank mismatch:\\n'\n",
      "                             f'    found {rank}: {shape.numpy()}\\n'\n",
      "                             f'    expected {len(names)}: {names}\\n')\n",
      "\n",
      "        for i, name in enumerate(names):\n",
      "            if isinstance(name, int):\n",
      "                old_dim = name\n",
      "            else:\n",
      "                old_dim = self.shapes.get(name, None)\n",
      "            new_dim = shape[i]\n",
      "\n",
      "            if broadcast and new_dim == 1:\n",
      "                continue\n",
      "\n",
      "            if old_dim is None:\n",
      "                # if the name is new, save it to the cache\n",
      "                self.shapes[name] = new_dim\n",
      "                continue\n",
      "\n",
      "            if new_dim != old_dim:\n",
      "                raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
      "                                 f\"    found: {new_dim}\\n\"\n",
      "                                 f\"    expected: {old_dim}\\n\")\n",
      "# Download the file\n",
      "import pathlib\n",
      "\n",
      "path_to_zip = tf.keras.utils.get_file(\n",
      "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
      "    extract=True)\n",
      "\n",
      "path_to_file = pathlib.Path(path_to_zip).parent /'spa-eng/spa.txt'\n",
      "print(path_to_file)\n",
      "def load_data(path):\n",
      "    text = path.read_text(encoding='utf-8')\n",
      "\n",
      "    lines = text.splitlines()\n",
      "    pairs = [line.split('\\t') for line in lines]\n",
      "\n",
      "    inp = [inp for targ, inp in pairs]\n",
      "    targ = [targ for targ, inp in pairs]\n",
      "    with open('/home/zhousc66/spa.txt', 'w', encoding='utf-8') as f:\n",
      "        for i in range(len(inp)):\n",
      "            f.write(f\"{targ[i]}\\t{inp[i]}\\n\")\n",
      "\n",
      "    return targ, inp\n",
      "targ, inp = load_data(path_to_file)\n",
      "BUFFER_SIZE = len(inp)\n",
      "BATCH_SIZE = 64\n",
      "# create a tf.data.Dataset string to wash the data and batch it efficiently\n",
      "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
      "dataset = dataset.batch(BATCH_SIZE)\n",
      "# tensorflow_text, tensorflow, matplotlib\n",
      "import numpy as np\n",
      "\n",
      "import typing\n",
      "from typing import Any, Tuple\n",
      "# Customize types\n",
      "import tensorflow as tf\n",
      "from tensorflow.keras.layers.experimental import preprocessing\n",
      "# import preprocess module\n",
      "import tensorflow_text as tf_text\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.ticker as ticker\n",
      "class ShapeChecker:\n",
      "    def __init__(self):\n",
      "        # save every cache\n",
      "        self.shapes = {}\n",
      "\n",
      "    def __call__(self, tensor, names, broadcast=False):\n",
      "        if not tf.executing_eagerly():\n",
      "            return\n",
      "\n",
      "        if isinstance(names, str):\n",
      "            names = (names,)\n",
      "\n",
      "        shape = tf.shape(tensor)\n",
      "        rank = tf.rank(tensor)\n",
      "\n",
      "        if rank != len(names):\n",
      "            raise ValueError(f'Rank mismatch:\\n'\n",
      "                             f'    found {rank}: {shape.numpy()}\\n'\n",
      "                             f'    expected {len(names)}: {names}\\n')\n",
      "\n",
      "        for i, name in enumerate(names):\n",
      "            if isinstance(name, int):\n",
      "                old_dim = name\n",
      "            else:\n",
      "                old_dim = self.shapes.get(name, None)\n",
      "            new_dim = shape[i]\n",
      "\n",
      "            if broadcast and new_dim == 1:\n",
      "                continue\n",
      "\n",
      "            if old_dim is None:\n",
      "                # if the name is new, save it to the cache\n",
      "                self.shapes[name] = new_dim\n",
      "                continue\n",
      "\n",
      "            if new_dim != old_dim:\n",
      "                raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
      "                                 f\"    found: {new_dim}\\n\"\n",
      "                                 f\"    expected: {old_dim}\\n\")\n",
      "# Download the file\n",
      "import pathlib\n",
      "\n",
      "path_to_zip = tf.keras.utils.get_file(\n",
      "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
      "    extract=True)\n",
      "\n",
      "path_to_file = pathlib.Path(path_to_zip).parent /'spa-eng/spa.txt'\n",
      "print(path_to_file)\n",
      "def load_data(path):\n",
      "    text = path.read_text(encoding='utf-8')\n",
      "\n",
      "    lines = text.splitlines()\n",
      "    pairs = [line.split('\\t') for line in lines]\n",
      "\n",
      "    inp = [inp for targ, inp in pairs]\n",
      "    targ = [targ for targ, inp in pairs]\n",
      "    with open('/home/zhousc66/spa.txt', 'w', encoding='utf-8') as f:\n",
      "        for i in range(len(inp)):\n",
      "            f.write(f\"{targ[i]}\\t{inp[i]}\\n\")\n",
      "\n",
      "    return targ, inp\n",
      "targ, inp = load_data(path_to_file)\n",
      "BUFFER_SIZE = len(inp)\n",
      "BATCH_SIZE = 64\n",
      "# create a tf.data.Dataset string to wash the data and batch it efficiently\n",
      "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
      "dataset = dataset.batch(BATCH_SIZE)\n",
      "for example_input_batch, example_target_batch in dataset.take(1):\n",
      "    print(example_input_batch[:5])\n",
      "    print()\n",
      "    print(example_target_batch[:5])\n",
      "    break\n",
      "# tensorflow_text, tensorflow, matplotlib\n",
      "import numpy as np\n",
      "\n",
      "import typing\n",
      "from typing import Any, Tuple\n",
      "# Customize types\n",
      "import tensorflow as tf\n",
      "from tensorflow.keras.layers.experimental import preprocessing\n",
      "# import preprocess module\n",
      "import tensorflow_text as tf_text\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.ticker as ticker\n",
      "class ShapeChecker:\n",
      "    def __init__(self):\n",
      "        # save every cache\n",
      "        self.shapes = {}\n",
      "\n",
      "    def __call__(self, tensor, names, broadcast=False):\n",
      "        if not tf.executing_eagerly():\n",
      "            return\n",
      "\n",
      "        if isinstance(names, str):\n",
      "            names = (names,)\n",
      "\n",
      "        shape = tf.shape(tensor)\n",
      "        rank = tf.rank(tensor)\n",
      "\n",
      "        if rank != len(names):\n",
      "            raise ValueError(f'Rank mismatch:\\n'\n",
      "                             f'    found {rank}: {shape.numpy()}\\n'\n",
      "                             f'    expected {len(names)}: {names}\\n')\n",
      "\n",
      "        for i, name in enumerate(names):\n",
      "            if isinstance(name, int):\n",
      "                old_dim = name\n",
      "            else:\n",
      "                old_dim = self.shapes.get(name, None)\n",
      "            new_dim = shape[i]\n",
      "\n",
      "            if broadcast and new_dim == 1:\n",
      "                continue\n",
      "\n",
      "            if old_dim is None:\n",
      "                # if the name is new, save it to the cache\n",
      "                self.shapes[name] = new_dim\n",
      "                continue\n",
      "\n",
      "            if new_dim != old_dim:\n",
      "                raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
      "                                 f\"    found: {new_dim}\\n\"\n",
      "                                 f\"    expected: {old_dim}\\n\")\n",
      "# Download the file\n",
      "import pathlib\n",
      "\n",
      "path_to_zip = tf.keras.utils.get_file(\n",
      "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
      "    extract=True)\n",
      "\n",
      "path_to_file = pathlib.Path(path_to_zip).parent /'spa-eng/spa.txt'\n",
      "print(path_to_file)\n",
      "def load_data(path):\n",
      "    text = path.read_text(encoding='utf-8')\n",
      "\n",
      "    lines = text.splitlines()\n",
      "    pairs = [line.split('\\t') for line in lines]\n",
      "\n",
      "    inp = [inp for targ, inp in pairs]\n",
      "    targ = [targ for targ, inp in pairs]\n",
      "    with open('/home/zhousc66/spa.txt', 'w', encoding='utf-8') as f:\n",
      "        for i in range(len(inp)):\n",
      "            f.write(f\"{targ[i]}\\t{inp[i]}\\n\")\n",
      "\n",
      "    return targ, inp\n",
      "targ, inp = load_data(path_to_file)\n",
      "BUFFER_SIZE = len(inp)\n",
      "BATCH_SIZE = 64\n",
      "# create a tf.data.Dataset string to wash the data and batch it efficiently\n",
      "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
      "dataset = dataset.batch(BATCH_SIZE)\n",
      "for example_input_batch, example_target_batch in dataset.take(1):\n",
      "    print(example_input_batch[:5])\n",
      "    print()\n",
      "    print(example_target_batch[:5])\n",
      "    break\n",
      "example_text = tf.constant('¿Todavía está en casa?')\n",
      "\n",
      "print(example_text.numpy())\n",
      "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())\n",
      "def tf_lower_and_split_punct(text):\n",
      "    # 对字符进行切分\n",
      "    text = tf_text.normalize_utf8(text, 'NFKD')\n",
      "    text = tf.strings.lower(text)\n",
      "    # 保持空格，从a到z，并选择标点符号。\n",
      "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
      "    # 在标点符号周围添加空格。\n",
      "    text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
      "    # 去空格。\n",
      "    text = tf.strings.strip(text)\n",
      "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
      "    return text\n",
      "print(example_text.numpy().decode())\n",
      "# 输出解码结果(德语)\n",
      "print(tf_lower_and_split_punct(example_text).numpy().decode())\n",
      "# 对句子进行头尾标注\n",
      "# 输出结果：\n",
      "# ¿Todavía está en casa?\n",
      "# [START] ¿ todavia esta en casa ? [END]\n",
      "max_vocab_size = 5000\n",
      "\n",
      "input_text_processor = preprocessing.TextVectorization(\n",
      "    standardize=tf_lower_and_split_punct,\n",
      "    max_tokens=max_vocab_size)\n",
      "input_text_processor.adapt(inp)\n",
      "# this is first 10 words in vocabulary\n",
      "print(input_text_processor.get_vocabulary()[:10])\n",
      "output_text_processor = preprocessing.TextVectorization(\n",
      "    standardize=tf_lower_and_split_punct,\n",
      "    max_tokens=max_vocab_size)\n",
      "output_text_processor.adapt(targ)\n",
      "print(output_text_processor.get_vocabulary()[:10])\n",
      "example_tokens = input_text_processor(example_input_batch)\n",
      "print(example_tokens[:3, :10])\n",
      "input_vocab = np.array(input_text_processor.get_vocabulary())\n",
      "tokens = input_vocab[example_tokens[0].numpy()]\n",
      "' '.join(tokens)\n",
      "plt.subplot(1, 2, 1)\n",
      "plt.pcolormesh(example_tokens)\n",
      "plt.title('Token IDs')\n",
      "plt.subplot(1, 2, 2)\n",
      "plt.pcolormesh(example_tokens != 0)\n",
      "plt.title('Mask')\n",
      "#嵌入维度\n",
      "embedding_dim = 256\n",
      "#隐藏单元个数\n",
      "units = 1024\n",
      "class Encoder(tf.keras.layers.Layer):\n",
      "    def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
      "        super(Encoder, self).__init__()\n",
      "        self.enc_units = enc_units\n",
      "        self.input_vocab_size = input_vocab_size\n",
      "        # 嵌入层将令牌转换为向量\n",
      "        self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
      "                                                   embedding_dim)\n",
      "        # GRU RNN层依次处理这些向量。\n",
      "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
      "                                       return_sequences=True,\n",
      "                                       return_state=True,\n",
      "                                       recurrent_initializer='glorot_uniform')\n",
      "\n",
      "    def call(self, tokens, state=None):\n",
      "        shape_checker = ShapeChecker()\n",
      "        shape_checker(tokens, ('batch', 's'))\n",
      "        # 嵌入层查找每个标记的嵌入情况。\n",
      "        vectors = self.embedding(tokens)\n",
      "        shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
      "        output, state = self.gru(vectors, initial_state=state)\n",
      "        shape_checker(output, ('batch', 's', 'enc_units'))\n",
      "        shape_checker(state, ('batch', 'enc_units'))\n",
      "        # 返回新的序列和它的状态。\n",
      "        return output, state\n",
      "# 将输入的文本转换为token。\n",
      "example_tokens = input_text_processor(example_input_batch)\n",
      "# 对输入序列进行编码。\n",
      "encoder = Encoder(input_text_processor.vocabulary_size(),\n",
      "                  embedding_dim, units)\n",
      "example_enc_output, example_enc_state = encoder(example_tokens)\n",
      "print(f'Input batch, shape (batch): {example_input_batch.shape}')\n",
      "print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\n",
      "print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\n",
      "print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')\n",
      "class BahdanauAttention(tf.keras.layers.Layer):\n",
      "    def __init__(self, units):\n",
      "        super().__init__()\n",
      "        self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
      "        self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
      "        self.attention = tf.keras.layers.AdditiveAttention()\n",
      "\n",
      "    def call(self, query, value, mask):\n",
      "        shape_checker = ShapeChecker()\n",
      "        shape_checker(query, ('batch', 't', 'query_units'))\n",
      "        shape_checker(value, ('batch', 's', 'value_units'))\n",
      "        shape_checker(mask, ('batch', 's'))\n",
      "        # 构建Query矩阵\n",
      "        w1_query = self.W1(query)\n",
      "        shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
      "        # 构建Key矩阵\n",
      "        w2_key = self.W2(value)\n",
      "        shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
      "        # 构建mask矩阵\n",
      "        query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
      "        value_mask = mask\n",
      "        # 计算得到注意力图谱\n",
      "        context_vector, attention_weights = self.attention(\n",
      "            inputs=[w1_query, value, w2_key],\n",
      "            mask=[query_mask, value_mask],\n",
      "            return_attention_scores=True,\n",
      "        )\n",
      "        shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
      "        shape_checker(attention_weights, ('batch', 't', 's'))\n",
      "        return context_vector, attention_weights\n",
      "# test attention\n",
      "# 创建一个BahdanauAttention层\n",
      "attention_layer = BahdanauAttention(units)\n",
      "# 后续解码器将产生这个attention查询(Query矩阵)\n",
      "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n",
      "# 添加到编码tokens\n",
      "context_vector, attention_weights = attention_layer(\n",
      "    query=example_attention_query,\n",
      "    value=example_enc_output,\n",
      "    mask=(example_tokens != 0))\n",
      "\n",
      "print(f'Attention result shape: (batch_size, query_seq_length, units): {context_vector.shape}')\n",
      "\n",
      "print(f'Attention weights shape: (batch_size, query_seq_length,value_seq_length): {attention_weights.shape}')\n",
      "plt.subplot(1, 2, 1)\n",
      "plt.pcolormesh(attention_weights[:, 0, :])\n",
      "plt.title('Attention weights')\n",
      "plt.subplot(1, 2, 2)\n",
      "plt.pcolormesh(example_tokens != 0)\n",
      "plt.title('Mask')\n",
      "# 输出结果：\n",
      "# Text(0.5, 1.0, 'Mask')\n",
      "#取出部分attention用于展示\n",
      "attention_slice = attention_weights[0, 0].numpy()\n",
      "attention_slice = attention_slice[attention_slice != 0]\n",
      "plt.suptitle('Attention weights for one sequence')\n",
      "plt.figure(figsize=(12, 6))\n",
      "a1 = plt.subplot(1, 2, 1)\n",
      "plt.bar(range(len(attention_slice)), attention_slice)\n",
      "# 固定x轴\n",
      "plt.xlim(plt.xlim())\n",
      "plt.xlabel('Attention weights')\n",
      "a2 = plt.subplot(1, 2, 2)\n",
      "plt.bar(range(len(attention_slice)), attention_slice)\n",
      "plt.xlabel('Attention weights, zoomed')\n",
      "# 放大结果\n",
      "top = max(a1.get_ylim())\n",
      "zoom = 0.85 * top\n",
      "a2.set_ylim([0.90 * top, top])\n",
      "a1.plot(a1.get_xlim(), [zoom, zoom], color='k')\n",
      "\n",
      "\n",
      "# 输出结果：\n",
      "# [<matplotlib.lines.Line2D at 0x20c356a9670>]\n",
      "# <Figure size 432x288 with 0 Axes>\n",
      "class Decoder(tf.keras.layers.Layer):\n",
      "    def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
      "        super(Decoder, self).__init__()\n",
      "        self.dec_units = dec_units\n",
      "        self.output_vocab_size = output_vocab_size\n",
      "        self.embedding_dim = embedding_dim\n",
      "\n",
      "        # 嵌入层将令牌ID转为向量\n",
      "        self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
      "                                                   embedding_dim)\n",
      "        # RNN会记录到目前为止已经生成的内容。\n",
      "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
      "                                       return_sequences=True,\n",
      "                                       return_state=True,\n",
      "                                       recurrent_initializer='glorot_uniform')\n",
      "        # RNN的输出将是注意力层的查询。\n",
      "        self.attention = BahdanauAttention(self.dec_units)\n",
      "        self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
      "                                        use_bias=False)\n",
      "        self.fc = tf.keras.layers.Dense(self.output_vocab_size)\n",
      "class DecoderInput(typing.NamedTuple):\n",
      "    new_tokens: Any\n",
      "    enc_output: Any\n",
      "    mask: Any\n",
      "\n",
      "\n",
      "class DecoderOutput(typing.NamedTuple):\n",
      "    logits: Any\n",
      "    attention_weights: Any\n",
      "def call(self,\n",
      "         inputs: DecoderInput,\n",
      "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
      "    shape_checker = ShapeChecker()\n",
      "    shape_checker(inputs.new_tokens, ('batch', 't'))\n",
      "    shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n",
      "    shape_checker(inputs.mask, ('batch', 's'))\n",
      "    if state is not None:\n",
      "        shape_checker(state, ('batch', 'dec_units'))\n",
      "    #查询词嵌入\n",
      "    vectors = self.embedding(inputs.new_tokens)\n",
      "    shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n",
      "    #用RNN处理一个步骤\n",
      "    rnn_output, state = self.gru(vectors, initial_state=state)\n",
      "    shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n",
      "    shape_checker(state, ('batch', 'dec_units'))\n",
      "    #使用RNN输出作为关注的查询，超过了编码器的输出。\n",
      "\n",
      "    context_vector, attention_weights = self.attention(\n",
      "        query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
      "    shape_checker(context_vector, ('batch', 't', 'dec_units'))\n",
      "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
      "    # 加入context_vector和rnn_output\n",
      "    context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
      "    attention_vector = self.Wc(context_and_rnn_output)\n",
      "    shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n",
      "    # 生成logit预测\n",
      "    logits = self.fc(attention_vector)\n",
      "    shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n",
      "    return DecoderOutput(logits, attention_weights), state\n",
      "Decoder.call = call\n",
      "decoder = Decoder(output_text_processor.vocabulary_size(),\n",
      "                  embedding_dim, units)\n",
      "#转换目标序列，并收集[START]标记。\n",
      "example_output_tokens = output_text_processor(example_target_batch)\n",
      "start_index = output_text_processor.get_vocabulary().index('[START]')\n",
      "first_token = tf.constant([[start_index]] * example_output_tokens.shape[0])\n",
      "#运行decoder\n",
      "dec_result, dec_state = decoder(\n",
      "    inputs=DecoderInput(new_tokens=first_token,\n",
      "                        enc_output=example_enc_output,\n",
      "                        mask=(example_tokens != 0)),\n",
      "    state=example_enc_state\n",
      ")\n",
      "print(f'logits shape: (batch_size, t, output_vocab_size)'\n",
      "      f'{dec_result.logits.shape}')\n",
      "print(f'state shape: (batch_size, dec_units) {dec_state.shape}')\n",
      "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
      "#将令牌解码为输出的第一个单词。\n",
      "vocab = np.array(output_text_processor.get_vocabulary())\n",
      "first_word = vocab[sampled_token.numpy()]\n",
      "print(first_word[:5])\n",
      "dec_result, dec_state = decoder(\n",
      "    DecoderInput(sampled_token,\n",
      "                 example_enc_output,\n",
      "                 mask=(example_tokens != 0)),\n",
      "    state=dec_state)\n",
      "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
      "first_word = vocab[sampled_token.numpy()]\n",
      "print(first_word[:5])\n",
      "class MaskedLoss(tf.keras.losses.Loss):\n",
      "    def __init__(self):\n",
      "        self.name = 'masked_loss'\n",
      "        self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
      "            from_logits=True, reduction='none')\n",
      "\n",
      "    def __call__(self, y_true, y_pred):\n",
      "        shape_checker = ShapeChecker()\n",
      "        shape_checker(y_true, ('batch', 't'))\n",
      "        shape_checker(y_pred, ('batch', 't', 'logits'))\n",
      "        # 计算该批次中每一项的损失。\n",
      "        loss = self.loss(y_true, y_pred)\n",
      "        shape_checker(loss, ('batch', 't'))\n",
      "        # 屏蔽掉填充物上的损失。\n",
      "        mask = tf.cast(y_true != 0, tf.float32)\n",
      "        shape_checker(mask, ('batch', 't'))\n",
      "        loss *= mask\n",
      "        # 返回总的loss。\n",
      "        return tf.reduce_sum(loss)\n",
      "class TrainTranslator(tf.keras.Model):\n",
      "    def __init__(self, embedding_dim, units,\n",
      "                 input_text_processor,\n",
      "                 output_text_processor,\n",
      "                 use_tf_function=True):\n",
      "        super().__init__()\n",
      "\n",
      "        # 构建编码器和解码器\n",
      "        encoder = Encoder(input_text_processor.vocabulary_size(),\n",
      "                          embedding_dim, units)\n",
      "        decoder = Decoder(output_text_processor.vocabulary_size(),\n",
      "                          embedding_dim, units)\n",
      "        self.encoder = encoder\n",
      "        self.decoder = decoder\n",
      "        self.input_text_processor = input_text_processor\n",
      "        self.output_text_processor = output_text_processor\n",
      "        self.use_tf_function = use_tf_function\n",
      "        self.shape_checker = ShapeChecker()\n",
      "\n",
      "    def train_step(self, inputs):\n",
      "        self.shape_checker = ShapeChecker()\n",
      "\n",
      "        if self.use_tf_function:\n",
      "            return self._tf_train_step(inputs)\n",
      "        else:\n",
      "            return self._train_step(inputs)\n",
      "def _preprocess(self, input_text, target_text):\n",
      "    self.shape_checker(input_text, ('batch',))\n",
      "    self.shape_checker(target_text, ('batch',))\n",
      "    # 将文本转换为tokens ID\n",
      "    input_tokens = self.input_text_processor(input_text)\n",
      "    target_tokens = self.output_text_processor(target_text)\n",
      "    self.shape_checker(input_tokens, ('batch', 's'))\n",
      "    self.shape_checker(target_tokens, ('batch', 't'))\n",
      "    # 将ID转换为掩码\n",
      "    input_mask = input_tokens != 0\n",
      "    self.shape_checker(input_mask, ('batch', 's'))\n",
      "    target_mask = target_tokens != 0\n",
      "\n",
      "    self.shape_checker(target_mask, ('batch', 't'))\n",
      "    return input_tokens, input_mask, target_tokens, target_mask\n",
      "\n",
      "\n",
      "TrainTranslator._preprocess = _preprocess\n",
      "def _train_step(self, inputs):\n",
      "    input_text, target_text = inputs\n",
      "    (input_tokens, input_mask,\n",
      "     target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
      "    max_target_length = tf.shape(target_tokens)[1]\n",
      "    with tf.GradientTape() as tape:\n",
      "        #对输入进行编码\n",
      "        enc_output, enc_state = self.encoder(input_tokens)\n",
      "        self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
      "        self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
      "        #将解码器的状态初始化为编码器的最终状态。\n",
      "        # 这只有在编码器和解码器有相同数量的单位时生效。\n",
      "        dec_state = enc_state\n",
      "        loss = tf.constant(0.0)\n",
      "        for t in tf.range(max_target_length - 1):\n",
      "            #从目标序列中传入两个token:\n",
      "            # 1.解码器的当前输入.\n",
      "            # 2.解码器下次预测的目标.\n",
      "            new_tokens = target_tokens[:, t:t + 2]\n",
      "            step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
      "                                                   enc_output, dec_state)\n",
      "            loss = loss + step_loss\n",
      "        #对所有非填充token的损失进行平均计算。\n",
      "        average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
      "    #设置优化步骤\n",
      "    variables = self.trainable_variables\n",
      "    gradients = tape.gradient(average_loss, variables)\n",
      "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
      "    # 返回一个映射到当前值的字典\n",
      "    return {'batch_loss': average_loss}\n",
      "\n",
      "\n",
      "TrainTranslator._train_step = _train_step\n",
      "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
      "    input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
      "    # Run the decoder one step.\n",
      "    decoder_input = DecoderInput(new_tokens=input_token,\n",
      "                                 enc_output=enc_output,\n",
      "                                 mask=input_mask)\n",
      "    dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
      "    self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
      "    self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
      "    self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
      "    # `self.loss`返回非填充token的总数。\n",
      "    y = target_token\n",
      "    y_pred = dec_result.logits\n",
      "    step_loss = self.loss(y, y_pred)\n",
      "    return step_loss, dec_state\n",
      "TrainTranslator._loop_step = _loop_step\n",
      "\n",
      "translator = TrainTranslator(\n",
      "    embedding_dim, units,\n",
      "    input_text_processor=input_text_processor,\n",
      "    output_text_processor=output_text_processor,\n",
      "    use_tf_function=False)\n",
      "#配置损失和优化器\n",
      "translator.compile(\n",
      "    optimizer=tf.optimizers.Adam(),\n",
      "    loss=MaskedLoss(),\n",
      ")\n",
      "np.log(output_text_processor.vocabulary_size())\n",
      "# 输出结果:\n",
      "# 8.517193191416238\n",
      "get_ipython().run_cell_magic('time', '', \"for n in range(10):\\n    print(translator.train_step([example_input_batch, example_target_batch]))\\nprint()\\n\\n\\n# 输出结果:\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.6101117>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.5797815>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.522971>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.3605533>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.785821>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.0904937>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.8641896>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.3120656>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.264642>}\\n# {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.112561>}\\n\")\n",
      "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
      "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
      "def _tf_train_step(self, inputs):\n",
      "    return self._train_step(inputs)\n",
      "\n",
      "\n",
      "TrainTranslator._tf_train_step = _tf_train_step\n",
      "\n",
      "translator.use_tf_function = True\n",
      "#第一次运行由于需要对函数进行追踪，故速度会比较慢\n",
      "translator.train_step([example_input_batch, example_target_batch])\n",
      "get_ipython().run_cell_magic('time', '', 'for n in range(10):\\n    print(translator.train_step([example_input_batch, example_target_batch]))\\nprint()\\n')\n",
      "losses = []\n",
      "for n in range(100):\n",
      "    print('.', end='')\n",
      "    logs = translator.train_step([example_input_batch, example_target_batch])\n",
      "    losses.append(logs['batch_loss'].numpy())\n",
      "print()\n",
      "plt.plot(losses)\n",
      "# 输出结果:\n",
      "#\n",
      "# [<matplotlib.lines.Line2D at 0x20c362c3c70>]\n",
      "train_translator = TrainTranslator(\n",
      "    embedding_dim, units,\n",
      "    input_text_processor=input_text_processor,\n",
      "    output_text_processor=output_text_processor)\n",
      "# Configure the loss and optimizer\n",
      "train_translator.compile(\n",
      "    optimizer=tf.optimizers.Adam(),\n",
      "    loss=MaskedLoss(),\n",
      ")\n",
      "class BatchLogs(tf.keras.callbacks.Callback):\n",
      "    def __init__(self, key):\n",
      "        self.key = key\n",
      "        self.logs = []\n",
      "\n",
      "    def on_train_batch_end(self, n, logs):\n",
      "        self.logs.append(logs[self.key])\n",
      "\n",
      "\n",
      "batch_loss = BatchLogs('batch_loss')\n",
      "\n",
      "train_translator.fit(dataset, epochs=3,\n",
      "                     steps_per_epoch=3,\n",
      "                     callbacks=[batch_loss])\n",
      "# 如果上一个cell中的epoches和steps_per_epoch过小，此处没有绘图效果。\n",
      "plt.plot(batch_loss.logs)\n",
      "plt.ylim([0, 3])\n",
      "plt.xlabel('Batch #')\n",
      "plt.ylabel('CE/token')\n",
      "class Translator(tf.Module):\n",
      "    def __init__(self, encoder, decoder, input_text_processor,\n",
      "                 output_text_processor):\n",
      "        self.encoder = encoder\n",
      "        self.decoder = decoder\n",
      "        self.input_text_processor = input_text_processor\n",
      "        self.output_text_processor = output_text_processor\n",
      "        self.output_token_string_from_index = (\n",
      "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
      "                vocabulary=output_text_processor.get_vocabulary(),\n",
      "                mask_token='',\n",
      "                invert=True))\n",
      "\n",
      "        # 输出不应该产生padding、unknown或start。\n",
      "        index_from_string = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
      "            vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
      "        token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
      "        token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
      "\n",
      "        token_mask[np.array(token_mask_ids)] = True\n",
      "        self.token_mask = token_mask\n",
      "        self.start_token = index_from_string(tf.constant('[START]'))\n",
      "        self.end_token = index_from_string(tf.constant('[END]'))\n",
      "\n",
      "\n",
      "translator = Translator(\n",
      "    encoder=train_translator.encoder,\n",
      "    decoder=train_translator.decoder,\n",
      "    input_text_processor=input_text_processor,\n",
      "    output_text_processor=output_text_processor,\n",
      ")\n",
      "def tokens_to_text(self, result_tokens):\n",
      "    shape_checker = ShapeChecker()\n",
      "    shape_checker(result_tokens, ('batch', 't'))\n",
      "    result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
      "    shape_checker(result_text_tokens, ('batch', 't'))\n",
      "    result_text = tf.strings.reduce_join(result_text_tokens,\n",
      "                                         axis=1, separator=' ')\n",
      "    shape_checker(result_text, 'batch')\n",
      "    result_text = tf.strings.strip(result_text)\n",
      "    shape_checker(result_text, ('batch',))\n",
      "    return result_text\n",
      "\n",
      "\n",
      "Translator.tokens_to_text = tokens_to_text\n",
      "\n",
      "example_output_tokens = tf.random.uniform(\n",
      "    shape=[5, 2], minval=0, dtype=tf.int64,\n",
      "    maxval=output_text_processor.vocabulary_size())\n",
      "\n",
      "translator.tokens_to_text(example_output_tokens).numpy()\n",
      "def sample(self, logits, temperature):\n",
      "    shape_checker = ShapeChecker()\n",
      "    shape_checker(logits, ('batch', 't', 'vocab'))\n",
      "    shape_checker(self.token_mask, ('vocab',))\n",
      "    token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
      "    shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n",
      "    logits = tf.where(self.token_mask, -np.inf, logits)\n",
      "    if temperature == 0.0:\n",
      "        new_tokens = tf.argmax(logits, axis=-1)\n",
      "    else:\n",
      "        logits = tf.squeeze(logits, axis=1)\n",
      "        new_tokens = tf.random.categorical(logits / temperature,\n",
      "                                           num_samples=1)\n",
      "        shape_checker(new_tokens, ('batch', 't'))\n",
      "        return new_tokens\n",
      "\n",
      "Translator.sample = sample\n",
      "\n",
      "example_logits = tf.random.normal([5, 1,\n",
      "                                   output_text_processor.vocabulary_size()])\n",
      "example_output_tokens = translator.sample(example_logits, temperature=1.0)\n",
      "example_output_tokens\n",
      "def translate_unrolled(self,\n",
      "                       input_text, *,\n",
      "                       max_length=50,\n",
      "                       return_attention=True,\n",
      "                       temperature=1.0):\n",
      "    batch_size = tf.shape(input_text)[0]\n",
      "    input_tokens = self.input_text_processor(input_text)\n",
      "    enc_output, enc_state = self.encoder(input_tokens)\n",
      "    dec_state = enc_state\n",
      "    new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
      "    result_tokens = []\n",
      "    attention = []\n",
      "    done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
      "    for _ in range(max_length):\n",
      "        dec_input = DecoderInput(new_tokens=new_tokens,\n",
      "                                 enc_output=enc_output,\n",
      "                                 mask=(input_tokens != 0))\n",
      "        dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
      "        attention.append(dec_result.attention_weights)\n",
      "        new_tokens = self.sample(dec_result.logits, temperature)\n",
      "        done = done | (new_tokens == self.end_token)\n",
      "        # 一旦一个序列完成，它只产生0-padding。\n",
      "        new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
      "        result_tokens.append(new_tokens)\n",
      "        if tf.executing_eagerly() and tf.reduce_all(done):\n",
      "            break\n",
      "    # 将生成的token id列表转换为字符串列表。\n",
      "\n",
      "    result_tokens = tf.concat(result_tokens, axis=-1)\n",
      "    result_text = self.tokens_to_text(result_tokens)\n",
      "    if return_attention:\n",
      "        attention_stack = tf.concat(attention, axis=1)\n",
      "        return {'text': result_text, 'attention': attention_stack}\n",
      "    else:\n",
      "        return {'text': result_text}\n",
      "Translator.translate = translate_unrolled\n",
      "get_ipython().run_cell_magic('time', '', 'input_text = tf.constant([\\n    \\'hace mucho frio aqui.\\',  # \"It\\'s freezing here.\"\\n    \\'Esta es mi vida.\\',  # \"This is my life.\"\"\\n])\\nresult = translator.translate(\\n    input_text=input_text)\\n\\n# print(result)\\nprint(result[\\'text\\'][0].numpy().decode())\\nprint(result[\\'text\\'][1].numpy().decode())\\nprint()\\n# 实验结果:\\n# it is very cold here .\\n# this is my life .\\n# Wall time: 266 ms\\n\\n')\n",
      "from IPython import get_ipython\n",
      "\n",
      "# 获取当前运行的笔记本\n",
      "notebook = get_ipython().get_ipython().user_ns['In']\n",
      "\n",
      "# 打印所有输入单元格的内容\n",
      "for cell in notebook:\n",
      "    print(cell)\n"
     ]
    }
   ],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:45:18.427622Z",
     "start_time": "2024-05-01T09:45:18.424704Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5520434f3d758c9d",
   "outputs": [],
   "execution_count": 129
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
