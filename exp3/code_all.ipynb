{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-08T11:16:16.280992Z",
     "start_time": "2024-04-08T11:16:14.025743Z"
    }
   },
   "source": [
    "#numpy sklearn jieba gensim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import string\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import CountVectorizer #载入词袋模型特征\n",
    "from sklearn.feature_extraction.text import TfidfTransformer #载入Tfidf转换器\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #载入Tfidf特征\n",
    "import gensim\n",
    "from sklearn.naive_bayes import MultinomialNB #导入多项朴素贝叶斯分类算法\n",
    "from sklearn.linear_model import SGDClassifier #导入随机梯度下降分类器\n",
    "from sklearn.linear_model import LogisticRegression #导入逻辑回归分类器\n",
    "from sklearn import metrics"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T11:16:16.301414Z",
     "start_time": "2024-04-08T11:16:16.282070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_data():\n",
    "    \"\"\"\n",
    "    获取数据\n",
    "    :return：文本数据，对应的labels\n",
    "    \"\"\"\n",
    "    with open('./dataset/data/ham_data.txt', encoding='utf-8') as ham_f, open('./dataset/data/spam_data.txt',\n",
    "                                                                              encoding='utf-8') as spam_f:\n",
    "        ham_data = ham_f.readlines()\n",
    "        spam_data = spam_f.readlines()\n",
    "\n",
    "        ham_label = np.ones(len(ham_data)).tolist()\n",
    "        spam_label = np.zeros(len(spam_data)).tolist()\n",
    "\n",
    "        corpus = ham_data + spam_data\n",
    "\n",
    "        labels = ham_label + spam_label\n",
    "\n",
    "    return corpus, labels\n",
    "\n",
    "\n",
    "def prepare_datasets(corpus, labels, test_data_proportion=0.3):\n",
    "    \"\"\"\n",
    "    :param corpus:\n",
    "    :param labels:\n",
    "    :param test_data_proportion:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train_x, test_x, train_y, test_y = train_test_split(corpus, labels, test_size=test_data_proportion, random_state=42)\n",
    "    return train_x, test_x, train_y, test_y\n",
    "\n",
    "\n",
    "def remove_empty_docs(corpus, labels):\n",
    "    filtered_corpus = []\n",
    "    filtered_labels = []\n",
    "    for doc, label in zip(corpus, labels):\n",
    "        if doc.strip():\n",
    "            filtered_corpus.append(doc)\n",
    "            filtered_labels.append(label)\n",
    "\n",
    "    return filtered_corpus, filtered_labels\n",
    "\n",
    "\n",
    "corpus, labels = get_data()\n",
    "\n",
    "print(f'总的数据量：{len(labels)}')\n",
    "\n",
    "corpus, labels = remove_empty_docs(corpus, labels)\n",
    "\n",
    "print(f'样本之一：{corpus[10]}')\n",
    "print(f'样本的label：{labels[10]}')\n",
    "label_name_map = ['垃圾邮件', '正常邮件']\n",
    "print(f'实际类型：{label_name_map[int(labels[10])]},'\n",
    "      f'{label_name_map[int(labels[5900])]}')\n",
    "\n",
    "# 对数据进行划分\n",
    "train_corpus, test_corpus, train_labels, test_labels = prepare_datasets(corpus, labels, test_data_proportion=0.3)\n"
   ],
   "id": "17e6d9ae249ce22e",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T11:16:16.307709Z",
     "start_time": "2024-04-08T11:16:16.302863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('./dataset/stop_words.utf8', encoding='utf-8') as f:\n",
    "    stopword_list = f.readlines()\n",
    "\n",
    "\n",
    "# jieba分词\n",
    "def tokenize_text(text):\n",
    "    tokens = jieba.lcut(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# 去除特殊字符\n",
    "def remove_special_characters(text):\n",
    "    tokens = tokenize_text(text)\n",
    "    pattern = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "    filtered_tokens = filter(None, [pattern.sub('', token) for token in tokens])\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "# 去除停用词\n",
    "def remove_stopwords(text):\n",
    "    tokens = tokenize_text(text)\n",
    "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "# 当tokenize=True时候，会对文本进行分词，除此以外还会对文本进行去除特殊符号、停用词等预处理\n",
    "def normalize_corpus(corpus, tokenize=False):\n",
    "    normalized_corpus = []\n",
    "    for text in corpus:\n",
    "        text = remove_special_characters(text)\n",
    "        text = remove_stopwords(text)\n",
    "        normalized_corpus.append(text)\n",
    "        if tokenize:\n",
    "            text = tokenize_text(text)\n",
    "            normalized_corpus.append(text)\n",
    "    return normalized_corpus\n"
   ],
   "id": "71156a7cef2cddfc",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T11:16:38.124300Z",
     "start_time": "2024-04-08T11:16:16.309989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def bow_extractor(corpus, ngram_range=(1, 1)):\n",
    "    vectorizer = CountVectorizer(min_df=1, ngram_range=ngram_range)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features\n",
    "\n",
    "\n",
    "# Tfidf特征转换\n",
    "def tfidf_transformer(bow_matrix):\n",
    "    transformer = TfidfTransformer(norm='l2', smooth_idf=True, use_idf=True)\n",
    "    tfidf_matrix = transformer.fit_transform(bow_matrix)\n",
    "    return transformer, tfidf_matrix\n",
    "\n",
    "\n",
    "# tfidf特征提取\n",
    "def tfidf_extractor(corpus, ngram_range=(1, 1)):\n",
    "    vectorizer = TfidfVectorizer(min_df=1, norm='l2', smooth_idf=True, use_idf=True, ngram_range=ngram_range)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features\n",
    "\n",
    "\n",
    "# 进行归一化\n",
    "norm_train_corpus = normalize_corpus(train_corpus)\n",
    "norm_test_corpus = normalize_corpus(test_corpus)\n",
    "\n",
    "# 词袋模型特征\n",
    "bow_vectorizer, bow_train_features = bow_extractor(norm_train_corpus)\n",
    "bow_test_features = bow_vectorizer.transform(norm_test_corpus)\n",
    "\n",
    "# tf-idf特征\n",
    "tfidf_vectorizer, tfidf_train_features = tfidf_extractor(norm_train_corpus)\n",
    "tfidf_test_features = tfidf_vectorizer.transform(norm_test_corpus)\n",
    "\n",
    "# 训练数据tokenize化\n",
    "tokenized_train = [jieba.lcut(text) for text in norm_train_corpus]\n",
    "print(tokenized_train[2:10])\n",
    "tokenized_test = [jieba.lcut(text) for text in norm_test_corpus]\n",
    "\n",
    "# build word2vec模型\n",
    "model = gensim.models.Word2Vec(tokenized_train, window=100, min_count=30, sample=1e-3)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "svm = SGDClassifier(loss='hinge')\n",
    "lr = LogisticRegression()\n",
    "\n",
    "\n",
    "# 首先声明了mnb, svm, lr 三个分类器，然后传入train_predict_evaluate_model函数中\n",
    "def train_predict_evaluate_model(classifier, train_features, train_labels, test_features, test_labels):\n",
    "    # build model\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    # predict using model\n",
    "    predictions = classifier.predict(test_features)\n",
    "    # evaluate model prediction performance\n",
    "    get_metrics(true_labels=test_labels, predicted_labels=predictions)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    print('Accuracy:', np.round(metrics.accuracy_score(true_labels, predicted_labels), 2))\n",
    "    print('Precision:', np.round(metrics.precision_score(true_labels, predicted_labels, average='weighted'), 2))\n",
    "    print('F1 Score:', np.round(metrics.f1_score(true_labels, predicted_labels, average='weighted'), 2))\n"
   ],
   "id": "248c1bb5174e3b22",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T11:16:38.339564Z",
     "start_time": "2024-04-08T11:16:38.125392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('基于词袋模型的多项朴素贝叶斯')\n",
    "mnb_bow_predictions = train_predict_evaluate_model(classifier=mnb, train_features=bow_train_features,\n",
    "                                                   train_labels=train_labels, test_features=bow_test_features,\n",
    "                                                   test_labels=test_labels)\n",
    "\n",
    "# 输出结果：\n",
    "# 自己跑\n",
    "\n",
    "# 基于词袋模型特征的逻辑回归\n",
    "print('基于词袋模型特征的逻辑回归')\n",
    "lr_bow_predictions = train_predict_evaluate_model(classifier=lr, train_features=bow_train_features,\n",
    "                                                  train_labels=train_labels, test_features=bow_test_features,\n",
    "                                                  test_labels=test_labels)\n",
    "# 输出结果：\n",
    "# 自己跑\n",
    "\n",
    "# 基于词袋模型的支持向量机方法\n",
    "print('基于词袋模型的支持向量机方法')\n",
    "svm_bow_predictions = train_predict_evaluate_model(classifier=svm, train_features=bow_train_features,\n",
    "                                                   train_labels=train_labels, test_features=bow_test_features,\n",
    "                                                   test_labels=test_labels)\n",
    "\n",
    "# 输出结果：\n",
    "# 自己跑\n",
    "\n",
    "# 基于tf-idf特征的多项朴素贝叶斯\n",
    "print('基于tf-idf特征的多项朴素贝叶斯')\n",
    "mnb_tfidf_predictions = train_predict_evaluate_model(classifier=mnb, train_features=tfidf_train_features,\n",
    "                                                     train_labels=train_labels, test_features=tfidf_test_features,\n",
    "                                                     test_labels=test_labels)\n",
    "\n",
    "# 输出结果：\n",
    "# 自己跑\n",
    "\n",
    "# 基于tf-idf特征的逻辑回归\n",
    "print('基于tf-idf特征的逻辑回归')\n",
    "lr_tfidf_predictions = train_predict_evaluate_model(classifier=lr, train_features=tfidf_train_features,\n",
    "                                                    train_labels=train_labels, test_features=tfidf_test_features,\n",
    "                                                    test_labels=test_labels)\n",
    "\n",
    "# 输出结果：\n",
    "# 自己跑\n",
    "\n",
    "# 基于tf-idf特征的支持向量机方法\n",
    "print('基于tf-idf特征的支持向量机方法')\n",
    "svm_tfidf_predictions = train_predict_evaluate_model(classifier=svm, train_features=tfidf_train_features,\n",
    "                                                     train_labels=train_labels, test_features=tfidf_test_features,\n",
    "                                                     test_labels=test_labels)\n"
   ],
   "id": "d2015712209d6e2d",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T11:16:38.348739Z",
     "start_time": "2024-04-08T11:16:38.343089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num = 0\n",
    "for document, label, predicted_label in zip(test_corpus, test_labels, svm_tfidf_predictions):\n",
    "    if label == 0 and predicted_label == 0:\n",
    "        print('邮件类型：', label_name_map[int(label)])\n",
    "        print('预测的邮件类型：', label_name_map[int(predicted_label)])\n",
    "        print('文本：-')\n",
    "        print(re.sub('\\n', '', document))\n",
    "        num += 1\n",
    "        if num == 4:\n",
    "            break\n",
    "\n",
    "num = 0\n",
    "for document, label, predicted_label in zip(test_corpus, test_labels, svm_tfidf_predictions):\n",
    "    if label == 1 and predicted_label == 1:\n",
    "        print('邮件类型：', label_name_map[int(label)])\n",
    "        print('预测的邮件类型：', label_name_map[int(predicted_label)])\n",
    "        print('文本：-')\n",
    "        print(re.sub('\\n', '', document))\n",
    "        num += 1\n",
    "        if num == 4:\n",
    "            break\n"
   ],
   "id": "40f4c8b36e6772ea",
   "execution_count": 6,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
